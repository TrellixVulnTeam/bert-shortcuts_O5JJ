{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from uuid import uuid4\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "account_id =  boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role=\"arn:aws:iam::{}:role/service-role/AmazonSageMaker-ExecutionRole-20190118T115449\".format(account_id)\n",
    "max_runs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = \"temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_examples_dir = os.path.join(temp_dir, \"hugging_face_example\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup image and instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_image_name=f\"huggingface-pytorch-training:1.9.1-transformers4.12.3-gpu-py38-cu111-ubuntu20.04\"\n",
    "image_account_id=\"763104351884\"\n",
    "instance_type = \"ml.p3.2xlarge\"\n",
    "instance_type_gpu_map = {\"ml.p3.8xlarge\":4, \"ml.p3.2xlarge\": 1, \"ml.p3.16xlarge\":8}\n",
    "instance_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_repo = \"{}.dkr.ecr.{}.amazonaws.com/{}\".format(image_account_id, region, custom_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configure train/ test and validation datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"aegovan-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_bert=\"s3://{}/embeddings/bert_base_cased/\".format(bucket)\n",
    "\n",
    "\n",
    "trainfile = \"s3://{}/glue_dataset/train/multinli_1.0_train.jsonl\".format(bucket)\n",
    "# valfile=\"s3://{}/mnli_dataset/val/multinli_1.0_dev_matched.jsonl\".format(bucket)\n",
    "\n",
    "#trainfile = \"s3://{}/mnli_dataset_mini/train/multinli.jsonl\".format(bucket)\n",
    "valfile=\"s3://{}/glue_dataset_mini/train/multinli.jsonl\".format(bucket)\n",
    "\n",
    "model_version = \"mnli-reverse-lang-bert-accuracy-2022-01-23-21-29-34-327\"\n",
    "\n",
    "s3_model_path = f\"s3://aegovan-data/mnli_sagemakerresults/{model_version}/output/model.tar.gz\"\n",
    "s3_model_package_path = f\"s3://aegovan-data/models/{model_version}/output\"\n",
    "s3_model_config_vocab_path = \"s3://aegovan-data/embeddings/bert_base_cased/\"\n",
    "\n",
    "s3_output_path= f\"s3://{bucket}/gluebenchmark_sagemakerresults/{model_version}/\"\n",
    "s3_code_path= f\"s3://{bucket}/gbucket_code\"\n",
    "s3_checkpoint = \"s3://{}/mnli_bert_checkpoint/{}\".format(bucket, str(uuid4()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run processing job training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(transformer_examples_dir):\n",
    "    shutil.rmtree(transformer_examples_dir)\n",
    "    os.makedirs(transformer_examples_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/hugging_face_example'...\n",
      "remote: Enumerating objects: 101039, done.\u001b[K\n",
      "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
      "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
      "remote: Total 101039 (delta 45), reused 44 (delta 28), pack-reused 100957\u001b[K\n",
      "Receiving objects: 100% (101039/101039), 86.59 MiB | 15.83 MiB/s, done.\n",
      "Resolving deltas: 100% (73330/73330), done.\n",
      "Note: switching to 'tags/v4.12.3'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at 3ea15d278 Style\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/transformers $transformer_examples_dir\n",
    "!git -C $transformer_examples_dir checkout tags/v4.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "framework_processor = FrameworkProcessor(HuggingFace,\n",
    "                                      framework_version=None,\n",
    "                                      image_uri=docker_repo,\n",
    "                                      code_location = s3_code_path, \n",
    "                                       py_version=\"py36\",\n",
    "                                       command=[\"python\"],\n",
    "                                       env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "                                       role=role,\n",
    "                                       instance_type=instance_type,\n",
    "                                       instance_count=instance_count,\n",
    "                                       max_runtime_in_seconds= 5 * 24 * 60 * 60,\n",
    "                                       volume_size_in_gb = 250,\n",
    "                                       network_config=NetworkConfig(enable_network_isolation=False),\n",
    "                                       base_job_name =\"glue-processing\"\n",
    "                                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run base mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  glue-processing-2022-02-19-17-25-50-403\n",
      "Inputs:  [{'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/gbucket_code/glue-processing-2022-02-19-17-25-50-403/source/sourcedir.tar.gz', 'LocalPath': '/opt/ml/processing/input/code/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'entrypoint', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/gbucket_code/glue-processing-2022-02-19-17-25-50-403/source/runproc.sh', 'LocalPath': '/opt/ml/processing/input/entrypoint', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'predictions', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://aegovan-data/gluebenchmark_sagemakerresults/mnli-reverse-lang-bert-accuracy-2022-01-23-21-29-34-327/', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".......................................\u001b[34mWARNING: Skipping typing as it is not installed.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting accelerate\n",
      "  Downloading accelerate-0.5.1-py3-none-any.whl (58 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets>=1.8.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.1.96)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (3.19.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.9.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (21.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.70.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2.26.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (3.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (1.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (4.62.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (5.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2021.10.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 5)) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.3->-r requirements.txt (line 7)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.8.0->-r requirements.txt (line 2)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets>=1.8.0->-r requirements.txt (line 2)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2021.10.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (4.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (5.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (21.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: accelerate\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.5.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:30 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:30 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=None,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=True,\u001b[0m\n",
      "\u001b[34mdo_eval=True,\u001b[0m\n",
      "\u001b[34mdo_predict=True,\u001b[0m\n",
      "\u001b[34mdo_train=True,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_steps=200,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34mfp16=False,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=4,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=False,\u001b[0m\n",
      "\u001b[34mgreater_is_better=False,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_strategy=HubStrategy.EVERY_SAVE,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=2e-05,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=True,\u001b[0m\n",
      "\u001b[34mlocal_rank=-1,\u001b[0m\n",
      "\u001b[34mlog_level=-1,\u001b[0m\n",
      "\u001b[34mlog_level_replica=-1,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/opt/ml/processing/output/runs/Feb19_17-32-30_ip-10-0-65-22.us-east-2.compute.internal,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=500,\u001b[0m\n",
      "\u001b[34mlogging_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=SchedulerType.LINEAR,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=1.0,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=loss,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=3.0,\u001b[0m\n",
      "\u001b[34moutput_dir=/opt/ml/processing/output,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=True,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=8,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=8,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=[],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/opt/ml/processing/output,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_steps=200,\u001b[0m\n",
      "\u001b[34msave_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34msave_total_limit=None,\u001b[0m\n",
      "\u001b[34mseed=42,\u001b[0m\n",
      "\u001b[34msharded_ddp=[],\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.0,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.0,\u001b[0m\n",
      "\u001b[34mxpu_backend=None,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:30 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/glue.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmprrlxas0m\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/7.78k [00:00<?, ?B/s]#015Downloading: 28.8kB [00:00, 14.8MB/s]                   \u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:30 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/glue.py in cache at /root/.cache/huggingface/datasets/downloads/ebcebc40af3c6b9af1a2f380ea06637ee192bce2d17d528809dd0ee2fa281675.759f3e257a3fad0984d9f8ba9a26479d341795eb50fa64e4c1de40f1fc421313.py\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:30 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/ebcebc40af3c6b9af1a2f380ea06637ee192bce2d17d528809dd0ee2fa281675.759f3e257a3fad0984d9f8ba9a26479d341795eb50fa64e4c1de40f1fc421313.py\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:30 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpjjjsjpvc\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/4.47k [00:00<?, ?B/s]#015Downloading: 28.7kB [00:00, 15.4MB/s]                   \u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:31 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/eea1163a0dd089739f6e5e3951d74b1200c7e66d462d607c43cbc8c4e69bbd47.082d8848abcb8cddda90647ec069014ca338abd4f45e0a83c6df1ece0d45476a\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:31 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/eea1163a0dd089739f6e5e3951d74b1200c7e66d462d607c43cbc8c4e69bbd47.082d8848abcb8cddda90647ec069014ca338abd4f45e0a83c6df1ece0d45476a\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:31 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:31 - INFO - datasets.builder - Generating dataset glue (/root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset glue/mnli (download: 298.29 MiB, generated: 78.65 MiB, post-processed: Unknown size, total: 376.95 MiB) to /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:31 - INFO - datasets.builder - Dataset not on Hf google storage. Downloading and preparing it from source\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:31 - INFO - datasets.utils.file_utils - https://dl.fbaipublicfiles.com/glue/data/MNLI.zip not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmproknf_1d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Downloading:   0%|          | 0.00/313M [00:00<?, ?B/s]#015Downloading:   0%|          | 52.2k/313M [00:00<15:51, 329kB/s]#015Downloading:   0%|          | 296k/313M [00:00<05:00, 1.04MB/s]#015Downloading:   0%|          | 1.25M/313M [00:00<01:34, 3.29MB/s]#015Downloading:   1%|          | 3.46M/313M [00:00<00:35, 8.71MB/s]#015Downloading:   2%|▏         | 7.14M/313M [00:00<00:18, 16.9MB/s]#015Downloading:   4%|▍         | 12.1M/313M [00:00<00:11, 26.7MB/s]#015Downloading:   5%|▌         | 16.4M/313M [00:00<00:09, 31.4MB/s]#015Downloading:   7%|▋         | 21.4M/313M [00:00<00:07, 36.8MB/s]#015Downloading:   8%|▊         | 26.1M/313M [00:01<00:07, 39.9MB/s]#015Downloading:  10%|█         | 31.5M/313M [00:01<00:06, 44.0MB/s]#015Downloading:  12%|█▏        | 36.4M/313M [00:01<00:06, 44.1MB/s]#015Downloading:  13%|█▎        | 41.8M/313M [00:01<00:05, 46.8MB/s]#015Downloading:  15%|█▌        | 47.1M/313M [00:01<00:05, 48.7MB/s]#015Downloading:  17%|█▋        | 52.5M/313M [00:01<00:05, 50.3MB/s]#015Downloading:  18%|█▊        | 57.6M/313M [00:01<00:05, 48.6MB/s]#015Downloading:  20%|██        | 62.9M/313M [00:01<00:04, 50.1MB/s]#015Downloading:  22%|██▏       | 68.2M/313M [00:01<00:04, 50.9MB/s]#015Downloading:  24%|██▎       | 73.8M/313M [00:02<00:04, 52.0MB/s]#015Downloading:  25%|██▌       | 79.0M/313M [00:02<00:04, 50.8MB/s]#015Downloading:  27%|██▋       | 84.2M/313M [00:02<00:04, 51.1MB/s]#015Downloading:  29%|██▊       | 89.8M/313M [00:02<00:04, 52.4MB/s]#015Downloading:  30%|███       | 95.0M/313M [00:02<00:04, 51.8MB/s]#015Downloading:  32%|███▏      | 100M/313M [00:02<00:04, 51.6MB/s] #015Downloading:  34%|███▎      | 105M/313M [00:02<00:04, 51.5MB/s]#015Downloading:  35%|███▌      | 111M/313M [00:02<00:03, 51.0MB/s]#015Downloading:  37%|███▋      | 116M/313M [00:02<00:03, 51.9MB/s]#015Downloading:  39%|███▊      | 121M/313M [00:02<00:03, 51.2MB/s]#015Downloading:  40%|████      | 126M/313M [00:03<00:03, 52.1MB/s]#015Downloading:  42%|████▏     | 132M/313M [00:03<00:03, 52.5MB/s]#015Downloading:  44%|████▍     | 137M/313M [00:03<00:03, 51.3MB/s]#015Downloading:  45%|████▌     | 142M/313M [00:03<00:03, 51.0MB/s]#015Downloading:  47%|████▋     | 147M/313M [00:03<00:03, 51.2MB/s]#015Downloading:  49%|████▉     | 153M/313M [00:03<00:03, 51.1MB/s]#015Downloading:  51%|█████     | 158M/313M [00:03<00:03, 50.9MB/s]#015Downloading:  52%|█████▏    | 163M/313M [00:03<00:02, 51.6MB/s]#015Downloading:  54%|█████▍    | 169M/313M [00:03<00:02, 52.6MB/s]#015Downloading:  56%|█████▌    | 174M/313M [00:03<00:02, 51.3MB/s]#015Downloading:  57%|█████▋    | 179M/313M [00:04<00:02, 51.3MB/s]#015Downloading:  59%|█████▉    | 185M/313M [00:04<00:02, 51.8MB/s]#015Downloading:  61%|██████    | 190M/313M [00:04<00:02, 52.2MB/s]#015Downloading:  62%|██████▏   | 195M/313M [00:04<00:02, 51.4MB/s]#015Downloading:  64%|██████▍   | 200M/313M [00:04<00:02, 51.3MB/s]#015Downloading:  66%|██████▌   | 205M/313M [00:04<00:02, 51.3MB/s]#015Downloading:  67%|██████▋   | 211M/313M [00:04<00:01, 52.7MB/s]#015Downloading:  69%|██████▉   | 216M/313M [00:04<00:01, 51.4MB/s]#015Downloading:  71%|███████   | 221M/313M [00:04<00:01, 51.3MB/s]#015Downloading:  73%|███████▎  | 227M/313M [00:04<00:01, 52.1MB/s]#015Downloading:  74%|███████▍  | 232M/313M [00:05<00:01, 51.5MB/s]#015Downloading:  76%|███████▌  | 237M/313M [00:05<00:01, 47.4MB/s]#015Downloading:  78%|███████▊  | 243M/313M [00:05<00:01, 50.5MB/s]#015Downloading:  80%|███████▉  | 249M/313M [00:05<00:01, 53.0MB/s]#015Downloading:  81%|████████▏ | 254M/313M [00:05<00:01, 50.9MB/s]#015Downloading:  83%|████████▎ | 260M/313M [00:05<00:01, 46.8MB/s]#015Downloading:  85%|████████▍ | 266M/313M [00:05<00:00, 50.4MB/s]#015Downloading:  87%|████████▋ | 272M/313M [00:05<00:00, 53.7MB/s]#015Downloading:  89%|████████▊ | 277M/313M [00:05<00:00, 53.2MB/s]#015Downloading:  90%|█████████ | 283M/313M [00:06<00:00, 54.2MB/s]#015Downloading:  92%|█████████▏| 288M/313M [00:06<00:00, 52.5MB/s]#015Downloading:  94%|█████████▍| 294M/313M [00:06<00:00, 51.7MB/s]#015Downloading:  96%|█████████▌| 299M/313M [00:06<00:00, 51.6MB/s]#015Downloading:  97%|█████████▋| 304M/313M [00:06<00:00, 51.4MB/s]#015Downloading:  99%|█████████▉| 309M/313M [00:06<00:00, 51.5MB/s]#015Downloading: 100%|██████████| 313M/313M [00:06<00:00, 47.0MB/s]\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:38 - INFO - datasets.utils.file_utils - storing https://dl.fbaipublicfiles.com/glue/data/MNLI.zip in cache at /root/.cache/huggingface/datasets/downloads/74d7bc70ada44c1086d1ba81cf6271c128514f629fb8edcd548c113939e3b5f2\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:38 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/74d7bc70ada44c1086d1ba81cf6271c128514f629fb8edcd548c113939e3b5f2\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:38 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:39 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:47 - INFO - datasets.utils.info_utils - All the checksums matched successfully for dataset source files\u001b[0m\n",
      "\u001b[34m02/19/2022 17:32:47 - INFO - datasets.builder - Generating split train\u001b[0m\n",
      "\u001b[34m02/19/2022 17:33:08 - INFO - datasets.builder - Generating split validation_matched\u001b[0m\n",
      "\u001b[34m02/19/2022 17:33:08 - INFO - datasets.builder - Generating split validation_mismatched\u001b[0m\n",
      "\u001b[34m02/19/2022 17:33:09 - INFO - datasets.builder - Generating split test_matched\u001b[0m\n",
      "\u001b[34m02/19/2022 17:33:09 - INFO - datasets.builder - Generating split test_mismatched\u001b[0m\n",
      "\u001b[34m02/19/2022 17:33:10 - INFO - datasets.utils.info_utils - All the splits matched successfully.\u001b[0m\n",
      "\u001b[34mDataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m#0150 examples [00:00, ? examples/s]#0151908 examples [00:00, 19072.42 examples/s]#0153918 examples [00:00, 19671.83 examples/s]#0155954 examples [00:00, 19984.32 examples/s]#0157956 examples [00:00, 19994.37 examples/s]#0159970 examples [00:00, 20045.72 examples/s]#01511975 examples [00:00, 19047.79 examples/s]#01514041 examples [00:00, 19555.45 examples/s]#01516092 examples [00:00, 19849.59 examples/s]#01518150 examples [00:00, 20072.82 examples/s]#01520162 examples [00:01, 19469.29 examples/s]#01522213 examples [00:01, 19774.14 examples/s]#01524278 examples [00:01, 20032.38 examples/s]#01526287 examples [00:01, 20045.36 examples/s]#01528295 examples [00:01, 20052.82 examples/s]#01530303 examples [00:01, 15910.44 examples/s]#01532334 examples [00:01, 17023.51 examples/s]#01534367 examples [00:01, 17901.30 examples/s]#01536420 examples [00:01, 18621.29 examples/s]#01538455 examples [00:02, 19106.99 examples/s]#01540419 examples [00:02, 18840.58 examples/s]#01542460 examples [00:02, 19288.74 examples/s]#01544500 examples [00:02, 19609.62 examples/s]#01546529 examples [00:02, 19807.50 examples/s]#01548565 examples [00:02, 19967.54 examples/s]#01550573 examples [00:02, 19180.85 examples/s]#01552624 examples [00:02, 19564.47 examples/s]#01554697 examples [00:02, 19902.29 examples/s]#01556749 examples [00:02, 20081.92 examples/s]#01558792 examples [00:03, 20184.61 examples/s]#01560816 examples [00:03, 19458.35 examples/s]#01562869 examples [00:03, 19766.82 examples/s]#01564909 examples [00:03, 19948.85 examples/s]#01566943 examples [00:03, 20063.86 examples/s]#01568979 examples [00:03, 20149.66 examples/s]#01570997 examples [00:03, 19540.75 examples/s]#01573046 examples [00:03, 19815.21 examples/s]#01575104 examples [00:03, 20039.21 examples/s]#01577157 examples [00:03, 20183.02 examples/s]#01579209 examples [00:04, 20281.33 examples/s]#01581240 examples [00:04, 19515.67 examples/s]#01583199 examples [00:04, 16251.94 examples/s]#01585241 examples [00:04, 17320.79 examples/s]#01587284 examples [00:04, 18152.72 examples/s]#01589298 examples [00:04, 18700.11 examples/s]#01591220 examples [00:04, 18477.53 examples/s]#01593289 examples [00:04, 19104.63 examples/s]#01595347 examples [00:04, 19528.06 examples/s]#01597409 examples [00:05, 19845.66 examples/s]#01599459 examples [00:05, 20035.95 examples/s]#015101475 examples [00:05, 19463.67 examples/s]#015103513 examples [00:05, 19729.47 examples/s]#015105555 examples [00:05, 19930.84 examples/s]#015107592 examples [00:05, 20059.31 examples/s]#015109655 examples [00:05, 20225.77 examples/s]#015111682 examples [00:05, 19467.01 examples/s]#015113746 examples [00:05, 19805.14 examples/s]#015115794 examples [00:05, 20001.08 examples/s]#015117853 examples [00:06, 20172.51 examples/s]#015119885 examples [00:06, 20213.44 examples/s]#015121910 examples [00:06, 19475.94 examples/s]#015123953 examples [00:06, 19749.88 examples/s]#015125994 examples [00:06, 19940.81 examples/s]#015128041 examples [00:06, 20096.23 examples/s]#015130055 examples [00:06, 19545.36 examples/s]#015132113 examples [00:06, 19846.11 examples/s]#015134156 examples [00:06, 20015.39 examples/s]#015136162 examples [00:07, 17107.60 examples/s]#015138189 examples [00:07, 17945.35 examples/s]#015140047 examples [00:07, 17750.48 examples/s]#015142068 examples [00:07, 18432.50 examples/s]#015144097 examples [00:07, 18958.32 examples/s]#015146142 examples [00:07, 19388.41 examples/s]#015148200 examples [00:07, 19735.01 examples/s]#015150190 examples [00:07, 19208.22 examples/s]#015152225 examples [00:07, 19537.40 examples/s]#015154265 examples [00:07, 19789.37 examples/s]#015156311 examples [00:08, 19985.75 examples/s]#015158368 examples [00:08, 20156.10 examples/s]#015160388 examples [00:08, 19289.91 examples/s]#015162417 examples [00:08, 19576.69 examples/s]#015164457 examples [00:08, 19814.77 examples/s]#015166498 examples [00:08, 19988.16 examples/s]#015168572 examples [00:08, 20207.84 examples/s]#015170597 examples [00:08, 19564.33 examples/s]#015172663 examples [00:08, 19882.80 examples/s]#015174707 examples [00:08, 20044.14 examples/s]#015176758 examples [00:09, 20177.61 examples/s]#015178790 examples [00:09, 20218.50 examples/s]#015180815 examples [00:09, 19375.06 examples/s]#015182856 examples [00:09, 19674.22 examples/s]#015184913 examples [00:09, 19935.73 examples/s]#015186966 examples [00:09, 20108.82 examples/s]#015188982 examples [00:09, 17432.44 examples/s]#015190791 examples [00:09, 17452.95 examples/s]#015192836 examples [00:09, 18277.20 examples/s]#015194881 examples [00:10, 18887.86 examples/s]#015196910 examples [00:10, 19288.33 examples/s]#015198941 examples [00:10, 19582.33 examples/s]#015200917 examples [00:10, 18972.92 examples/s]#015202953 examples [00:10, 19370.08 examples/s]#015204996 examples [00:10, 19677.41 examples/s]#015207053 examples [00:10, 19938.91 examples/s]#015209120 examples [00:10, 20152.23 examples/s]#015211141 examples [00:10, 19528.78 examples/s]#015213183 examples [00:10, 19787.28 examples/s]#015215220 examples [00:11, 19956.21 examples/s]#015217256 examples [00:11, 20074.42 examples/s]#015219304 examples [00:11, 20194.33 examples/s]#015221326 examples [00:11, 19460.46 examples/s]#015223374 examples [00:11, 19756.07 examples/s]#015225406 examples [00:11, 19919.74 examples/s]#015227428 examples [00:11, 20008.08 examples/s]#015229471 examples [00:11, 20130.36 examples/s]#015231487 examples [00:11, 19545.60 examples/s]#015233533 examples [00:12, 19812.09 examples/s]#015235574 examples [00:12, 19985.03 examples/s]#015237609 examples [00:12, 20092.42 examples/s]#015239633 examples [00:12, 20134.68 examples/s]#015241649 examples [00:12, 19400.23 examples/s]#015243596 examples [00:12, 17144.83 examples/s]#015245629 examples [00:12, 17999.06 examples/s]#015247683 examples [00:12, 18701.49 examples/s]#015249734 examples [00:12, 19212.00 examples/s]#015251685 examples [00:12, 18917.88 examples/s]#015253724 examples [00:13, 19338.85 examples/s]#015255721 examples [00:13, 19521.57 examples/s]#015257694 examples [00:13, 19581.20 examples/s]#015259743 examples [00:13, 19849.06 examples/s]#015261735 examples [00:13, 19262.54 examples/s]#015263777 examples [00:13, 19598.37 examples/s]#015265831 examples [00:13, 19873.33 examples/s]#015267889 examples [00:13, 20081.19 examples/s]#015269965 examples [00:13, 20282.14 examples/s]#015271997 examples [00:14, 19638.77 examples/s]#015274031 examples [00:14, 19841.93 examples/s]#015276070 examples [00:14, 20001.60 examples/s]#015278105 examples [00:14, 20103.71 examples/s]#015280119 examples [00:14, 19413.82 examples/s]#015282145 examples [00:14, 19656.92 examples/s]#015284179 examples [00:14, 19855.34 examples/s]#015286211 examples [00:14, 19991.85 examples/s]#015288256 examples [00:14, 20124.40 examples/s]#015290271 examples [00:14, 19389.71 examples/s]#015292286 examples [00:15, 19608.87 examples/s]#015294313 examples [00:15, 19801.78 examples/s]#015296298 examples [00:15, 16475.22 examples/s]#015298333 examples [00:15, 17479.51 examples/s]#015300163 examples [00:15, 17543.06 examples/s]#015302188 examples [00:15, 18291.91 examples/s]#015304209 examples [00:15, 18834.55 examples/s]#015306260 examples [00:15, 19316.38 examples/s]#015308293 examples [00:15, 19609.89 examples/s]#015310274 examples [00:16, 18800.86 examples/s]#015312287 examples [00:16, 19180.96 examples/s]#015314316 examples [00:16, 19500.94 examples/s]#015316356 examples [00:16, 19764.10 examples/s]#015318395 examples [00:16, 19946.69 examples/s]#015320397 examples [00:16, 19320.02 examples/s]#015322418 examples [00:16, 19578.06 examples/s]#015324457 examples [00:16, 19814.63 examples/s]#015326507 examples [00:16, 20016.34 examples/s]#015328537 examples [00:16, 20097.61 examples/s]#015330550 examples [00:17, 19421.30 examples/s]#015332572 examples [00:17, 19653.40 examples/s]#015334577 examples [00:17, 19768.42 examples/s]#015336612 examples [00:17, 19937.95 examples/s]#015338609 examples [00:17, 16940.11 examples/s]#015340382 examples [00:17, 15012.90 examples/s]#015341969 examples [00:17, 15134.70 examples/s]#015343939 examples [00:17, 16325.36 examples/s]#015345930 examples [00:17, 17296.65 examples/s]#015347948 examples [00:18, 18100.98 examples/s]#015349802 examples [00:18, 15372.43 examples/s]#015351568 examples [00:18, 15955.67 examples/s]#015353579 examples [00:18, 17065.42 examples/s]#015355592 examples [00:18, 17911.56 examples/s]#015357615 examples [00:18, 18566.42 examples/s]#015359640 examples [00:18, 19048.67 examples/s]#015361577 examples [00:18, 18662.77 examples/s]#015363600 examples [00:18, 19113.56 examples/s]#015365605 examples [00:19, 19385.47 examples/s]#015367620 examples [00:19, 19608.08 examples/s]#015369661 examples [00:19, 19844.93 examples/s]#015371653 examples [00:19, 19139.94 examples/s]#015373663 examples [00:19, 19415.94 examples/s]#015375676 examples [00:19, 19623.14 examples/s]#015377698 examples [00:19, 19798.05 examples/s]#015379725 examples [00:19, 19936.42 examples/s]#015381722 examples [00:19, 19174.91 examples/s]#015383754 examples [00:19, 19505.67 examples/s]#015385759 examples [00:20, 19663.06 examples/s]#015387785 examples [00:20, 19836.74 examples/s]#015389816 examples [00:20, 19972.86 examples/s]#015391817 examples [00:20, 19407.54 examples/s]#015                                            #015#0150 examples [00:00, ? examples/s]#0151892 examples [00:00, 18909.20 examples/s]#0153886 examples [00:00, 19514.44 examples/s]#0155892 examples [00:00, 19762.96 examples/s]#0157877 examples [00:00, 19793.27 examples/s]#015                                          #015#0150 examples [00:00, ? examples/s]#0151890 examples [00:00, 18894.48 examples/s]#0153866 examples [00:00, 19399.80 examples/s]#0155856 examples [00:00, 19622.90 examples/s]#0157839 examples [00:00, 19703.87 examples/s]#0159810 examples [00:00, 19702.71 examples/s]#015                                          #015#0150 examples [00:00, ? examples/s]#0152121 examples [00:00, 21205.02 examples/s]#0154286 examples [00:00, 21460.59 examples/s]#0156488 examples [00:00, 21711.07 examples/s]#0158703 examples [00:00, 21880.03 examples/s]#015                                          #015#0150 examples [00:00, ? examples/s]#0152076 examples [00:00, 20754.53 examples/s]#0154266 examples [00:00, 21427.34 examples/s]#0156476 examples [00:00, 21730.29 examples/s]#0158675 examples [00:00, 21828.15 examples/s]#015                                          #015#015  0%|          | 0/5 [00:00<?, ?it/s]#015100%|██████████| 5/5 [00:00<00:00, 785.45it/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1753] 2022-02-19 17:33:10,382 >> https://huggingface.co/bert-base-cased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpxkoanoww\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 570/570 [00:00<00:00, 520kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1757] 2022-02-19 17:33:10,453 >> storing https://huggingface.co/bert-base-cased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1765] 2022-02-19 17:33:10,453 >> creating metadata file for /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:588] 2022-02-19 17:33:10,453 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:625] 2022-02-19 17:33:10,454 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1753] 2022-02-19 17:33:10,524 >> https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpc59wg6cj\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 26.9kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1757] 2022-02-19 17:33:10,594 >> storing https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1765] 2022-02-19 17:33:10,594 >> creating metadata file for /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:588] 2022-02-19 17:33:10,668 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:625] 2022-02-19 17:33:10,669 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1753] 2022-02-19 17:33:10,815 >> https://huggingface.co/bert-base-cased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpdw0fzzjb\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 208k/208k [00:00<00:00, 4.62MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1757] 2022-02-19 17:33:10,931 >> storing https://huggingface.co/bert-base-cased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1765] 2022-02-19 17:33:10,932 >> creating metadata file for /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1753] 2022-02-19 17:33:11,001 >> https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp4rvdab9p\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 426k/426k [00:00<00:00, 7.47MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1757] 2022-02-19 17:33:11,131 >> storing https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1765] 2022-02-19 17:33:11,131 >> creating metadata file for /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1742] 2022-02-19 17:33:11,338 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1742] 2022-02-19 17:33:11,339 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1742] 2022-02-19 17:33:11,339 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1742] 2022-02-19 17:33:11,339 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1742] 2022-02-19 17:33:11,339 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:588] 2022-02-19 17:33:11,405 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:625] 2022-02-19 17:33:11,406 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:1753] 2022-02-19 17:33:11,528 >> https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpmfwsw9lz\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sm/0jbn3m7x7gg6sxqyq1h3lmgj6h25fm/T/ipykernel_60883/1864268791.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msm_local_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms3_output_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 output_name='predictions')]\n\u001b[0m\u001b[1;32m     57\u001b[0m     )\n",
      "\u001b[0;32m~/venv/shortcuts/lib/python3.7/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, code, source_dir, dependencies, git_config, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m   1604\u001b[0m             \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m             \u001b[0mexperiment_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1607\u001b[0m         )\n\u001b[1;32m   1608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/shortcuts/lib/python3.7/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_include_code_in_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/shortcuts/lib/python3.7/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    960\u001b[0m         \"\"\"\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_processing_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_processing_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/shortcuts/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_processing_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3811\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3813\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "sm_local_input_models = \"/opt/ml/processing/input/data/models\"\n",
    "sm_local_input_data = \"/opt/ml/processing/input/data/jsonlines\"\n",
    "sm_local_input_vocab = \"/opt/ml/processing/input/data/vocab\"\n",
    "\n",
    "\n",
    "sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "\n",
    "\n",
    "framework_processor.run(\n",
    "        code=f'run_glue.py',\n",
    "        source_dir=f'{transformer_examples_dir}/examples/pytorch/text-classification',\n",
    "        arguments=[\n",
    "            \"--task_name\", \"mnli\",\n",
    "            \"--model_name_or_path\", \"bert-base-cased\",\n",
    "            \"--do_train\", \"1\",\n",
    "            \"--do_eval\",\"1\",\n",
    "            \"--do_predict\",\"1\",\n",
    "            \"--max_seq_length\", str(512),\n",
    "            \"--per_device_train_batch_size\", str(8),\n",
    "            \"--gradient_accumulation_steps\", str(4),\n",
    "            \"--learning_rate\", str(2e-5),\n",
    "            \"--num_train_epochs\", str(3),\n",
    "            \"--output_dir\", sm_local_output,\n",
    "            \"--overwrite_output_dir\", \"1\",\n",
    "            \"--load_best_model_at_end\", \"1\",     # load the best model when finished training (default metric is loss)\n",
    "            \"--eval_steps\",\"200\",\n",
    "            \"--save_steps\",\"200\",\n",
    "            \"--evaluation_strategy\",\"steps\",\n",
    "            \"--disable_tqdm\",\"1\"\n",
    "           \n",
    "        ],\n",
    "\n",
    "        inputs=[\n",
    "#                 ProcessingInput(\n",
    "#                     source=s3_input_data,\n",
    "#                     s3_data_type = s3_data_type,\n",
    "#                     destination=sm_local_input_data,\n",
    "#                     s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "#                 ProcessingInput(\n",
    "#                         source=s3_model_path,\n",
    "#                         destination=sm_local_input_models,\n",
    "#                         s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "#                 ProcessingInput(\n",
    "#                         source=s3_input_vocab,\n",
    "#                         destination=sm_local_input_vocab,\n",
    "#                         s3_data_distribution_type=\"FullyReplicated\")\n",
    "            ],\n",
    "\n",
    "\n",
    "        outputs=[ProcessingOutput(\n",
    "                source=sm_local_output, \n",
    "                destination=s3_output_path,\n",
    "                output_name='predictions')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with reverse train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "framework_processor = FrameworkProcessor(HuggingFace,\n",
    "                                      framework_version=None,\n",
    "                                      image_uri=docker_repo,\n",
    "                                       code_location = s3_code_path, \n",
    "                                       py_version=\"py36\",\n",
    "                                       command=[\"python\"],\n",
    "                                       env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "                                       role=role,\n",
    "                                       instance_type=\"ml.m5.large\",\n",
    "                                       instance_count=1,\n",
    "                                       max_runtime_in_seconds= 5 * 24 * 60 * 60,\n",
    "                                       volume_size_in_gb = 250,\n",
    "                                       network_config=NetworkConfig(enable_network_isolation=False),\n",
    "                                       base_job_name =\"model-packaging\"\n",
    "                                       )\n",
    "\n",
    "sm_local_input_model = \"/opt/ml/processing/input/data/model\"\n",
    "sm_local_input_config_vocab = \"/opt/ml/processing/input/data/config_vocab\"\n",
    "\n",
    "\n",
    "sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "framework_processor.run(\n",
    "        code=f'model_package_bert_utils.py',\n",
    "        source_dir=f'../src/utils',\n",
    "        arguments=[\n",
    "            \"--modeltarfile\", f\"{sm_local_input_model}/model.tar.gz\" ,\n",
    "            \"--modelconfigfile\", f\"{sm_local_input_config_vocab}/config.json\",\n",
    "            \"--vocabfile\",f\"{sm_local_input_config_vocab}/vocab.txt\",\n",
    "            \"--outdir\",sm_local_output\n",
    "          \n",
    "        ],\n",
    "\n",
    "        inputs=[\n",
    "                ProcessingInput(\n",
    "                    source=s3_model_path,\n",
    "                    s3_data_type = \"S3Prefix\",\n",
    "                    destination=sm_local_input_model,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "                ProcessingInput(\n",
    "                        source=s3_model_config_vocab_path,\n",
    "                        destination=sm_local_input_config_vocab,\n",
    "                        s3_data_distribution_type=\"FullyReplicated\")\n",
    "\n",
    "            ],\n",
    "\n",
    "\n",
    "        outputs=[ProcessingOutput(\n",
    "                source=sm_local_output, \n",
    "                destination=s3_model_package_path,\n",
    "                output_name='predictions')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with reverse mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  glue-reverse-mnli-2022-02-19-17-33-44-928\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/models/mnli-reverse-lang-bert-accuracy-2022-01-23-21-29-34-327/output', 'LocalPath': '/opt/ml/processing/input/data/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/gbucket_code/glue-reverse-mnli-2022-02-19-17-33-44-928/source/sourcedir.tar.gz', 'LocalPath': '/opt/ml/processing/input/code/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'entrypoint', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/gbucket_code/glue-reverse-mnli-2022-02-19-17-33-44-928/source/runproc.sh', 'LocalPath': '/opt/ml/processing/input/entrypoint', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'predictions', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://aegovan-data/gluebenchmark_sagemakerresults/mnli-reverse-lang-bert-accuracy-2022-01-23-21-29-34-327/', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "......................................\u001b[34mWARNING: Skipping typing as it is not installed.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting accelerate\n",
      "  Downloading accelerate-0.5.1-py3-none-any.whl (58 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets>=1.8.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.1.96)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (3.19.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.9.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (4.62.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (5.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (1.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.70.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2.26.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2021.10.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (21.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (3.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 5)) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.3->-r requirements.txt (line 7)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.8.0->-r requirements.txt (line 2)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets>=1.8.0->-r requirements.txt (line 2)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2021.10.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (5.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (4.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (21.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: accelerate\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.5.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:23 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:23 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=None,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=True,\u001b[0m\n",
      "\u001b[34mdo_eval=True,\u001b[0m\n",
      "\u001b[34mdo_predict=True,\u001b[0m\n",
      "\u001b[34mdo_train=True,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_steps=200,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34mfp16=False,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=4,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=False,\u001b[0m\n",
      "\u001b[34mgreater_is_better=False,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_strategy=HubStrategy.EVERY_SAVE,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=2e-05,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=True,\u001b[0m\n",
      "\u001b[34mlocal_rank=-1,\u001b[0m\n",
      "\u001b[34mlog_level=-1,\u001b[0m\n",
      "\u001b[34mlog_level_replica=-1,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/opt/ml/processing/output/runs/Feb19_17-40-22_ip-10-0-66-64.us-east-2.compute.internal,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=500,\u001b[0m\n",
      "\u001b[34mlogging_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=SchedulerType.LINEAR,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=1.0,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=loss,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=3.0,\u001b[0m\n",
      "\u001b[34moutput_dir=/opt/ml/processing/output,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=True,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=8,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=8,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=[],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/opt/ml/processing/output,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_steps=200,\u001b[0m\n",
      "\u001b[34msave_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34msave_total_limit=None,\u001b[0m\n",
      "\u001b[34mseed=42,\u001b[0m\n",
      "\u001b[34msharded_ddp=[],\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.0,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.0,\u001b[0m\n",
      "\u001b[34mxpu_backend=None,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:23 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/glue.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp9_yai00w\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/7.78k [00:00<?, ?B/s]#015Downloading: 28.8kB [00:00, 20.0MB/s]                   \u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:23 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/glue.py in cache at /root/.cache/huggingface/datasets/downloads/ebcebc40af3c6b9af1a2f380ea06637ee192bce2d17d528809dd0ee2fa281675.759f3e257a3fad0984d9f8ba9a26479d341795eb50fa64e4c1de40f1fc421313.py\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:23 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/ebcebc40af3c6b9af1a2f380ea06637ee192bce2d17d528809dd0ee2fa281675.759f3e257a3fad0984d9f8ba9a26479d341795eb50fa64e4c1de40f1fc421313.py\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:23 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp9wfv4d92\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/4.47k [00:00<?, ?B/s]#015Downloading: 28.7kB [00:00, 23.1MB/s]                   \u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:23 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/eea1163a0dd089739f6e5e3951d74b1200c7e66d462d607c43cbc8c4e69bbd47.082d8848abcb8cddda90647ec069014ca338abd4f45e0a83c6df1ece0d45476a\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:23 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/eea1163a0dd089739f6e5e3951d74b1200c7e66d462d607c43cbc8c4e69bbd47.082d8848abcb8cddda90647ec069014ca338abd4f45e0a83c6df1ece0d45476a\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:23 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:23 - INFO - datasets.builder - Generating dataset glue (/root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset glue/mnli (download: 298.29 MiB, generated: 78.65 MiB, post-processed: Unknown size, total: 376.95 MiB) to /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:23 - INFO - datasets.builder - Dataset not on Hf google storage. Downloading and preparing it from source\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:24 - INFO - datasets.utils.file_utils - https://dl.fbaipublicfiles.com/glue/data/MNLI.zip not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpitotrkrz\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Downloading:   0%|          | 0.00/313M [00:00<?, ?B/s]#015Downloading:   0%|          | 52.2k/313M [00:00<16:34, 314kB/s]#015Downloading:   0%|          | 296k/313M [00:00<05:10, 1.01MB/s]#015Downloading:   0%|          | 1.25M/313M [00:00<01:37, 3.18MB/s]#015Downloading:   1%|          | 3.40M/313M [00:00<00:37, 8.34MB/s]#015Downloading:   2%|▏         | 6.96M/313M [00:00<00:18, 16.2MB/s]#015Downloading:   4%|▍         | 12.3M/313M [00:00<00:11, 26.9MB/s]#015Downloading:   5%|▌         | 16.1M/313M [00:00<00:10, 29.3MB/s]#015Downloading:   7%|▋         | 21.1M/313M [00:01<00:08, 35.1MB/s]#015Downloading:   8%|▊         | 26.3M/313M [00:01<00:07, 40.3MB/s]#015Downloading:  10%|█         | 31.5M/313M [00:01<00:06, 43.7MB/s]#015Downloading:  12%|█▏        | 36.9M/313M [00:01<00:05, 46.4MB/s]#015Downloading:  13%|█▎        | 41.7M/313M [00:01<00:06, 45.1MB/s]#015Downloading:  15%|█▌        | 47.3M/313M [00:01<00:05, 48.4MB/s]#015Downloading:  17%|█▋        | 52.2M/313M [00:01<00:07, 34.0MB/s]#015Downloading:  19%|█▊        | 58.6M/313M [00:01<00:06, 40.6MB/s]#015Downloading:  21%|██        | 64.9M/313M [00:01<00:05, 46.3MB/s]#015Downloading:  23%|██▎       | 71.4M/313M [00:02<00:04, 51.1MB/s]#015Downloading:  25%|██▌       | 78.3M/313M [00:02<00:04, 55.9MB/s]#015Downloading:  27%|██▋       | 84.9M/313M [00:02<00:03, 58.6MB/s]#015Downloading:  29%|██▉       | 91.0M/313M [00:02<00:03, 57.9MB/s]#015Downloading:  31%|███       | 97.0M/313M [00:02<00:04, 53.4MB/s]#015Downloading:  33%|███▎      | 103M/313M [00:02<00:03, 54.1MB/s] #015Downloading:  35%|███▍      | 108M/313M [00:02<00:04, 51.1MB/s]#015Downloading:  36%|███▋      | 113M/313M [00:02<00:03, 51.4MB/s]#015Downloading:  38%|███▊      | 119M/313M [00:02<00:03, 51.5MB/s]#015Downloading:  40%|███▉      | 124M/313M [00:03<00:03, 51.8MB/s]#015Downloading:  41%|████▏     | 129M/313M [00:03<00:03, 50.2MB/s]#015Downloading:  43%|████▎     | 134M/313M [00:03<00:03, 49.8MB/s]#015Downloading:  45%|████▍     | 140M/313M [00:03<00:03, 51.4MB/s]#015Downloading:  46%|████▋     | 145M/313M [00:03<00:03, 51.7MB/s]#015Downloading:  48%|████▊     | 150M/313M [00:03<00:03, 50.1MB/s]#015Downloading:  50%|████▉     | 155M/313M [00:03<00:03, 50.5MB/s]#015Downloading:  51%|█████▏    | 161M/313M [00:03<00:02, 51.4MB/s]#015Downloading:  53%|█████▎    | 166M/313M [00:03<00:03, 48.7MB/s]#015Downloading:  55%|█████▍    | 171M/313M [00:03<00:02, 49.6MB/s]#015Downloading:  56%|█████▋    | 177M/313M [00:04<00:02, 51.2MB/s]#015Downloading:  58%|█████▊    | 182M/313M [00:04<00:02, 51.4MB/s]#015Downloading:  60%|█████▉    | 187M/313M [00:04<00:02, 51.7MB/s]#015Downloading:  61%|██████▏   | 192M/313M [00:04<00:02, 49.7MB/s]#015Downloading:  63%|██████▎   | 197M/313M [00:04<00:02, 49.2MB/s]#015Downloading:  65%|██████▍   | 203M/313M [00:04<00:02, 50.6MB/s]#015Downloading:  66%|██████▋   | 208M/313M [00:04<00:02, 48.2MB/s]#015Downloading:  68%|██████▊   | 213M/313M [00:04<00:01, 50.6MB/s]#015Downloading:  70%|██████▉   | 219M/313M [00:04<00:01, 50.9MB/s]#015Downloading:  72%|███████▏  | 224M/313M [00:05<00:01, 51.1MB/s]#015Downloading:  73%|███████▎  | 229M/313M [00:05<00:01, 51.5MB/s]#015Downloading:  75%|███████▍  | 234M/313M [00:05<00:01, 49.2MB/s]#015Downloading:  77%|███████▋  | 240M/313M [00:05<00:01, 50.5MB/s]#015Downloading:  78%|███████▊  | 245M/313M [00:05<00:01, 50.4MB/s]#015Downloading:  80%|███████▉  | 250M/313M [00:05<00:01, 51.0MB/s]#015Downloading:  82%|████████▏ | 255M/313M [00:05<00:01, 49.9MB/s]#015Downloading:  83%|████████▎ | 260M/313M [00:05<00:01, 47.6MB/s]#015Downloading:  85%|████████▌ | 266M/313M [00:05<00:00, 51.2MB/s]#015Downloading:  87%|████████▋ | 271M/313M [00:05<00:00, 50.9MB/s]#015Downloading:  88%|████████▊ | 276M/313M [00:06<00:00, 50.3MB/s]#015Downloading:  90%|████████▉ | 281M/313M [00:06<00:00, 49.8MB/s]#015Downloading:  92%|█████████▏| 287M/313M [00:06<00:00, 51.1MB/s]#015Downloading:  93%|█████████▎| 292M/313M [00:06<00:00, 48.3MB/s]#015Downloading:  95%|█████████▌| 297M/313M [00:06<00:00, 50.2MB/s]#015Downloading:  97%|█████████▋| 302M/313M [00:06<00:00, 49.3MB/s]#015Downloading:  98%|█████████▊| 307M/313M [00:06<00:00, 47.8MB/s]#015Downloading: 100%|██████████| 313M/313M [00:06<00:00, 46.0MB/s]\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:31 - INFO - datasets.utils.file_utils - storing https://dl.fbaipublicfiles.com/glue/data/MNLI.zip in cache at /root/.cache/huggingface/datasets/downloads/74d7bc70ada44c1086d1ba81cf6271c128514f629fb8edcd548c113939e3b5f2\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:31 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/74d7bc70ada44c1086d1ba81cf6271c128514f629fb8edcd548c113939e3b5f2\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:31 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:32 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:40 - INFO - datasets.utils.info_utils - All the checksums matched successfully for dataset source files\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:40 - INFO - datasets.builder - Generating split train\u001b[0m\n",
      "\u001b[34m02/19/2022 17:40:59 - INFO - datasets.builder - Generating split validation_matched\u001b[0m\n",
      "\u001b[34m02/19/2022 17:41:00 - INFO - datasets.builder - Generating split validation_mismatched\u001b[0m\n",
      "\u001b[34m02/19/2022 17:41:00 - INFO - datasets.builder - Generating split test_matched\u001b[0m\n",
      "\u001b[34m02/19/2022 17:41:01 - INFO - datasets.builder - Generating split test_mismatched\u001b[0m\n",
      "\u001b[34m02/19/2022 17:41:01 - INFO - datasets.utils.info_utils - All the splits matched successfully.\u001b[0m\n",
      "\u001b[34mDataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m#0150 examples [00:00, ? examples/s]#0151990 examples [00:00, 19897.60 examples/s]#0154115 examples [00:00, 20691.22 examples/s]#0156228 examples [00:00, 20888.20 examples/s]#0158322 examples [00:00, 20907.65 examples/s]#01510413 examples [00:00, 19899.34 examples/s]#01512558 examples [00:00, 20408.69 examples/s]#01514706 examples [00:00, 20750.13 examples/s]#01516835 examples [00:00, 20918.50 examples/s]#01518955 examples [00:00, 21004.06 examples/s]#01521059 examples [00:01, 20313.60 examples/s]#01523207 examples [00:01, 20657.22 examples/s]#01525364 examples [00:01, 20926.70 examples/s]#01527474 examples [00:01, 20971.50 examples/s]#01529603 examples [00:01, 21064.93 examples/s]#01531712 examples [00:01, 17806.08 examples/s]#01533842 examples [00:01, 18732.57 examples/s]#01535982 examples [00:01, 19464.20 examples/s]#01538106 examples [00:01, 19963.22 examples/s]#01540147 examples [00:01, 19677.03 examples/s]#01542270 examples [00:02, 20118.83 examples/s]#01544416 examples [00:02, 20505.95 examples/s]#01546567 examples [00:02, 20797.00 examples/s]#01548688 examples [00:02, 20917.83 examples/s]#01550790 examples [00:02, 20246.11 examples/s]#01552929 examples [00:02, 20577.23 examples/s]#01555085 examples [00:02, 20862.54 examples/s]#01557233 examples [00:02, 21043.34 examples/s]#01559343 examples [00:02, 20706.05 examples/s]#01561419 examples [00:03, 20241.77 examples/s]#01563522 examples [00:03, 20469.06 examples/s]#01565653 examples [00:03, 20715.66 examples/s]#01567788 examples [00:03, 20900.62 examples/s]#01569894 examples [00:03, 20947.67 examples/s]#01571991 examples [00:03, 20363.93 examples/s]#01574148 examples [00:03, 20716.09 examples/s]#01576300 examples [00:03, 20952.63 examples/s]#01578414 examples [00:03, 21005.69 examples/s]#01580517 examples [00:03, 20395.38 examples/s]#01582672 examples [00:04, 20731.82 examples/s]#01584750 examples [00:04, 18078.60 examples/s]#01586868 examples [00:04, 18908.20 examples/s]#01588976 examples [00:04, 19507.02 examples/s]#01590969 examples [00:04, 19144.33 examples/s]#01593103 examples [00:04, 19763.80 examples/s]#01595245 examples [00:04, 20239.79 examples/s]#01597379 examples [00:04, 20558.34 examples/s]#01599496 examples [00:04, 20735.20 examples/s]#015101580 examples [00:05, 20310.40 examples/s]#015103735 examples [00:05, 20669.92 examples/s]#015105879 examples [00:05, 20895.00 examples/s]#015108006 examples [00:05, 21002.84 examples/s]#015110111 examples [00:05, 20440.09 examples/s]#015112248 examples [00:05, 20710.99 examples/s]#015114393 examples [00:05, 20928.00 examples/s]#015116545 examples [00:05, 21102.14 examples/s]#015118681 examples [00:05, 21177.83 examples/s]#015120801 examples [00:05, 20478.92 examples/s]#015122944 examples [00:06, 20753.39 examples/s]#015125069 examples [00:06, 20898.74 examples/s]#015127222 examples [00:06, 21084.76 examples/s]#015129338 examples [00:06, 21106.67 examples/s]#015131451 examples [00:06, 20500.61 examples/s]#015133582 examples [00:06, 20734.63 examples/s]#015135660 examples [00:06, 18172.41 examples/s]#015137794 examples [00:06, 19024.14 examples/s]#015139906 examples [00:06, 19605.67 examples/s]#015141907 examples [00:06, 19453.88 examples/s]#015144062 examples [00:07, 20051.14 examples/s]#015146214 examples [00:07, 20475.68 examples/s]#015148344 examples [00:07, 20715.30 examples/s]#015150429 examples [00:07, 20157.32 examples/s]#015152571 examples [00:07, 20522.33 examples/s]#015154695 examples [00:07, 20731.73 examples/s]#015156842 examples [00:07, 20945.69 examples/s]#015158979 examples [00:07, 21070.22 examples/s]#015161090 examples [00:07, 20103.92 examples/s]#015163217 examples [00:08, 20438.96 examples/s]#015165358 examples [00:08, 20719.62 examples/s]#015167508 examples [00:08, 20946.74 examples/s]#015169633 examples [00:08, 21035.67 examples/s]#015171741 examples [00:08, 20516.00 examples/s]#015173886 examples [00:08, 20788.92 examples/s]#015176026 examples [00:08, 20965.75 examples/s]#015178134 examples [00:08, 20998.72 examples/s]#015180237 examples [00:08, 20235.24 examples/s]#015182382 examples [00:08, 20587.19 examples/s]#015184550 examples [00:09, 20906.29 examples/s]#015186728 examples [00:09, 21161.72 examples/s]#015188849 examples [00:09, 18460.53 examples/s]#015190759 examples [00:09, 18574.38 examples/s]#015192877 examples [00:09, 19295.57 examples/s]#015194993 examples [00:09, 19822.96 examples/s]#015197130 examples [00:09, 20267.15 examples/s]#015199265 examples [00:09, 20579.83 examples/s]#015201340 examples [00:09, 20147.02 examples/s]#015203483 examples [00:09, 20517.67 examples/s]#015205639 examples [00:10, 20820.84 examples/s]#015207783 examples [00:10, 20999.69 examples/s]#015209928 examples [00:10, 21132.42 examples/s]#015212046 examples [00:10, 20608.99 examples/s]#015214184 examples [00:10, 20831.08 examples/s]#015216314 examples [00:10, 20967.35 examples/s]#015218459 examples [00:10, 21108.64 examples/s]#015220573 examples [00:10, 20380.77 examples/s]#015222715 examples [00:10, 20680.90 examples/s]#015224858 examples [00:11, 20899.98 examples/s]#015227001 examples [00:11, 21056.28 examples/s]#015229161 examples [00:11, 21215.57 examples/s]#015231286 examples [00:11, 20576.27 examples/s]#015233435 examples [00:11, 20841.04 examples/s]#015235573 examples [00:11, 20997.27 examples/s]#015237721 examples [00:11, 21137.62 examples/s]#015239882 examples [00:11, 21275.00 examples/s]#015242012 examples [00:11, 20671.38 examples/s]#015244084 examples [00:11, 18151.48 examples/s]#015246222 examples [00:12, 19015.83 examples/s]#015248358 examples [00:12, 19662.32 examples/s]#015250365 examples [00:12, 19270.99 examples/s]#015252517 examples [00:12, 19904.69 examples/s]#015254675 examples [00:12, 20384.17 examples/s]#015256789 examples [00:12, 20601.82 examples/s]#015258949 examples [00:12, 20893.33 examples/s]#015261049 examples [00:12, 20323.15 examples/s]#015263171 examples [00:12, 20580.14 examples/s]#015265308 examples [00:13, 20810.97 examples/s]#015267396 examples [00:13, 20808.92 examples/s]#015269482 examples [00:13, 20754.27 examples/s]#015271561 examples [00:13, 20289.35 examples/s]#015273732 examples [00:13, 20705.17 examples/s]#015275902 examples [00:13, 20995.97 examples/s]#015278043 examples [00:13, 21116.69 examples/s]#015280157 examples [00:13, 20438.97 examples/s]#015282310 examples [00:13, 20754.06 examples/s]#015284460 examples [00:13, 20971.65 examples/s]#015286621 examples [00:14, 21158.32 examples/s]#015288780 examples [00:14, 21284.18 examples/s]#015290911 examples [00:14, 20706.53 examples/s]#015293051 examples [00:14, 20905.78 examples/s]#015295181 examples [00:14, 21019.56 examples/s]#015297286 examples [00:14, 18331.88 examples/s]#015299417 examples [00:14, 19132.41 examples/s]#015301383 examples [00:14, 19085.05 examples/s]#015303531 examples [00:14, 19758.80 examples/s]#015305681 examples [00:14, 20256.86 examples/s]#015307812 examples [00:15, 20562.24 examples/s]#015309936 examples [00:15, 20760.26 examples/s]#015312025 examples [00:15, 20307.10 examples/s]#015314180 examples [00:15, 20667.70 examples/s]#015316343 examples [00:15, 20948.47 examples/s]#015318482 examples [00:15, 21078.79 examples/s]#015320595 examples [00:15, 20253.56 examples/s]#015322727 examples [00:15, 20559.64 examples/s]#015324867 examples [00:15, 20802.30 examples/s]#015327017 examples [00:16, 21006.58 examples/s]#015329173 examples [00:16, 21167.92 examples/s]#015331294 examples [00:16, 20616.91 examples/s]#015333444 examples [00:16, 20872.95 examples/s]#015335575 examples [00:16, 20998.94 examples/s]#015337710 examples [00:16, 21102.22 examples/s]#015339838 examples [00:16, 21153.05 examples/s]#015341956 examples [00:16, 20482.89 examples/s]#015344110 examples [00:16, 20790.01 examples/s]#015346262 examples [00:16, 21002.21 examples/s]#015348419 examples [00:17, 21167.29 examples/s]#015350539 examples [00:17, 17080.84 examples/s]#015352690 examples [00:17, 18209.03 examples/s]#015354621 examples [00:17, 17454.42 examples/s]#015356445 examples [00:17, 14723.95 examples/s]#015358137 examples [00:17, 15249.24 examples/s]#015359757 examples [00:17, 14987.46 examples/s]#015361620 examples [00:17, 15935.99 examples/s]#015363739 examples [00:18, 17359.83 examples/s]#015365873 examples [00:18, 18468.32 examples/s]#015368005 examples [00:18, 19280.47 examples/s]#015370000 examples [00:18, 19293.70 examples/s]#015372155 examples [00:18, 19946.37 examples/s]#015374273 examples [00:18, 20305.78 examples/s]#015376404 examples [00:18, 20601.51 examples/s]#015378538 examples [00:18, 20819.13 examples/s]#015380628 examples [00:18, 20249.95 examples/s]#015382778 examples [00:18, 20613.88 examples/s]#015384919 examples [00:19, 20847.33 examples/s]#015387077 examples [00:19, 21063.95 examples/s]#015389218 examples [00:19, 21164.03 examples/s]#015391338 examples [00:19, 20545.67 examples/s]#015                                            #015#0150 examples [00:00, ? examples/s]#0152024 examples [00:00, 20232.78 examples/s]#0154123 examples [00:00, 20676.32 examples/s]#0156246 examples [00:00, 20925.00 examples/s]#0158360 examples [00:00, 21005.94 examples/s]#015                                          #015#0150 examples [00:00, ? examples/s]#0152005 examples [00:00, 20045.53 examples/s]#0154101 examples [00:00, 20575.39 examples/s]#0156201 examples [00:00, 20766.91 examples/s]#0158288 examples [00:00, 20804.10 examples/s]#015                                          #015#0150 examples [00:00, ? examples/s]#0152212 examples [00:00, 22104.37 examples/s]#0154533 examples [00:00, 22750.61 examples/s]#0156860 examples [00:00, 22985.22 examples/s]#0159177 examples [00:00, 23055.34 examples/s]#015                                          #015#0150 examples [00:00, ? examples/s]#0152204 examples [00:00, 22030.57 examples/s]#0154527 examples [00:00, 22733.93 examples/s]#0156865 examples [00:00, 23025.22 examples/s]#0159171 examples [00:00, 23036.34 examples/s]#015                                          #015#015  0%|          | 0/5 [00:00<?, ?it/s]#015100%|██████████| 5/5 [00:00<00:00, 776.46it/s]\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:586] 2022-02-19 17:41:01,719 >> loading configuration file /opt/ml/processing/input/data/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:625] 2022-02-19 17:41:01,720 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_auto.py:341] 2022-02-19 17:41:01,721 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:586] 2022-02-19 17:41:01,721 >> loading configuration file /opt/ml/processing/input/data/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:625] 2022-02-19 17:41:01,722 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1671] 2022-02-19 17:41:01,722 >> Didn't find file /opt/ml/processing/input/data/model/tokenizer.json. We won't load it.\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1671] 2022-02-19 17:41:01,722 >> Didn't find file /opt/ml/processing/input/data/model/added_tokens.json. We won't load it.\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1671] 2022-02-19 17:41:01,722 >> Didn't find file /opt/ml/processing/input/data/model/special_tokens_map.json. We won't load it.\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1671] 2022-02-19 17:41:01,722 >> Didn't find file /opt/ml/processing/input/data/model/tokenizer_config.json. We won't load it.\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1740] 2022-02-19 17:41:01,722 >> loading file /opt/ml/processing/input/data/model/vocab.txt\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1740] 2022-02-19 17:41:01,722 >> loading file None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1740] 2022-02-19 17:41:01,723 >> loading file None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1740] 2022-02-19 17:41:01,723 >> loading file None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1740] 2022-02-19 17:41:01,723 >> loading file None\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:586] 2022-02-19 17:41:01,723 >> loading configuration file /opt/ml/processing/input/data/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:625] 2022-02-19 17:41:01,724 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:586] 2022-02-19 17:41:01,749 >> loading configuration file /opt/ml/processing/input/data/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:625] 2022-02-19 17:41:01,750 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1338] 2022-02-19 17:41:01,792 >> loading weights file /opt/ml/processing/input/data/model/pytorch_model.bin\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[INFO|modeling_utils.py:1607] 2022-02-19 17:41:04,429 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:1609] 2022-02-19 17:41:04,430 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /opt/ml/processing/input/data/model and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m02/19/2022 17:41:04 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-89e6c98322b0322d.arrow\u001b[0m\n",
      "\u001b[34m#015Running tokenizer on dataset:   0%|          | 0/393 [00:00<?, ?ba/s]#015Running tokenizer on dataset:   0%|          | 1/393 [00:00<02:45,  2.36ba/s]#015Running tokenizer on dataset:   1%|          | 2/393 [00:00<01:46,  3.66ba/s]#015Running tokenizer on dataset:   1%|          | 3/393 [00:00<01:43,  3.78ba/s]#015Running tokenizer on dataset:   1%|          | 4/393 [00:01<01:28,  4.39ba/s]#015Running tokenizer on dataset:   1%|▏         | 5/393 [00:01<01:20,  4.82ba/s]#015Running tokenizer on dataset:   2%|▏         | 6/393 [00:01<01:14,  5.17ba/s]#015Running tokenizer on dataset:   2%|▏         | 7/393 [00:01<01:11,  5.43ba/s]#015Running tokenizer on dataset:   2%|▏         | 8/393 [00:01<01:08,  5.60ba/s]#015Running tokenizer on dataset:   2%|▏         | 9/393 [00:01<01:07,  5.68ba/s]#015Running tokenizer on dataset:   3%|▎         | 10/393 [00:02<01:06,  5.76ba/s]#015Running tokenizer on dataset:   3%|▎         | 11/393 [00:02<01:05,  5.81ba/s]#015Running tokenizer on dataset:   3%|▎         | 12/393 [00:02<01:05,  5.85ba/s]#015Running tokenizer on dataset:   3%|▎         | 13/393 [00:02<01:04,  5.87ba/s]#015Running tokenizer on dataset:   4%|▎         | 14/393 [00:02<01:04,  5.89ba/s]#015Running tokenizer on dataset:   4%|▍         | 15/393 [00:02<01:13,  5.18ba/s]#015Running tokenizer on dataset:   4%|▍         | 16/393 [00:03<01:10,  5.34ba/s]#015Running tokenizer on dataset:   4%|▍         | 17/393 [00:03<01:07,  5.54ba/s]#015Running tokenizer on dataset:   5%|▍         | 18/393 [00:03<01:05,  5.71ba/s]#015Running tokenizer on dataset:   5%|▍         | 19/393 [00:03<01:08,  5.43ba/s]#015Running tokenizer on dataset:   5%|▌         | 20/393 [00:04<01:35,  3.91ba/s]#015Running tokenizer on dataset:   5%|▌         | 21/393 [00:04<01:25,  4.33ba/s]#015Running tokenizer on dataset:   6%|▌         | 22/393 [00:04<01:18,  4.70ba/s]#015Running tokenizer on dataset:   6%|▌         | 23/393 [00:04<01:15,  4.89ba/s]#015Running tokenizer on dataset:   6%|▌         | 24/393 [00:04<01:13,  5.02ba/s]#015Running tokenizer on dataset:   6%|▋         | 25/393 [00:04<01:12,  5.07ba/s]#015Running tokenizer on dataset:   7%|▋         | 26/393 [00:05<01:11,  5.12ba/s]#015Running tokenizer on dataset:   7%|▋         | 27/393 [00:05<01:19,  4.59ba/s]#015Running tokenizer on dataset:   7%|▋         | 28/393 [00:05<01:15,  4.82ba/s]#015Running tokenizer on dataset:   7%|▋         | 29/393 [00:05<01:12,  4.99ba/s]#015Running tokenizer on dataset:   8%|▊         | 30/393 [00:05<01:10,  5.14ba/s]#015Running tokenizer on dataset:   8%|▊         | 31/393 [00:06<01:09,  5.21ba/s]#015Running tokenizer on dataset:   8%|▊         | 32/393 [00:08<05:30,  1.09ba/s]#015Running tokenizer on dataset:   8%|▊         | 33/393 [00:08<04:09,  1.44ba/s]#015Running tokenizer on dataset:   9%|▊         | 34/393 [00:09<03:12,  1.86ba/s]#015Running tokenizer on dataset:   9%|▉         | 35/393 [00:09<02:33,  2.34ba/s]#015Running tokenizer on dataset:   9%|▉         | 36/393 [00:09<02:05,  2.85ba/s]#015Running tokenizer on dataset:   9%|▉         | 37/393 [00:09<01:45,  3.38ba/s]#015Running tokenizer on dataset:  10%|▉         | 38/393 [00:09<01:31,  3.87ba/s]#015Running tokenizer on dataset:  10%|▉         | 39/393 [00:09<01:22,  4.29ba/s]#015Running tokenizer on dataset:  10%|█         | 40/393 [00:10<01:20,  4.38ba/s]#015Running tokenizer on dataset:  10%|█         | 41/393 [00:10<01:13,  4.78ba/s]#015Running tokenizer on dataset:  11%|█         | 42/393 [00:10<01:09,  5.08ba/s]#015Running tokenizer on dataset:  11%|█         | 43/393 [00:10<01:05,  5.32ba/s]#015Running tokenizer on dataset:  11%|█         | 44/393 [00:10<01:03,  5.51ba/s]#015Running tokenizer on dataset:  11%|█▏        | 45/393 [00:11<01:01,  5.63ba/s]#015Running tokenizer on dataset:  12%|█▏        | 46/393 [00:11<01:00,  5.71ba/s]#015Running tokenizer on dataset:  12%|█▏        | 47/393 [00:11<01:00,  5.76ba/s]#015Running tokenizer on dataset:  12%|█▏        | 48/393 [00:11<00:59,  5.80ba/s]#015Running tokenizer on dataset:  12%|█▏        | 49/393 [00:11<00:59,  5.80ba/s]#015Running tokenizer on dataset:  13%|█▎        | 50/393 [00:11<00:58,  5.82ba/s]#015Running tokenizer on dataset:  13%|█▎        | 51/393 [00:12<00:59,  5.80ba/s]#015Running tokenizer on dataset:  13%|█▎        | 52/393 [00:12<01:03,  5.38ba/s]#015Running tokenizer on dataset:  13%|█▎        | 53/393 [00:12<01:01,  5.57ba/s]#015Running tokenizer on dataset:  14%|█▎        | 54/393 [00:12<00:59,  5.70ba/s]#015Running tokenizer on dataset:  14%|█▍        | 55/393 [00:12<00:58,  5.79ba/s]#015Running tokenizer on dataset:  14%|█▍        | 56/393 [00:12<00:57,  5.82ba/s]#015Running tokenizer on dataset:  15%|█▍        | 57/393 [00:13<00:57,  5.85ba/s]#015Running tokenizer on dataset:  15%|█▍        | 58/393 [00:13<00:56,  5.89ba/s]#015Running tokenizer on dataset:  15%|█▌        | 59/393 [00:13<00:56,  5.88ba/s]#015Running tokenizer on dataset:  15%|█▌        | 60/393 [00:13<00:56,  5.87ba/s]#015Running tokenizer on dataset:  16%|█▌        | 61/393 [00:13<00:56,  5.88ba/s]#015Running tokenizer on dataset:  16%|█▌        | 62/393 [00:13<00:56,  5.85ba/s]#015Running tokenizer on dataset:  16%|█▌        | 63/393 [00:14<00:56,  5.79ba/s]#015Running tokenizer on dataset:  16%|█▋        | 64/393 [00:14<01:01,  5.37ba/s]#015Running tokenizer on dataset:  17%|█▋        | 65/393 [00:14<00:58,  5.56ba/s]#015Running tokenizer on dataset:  17%|█▋        | 66/393 [00:14<00:57,  5.69ba/s]#015Running tokenizer on dataset:  17%|█▋        | 67/393 [00:14<00:56,  5.75ba/s]#015Running tokenizer on dataset:  17%|█▋        | 68/393 [00:15<00:55,  5.80ba/s]#015Running tokenizer on dataset:  18%|█▊        | 69/393 [00:15<00:55,  5.86ba/s]#015Running tokenizer on dataset:  18%|█▊        | 70/393 [00:15<00:54,  5.90ba/s]#015Running tokenizer on dataset:  18%|█▊        | 71/393 [00:15<00:54,  5.90ba/s]#015Running tokenizer on dataset:  18%|█▊        | 72/393 [00:15<00:54,  5.92ba/s]#015Running tokenizer on dataset:  19%|█▊        | 73/393 [00:15<00:54,  5.90ba/s]#015Running tokenizer on dataset:  19%|█▉        | 74/393 [00:16<00:54,  5.85ba/s]#015Running tokenizer on dataset:  19%|█▉        | 75/393 [00:16<00:54,  5.82ba/s]#015Running tokenizer on dataset:  19%|█▉        | 76/393 [00:16<00:59,  5.36ba/s]#015Running tokenizer on dataset:  20%|█▉        | 77/393 [00:16<00:56,  5.55ba/s]#015Running tokenizer on dataset:  20%|█▉        | 78/393 [00:16<00:55,  5.68ba/s]#015Running tokenizer on dataset:  20%|██        | 79/393 [00:16<00:54,  5.73ba/s]#015Running tokenizer on dataset:  20%|██        | 80/393 [00:17<00:53,  5.81ba/s]#015Running tokenizer on dataset:  21%|██        | 81/393 [00:17<00:53,  5.85ba/s]#015Running tokenizer on dataset:  21%|██        | 82/393 [00:17<00:52,  5.87ba/s]#015Running tokenizer on dataset:  21%|██        | 83/393 [00:17<00:52,  5.87ba/s]#015Running tokenizer on dataset:  21%|██▏       | 84/393 [00:17<00:52,  5.90ba/s]#015Running tokenizer on dataset:  22%|██▏       | 85/393 [00:17<00:52,  5.86ba/s]#015Running tokenizer on dataset:  22%|██▏       | 86/393 [00:18<00:53,  5.77ba/s]#015Running tokenizer on dataset:  22%|██▏       | 87/393 [00:18<00:53,  5.76ba/s]#015Running tokenizer on dataset:  22%|██▏       | 88/393 [00:18<00:57,  5.35ba/s]#015Running tokenizer on dataset:  23%|██▎       | 89/393 [00:18<00:54,  5.53ba/s]#015Running tokenizer on dataset:  23%|██▎       | 90/393 [00:18<00:53,  5.67ba/s]#015Running tokenizer on dataset:  23%|██▎       | 91/393 [00:19<00:52,  5.70ba/s]#015Running tokenizer on dataset:  23%|██▎       | 92/393 [00:19<00:52,  5.77ba/s]#015Running tokenizer on dataset:  24%|██▎       | 93/393 [00:19<00:51,  5.82ba/s]#015Running tokenizer on dataset:  24%|██▍       | 94/393 [00:19<00:50,  5.87ba/s]#015Running tokenizer on dataset:  24%|██▍       | 95/393 [00:19<00:51,  5.83ba/s]#015Running tokenizer on dataset:  24%|██▍       | 96/393 [00:19<00:50,  5.84ba/s]#015Running tokenizer on dataset:  25%|██▍       | 97/393 [00:20<00:50,  5.87ba/s]#015Running tokenizer on dataset:  25%|██▍       | 98/393 [00:20<00:50,  5.86ba/s]#015Running tokenizer on dataset:  25%|██▌       | 99/393 [00:20<00:50,  5.82ba/s]#015Running tokenizer on dataset:  25%|██▌       | 100/393 [00:20<00:54,  5.38ba/s]#015Running tokenizer on dataset:  26%|██▌       | 101/393 [00:20<00:52,  5.58ba/s]#015Running tokenizer on dataset:  26%|██▌       | 102/393 [00:20<00:50,  5.74ba/s]#015Running tokenizer on dataset:  26%|██▌       | 103/393 [00:21<00:50,  5.75ba/s]#015Running tokenizer on dataset:  26%|██▋       | 104/393 [00:21<00:49,  5.83ba/s]#015Running tokenizer on dataset:  27%|██▋       | 105/393 [00:21<00:49,  5.87ba/s]#015Running tokenizer on dataset:  27%|██▋       | 106/393 [00:21<00:48,  5.90ba/s]#015Running tokenizer on dataset:  27%|██▋       | 107/393 [00:21<00:48,  5.84ba/s]#015Running tokenizer on dataset:  27%|██▋       | 108/393 [00:21<00:48,  5.85ba/s]#015Running tokenizer on dataset:  28%|██▊       | 109/393 [00:22<00:48,  5.85ba/s]#015Running tokenizer on dataset:  28%|██▊       | 110/393 [00:22<00:48,  5.87ba/s]#015Running tokenizer on dataset:  28%|██▊       | 111/393 [00:22<00:48,  5.87ba/s]#015Running tokenizer on dataset:  28%|██▊       | 112/393 [00:22<00:51,  5.41ba/s]#015Running tokenizer on dataset:  29%|██▉       | 113/393 [00:22<00:50,  5.59ba/s]#015Running tokenizer on dataset:  29%|██▉       | 114/393 [00:23<00:48,  5.73ba/s]#015Running tokenizer on dataset:  29%|██▉       | 115/393 [00:23<00:48,  5.77ba/s]#015Running tokenizer on dataset:  30%|██▉       | 116/393 [00:23<00:47,  5.82ba/s]#015Running tokenizer on dataset:  30%|██▉       | 117/393 [00:23<00:47,  5.84ba/s]#015Running tokenizer on dataset:  30%|███       | 118/393 [00:23<00:46,  5.88ba/s]#015Running tokenizer on dataset:  30%|███       | 119/393 [00:23<00:46,  5.88ba/s]#015Running tokenizer on dataset:  31%|███       | 120/393 [00:24<00:46,  5.88ba/s]#015Running tokenizer on dataset:  31%|███       | 121/393 [00:24<00:46,  5.87ba/s]#015Running tokenizer on dataset:  31%|███       | 122/393 [00:24<00:46,  5.88ba/s]#015Running tokenizer on dataset:  31%|███▏      | 123/393 [00:24<00:46,  5.86ba/s]#015Running tokenizer on dataset:  32%|███▏      | 124/393 [00:24<00:49,  5.43ba/s]#015Running tokenizer on dataset:  32%|███▏      | 125/393 [00:24<00:47,  5.61ba/s]#015Running tokenizer on dataset:  32%|███▏      | 126/393 [00:25<00:46,  5.74ba/s]#015Running tokenizer on dataset:  32%|███▏      | 127/393 [00:25<00:45,  5.81ba/s]#015Running tokenizer on dataset:  33%|███▎      | 128/393 [00:25<00:45,  5.86ba/s]#015Running tokenizer on dataset:  33%|███▎      | 129/393 [00:25<00:44,  5.87ba/s]#015Running tokenizer on dataset:  33%|███▎      | 130/393 [00:25<00:44,  5.92ba/s]#015Running tokenizer on dataset:  33%|███▎      | 131/393 [00:25<00:44,  5.90ba/s]#015Running tokenizer on dataset:  34%|███▎      | 132/393 [00:26<00:44,  5.82ba/s]#015Running tokenizer on dataset:  34%|███▍      | 133/393 [00:26<00:44,  5.82ba/s]#015Running tokenizer on dataset:  34%|███▍      | 134/393 [00:26<00:44,  5.83ba/s]#015Running tokenizer on dataset:  34%|███▍      | 135/393 [00:26<00:44,  5.86ba/s]#015Running tokenizer on dataset:  35%|███▍      | 136/393 [00:26<00:47,  5.39ba/s]#015Running tokenizer on dataset:  35%|███▍      | 137/393 [00:27<00:45,  5.59ba/s]#015Running tokenizer on dataset:  35%|███▌      | 138/393 [00:27<00:44,  5.72ba/s]#015Running tokenizer on dataset:  35%|███▌      | 139/393 [00:27<00:43,  5.80ba/s]#015Running tokenizer on dataset:  36%|███▌      | 140/393 [00:27<00:43,  5.80ba/s]#015Running tokenizer on dataset:  36%|███▌      | 141/393 [00:27<00:43,  5.82ba/s]#015Running tokenizer on dataset:  36%|███▌      | 142/393 [00:27<00:42,  5.86ba/s]#015Running tokenizer on dataset:  36%|███▋      | 143/393 [00:28<00:42,  5.87ba/s]#015Running tokenizer on dataset:  37%|███▋      | 144/393 [00:28<00:42,  5.84ba/s]#015Running tokenizer on dataset:  37%|███▋      | 145/393 [00:28<00:42,  5.83ba/s]#015Running tokenizer on dataset:  37%|███▋      | 146/393 [00:28<00:42,  5.82ba/s]#015Running tokenizer on dataset:  37%|███▋      | 147/393 [00:28<00:42,  5.83ba/s]#015Running tokenizer on dataset:  38%|███▊      | 148/393 [00:28<00:45,  5.34ba/s]#015Running tokenizer on dataset:  38%|███▊      | 149/393 [00:29<00:44,  5.52ba/s]#015Running tokenizer on dataset:  38%|███▊      | 150/393 [00:29<00:42,  5.67ba/s]#015Running tokenizer on dataset:  38%|███▊      | 151/393 [00:29<00:42,  5.73ba/s]#015Running tokenizer on dataset:  39%|███▊      | 152/393 [00:29<00:41,  5.78ba/s]#015Running tokenizer on dataset:  39%|███▉      | 153/393 [00:29<00:40,  5.86ba/s]#015Running tokenizer on dataset:  39%|███▉      | 154/393 [00:29<00:40,  5.89ba/s]#015Running tokenizer on dataset:  39%|███▉      | 155/393 [00:30<00:40,  5.89ba/s]#015Running tokenizer on dataset:  40%|███▉      | 156/393 [00:30<00:40,  5.88ba/s]#015Running tokenizer on dataset:  40%|███▉      | 157/393 [00:30<00:40,  5.87ba/s]#015Running tokenizer on dataset:  40%|████      | 158/393 [00:30<00:40,  5.85ba/s]#015Running tokenizer on dataset:  40%|████      | 159/393 [00:30<00:40,  5.84ba/s]#015Running tokenizer on dataset:  41%|████      | 160/393 [00:31<00:43,  5.35ba/s]#015Running tokenizer on dataset:  41%|████      | 161/393 [00:31<00:41,  5.56ba/s]#015Running tokenizer on dataset:  41%|████      | 162/393 [00:31<00:40,  5.67ba/s]#015Running tokenizer on dataset:  41%|████▏     | 163/393 [00:31<00:39,  5.77ba/s]#015Running tokenizer on dataset:  42%|████▏     | 164/393 [00:31<00:39,  5.80ba/s]#015Running tokenizer on dataset:  42%|████▏     | 165/393 [00:31<00:39,  5.83ba/s]#015Running tokenizer on dataset:  42%|████▏     | 166/393 [00:32<00:38,  5.89ba/s]#015Running tokenizer on dataset:  42%|████▏     | 167/393 [00:32<00:38,  5.87ba/s]#015Running tokenizer on dataset:  43%|████▎     | 168/393 [00:32<00:38,  5.88ba/s]#015Running tokenizer on dataset:  43%|████▎     | 169/393 [00:32<00:38,  5.89ba/s]#015Running tokenizer on dataset:  43%|████▎     | 170/393 [00:32<00:37,  5.88ba/s]#015Running tokenizer on dataset:  44%|████▎     | 171/393 [00:32<00:37,  5.90ba/s]#015Running tokenizer on dataset:  44%|████▍     | 172/393 [00:33<00:42,  5.20ba/s]#015Running tokenizer on dataset:  44%|████▍     | 173/393 [00:33<00:40,  5.43ba/s]#015Running tokenizer on dataset:  44%|████▍     | 174/393 [00:33<00:39,  5.59ba/s]#015Running tokenizer on dataset:  45%|████▍     | 175/393 [00:33<00:38,  5.72ba/s]#015Running tokenizer on dataset:  45%|████▍     | 176/393 [00:33<00:37,  5.77ba/s]#015Running tokenizer on dataset:  45%|████▌     | 177/393 [00:33<00:37,  5.82ba/s]#015Running tokenizer on dataset:  45%|████▌     | 178/393 [00:34<00:36,  5.86ba/s]#015Running tokenizer on dataset:  46%|████▌     | 179/393 [00:34<00:36,  5.86ba/s]#015Running tokenizer on dataset:  46%|████▌     | 180/393 [00:34<00:36,  5.81ba/s]#015Running tokenizer on dataset:  46%|████▌     | 181/393 [00:34<00:40,  5.23ba/s]#015Running tokenizer on dataset:  46%|████▋     | 182/393 [00:34<00:39,  5.36ba/s]#015Running tokenizer on dataset:  47%|████▋     | 183/393 [00:35<00:38,  5.45ba/s]#015Running tokenizer on dataset:  47%|████▋     | 184/393 [00:35<00:40,  5.11ba/s]#015Running tokenizer on dataset:  47%|████▋     | 185/393 [00:35<00:38,  5.36ba/s]#015Running tokenizer on dataset:  47%|████▋     | 186/393 [00:35<00:37,  5.50ba/s]#015Running tokenizer on dataset:  48%|████▊     | 187/393 [00:35<00:36,  5.63ba/s]#015Running tokenizer on dataset:  48%|████▊     | 188/393 [00:35<00:36,  5.69ba/s]#015Running tokenizer on dataset:  48%|████▊     | 189/393 [00:36<00:35,  5.76ba/s]#015Running tokenizer on dataset:  48%|████▊     | 190/393 [00:36<00:35,  5.78ba/s]#015Running tokenizer on dataset:  49%|████▊     | 191/393 [00:36<00:34,  5.83ba/s]#015Running tokenizer on dataset:  49%|████▉     | 192/\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m393 [00:36<00:34,  5.80ba/s]#015Running tokenizer on dataset:  49%|████▉     | 193/393 [00:36<00:34,  5.82ba/s]#015Running tokenizer on dataset:  49%|████▉     | 194/393 [00:36<00:34,  5.84ba/s]#015Running tokenizer on dataset:  50%|████▉     | 195/393 [00:37<00:34,  5.80ba/s]#015Running tokenizer on dataset:  50%|████▉     | 196/393 [00:37<00:36,  5.37ba/s]#015Running tokenizer on dataset:  50%|█████     | 197/393 [00:37<00:35,  5.57ba/s]#015Running tokenizer on dataset:  50%|█████     | 198/393 [00:37<00:34,  5.71ba/s]#015Running tokenizer on dataset:  51%|█████     | 199/393 [00:37<00:33,  5.78ba/s]#015Running tokenizer on dataset:  51%|█████     | 200/393 [00:38<00:33,  5.82ba/s]#015Running tokenizer on dataset:  51%|█████     | 201/393 [00:38<00:32,  5.84ba/s]#015Running tokenizer on dataset:  51%|█████▏    | 202/393 [00:38<00:32,  5.87ba/s]#015Running tokenizer on dataset:  52%|█████▏    | 203/393 [00:38<00:32,  5.86ba/s]#015Running tokenizer on dataset:  52%|█████▏    | 204/393 [00:38<00:32,  5.87ba/s]#015Running tokenizer on dataset:  52%|█████▏    | 205/393 [00:38<00:32,  5.87ba/s]#015Running tokenizer on dataset:  52%|█████▏    | 206/393 [00:39<00:32,  5.84ba/s]#015Running tokenizer on dataset:  53%|█████▎    | 207/393 [00:39<00:31,  5.82ba/s]#015Running tokenizer on dataset:  53%|█████▎    | 208/393 [00:39<00:34,  5.33ba/s]#015Running tokenizer on dataset:  53%|█████▎    | 209/393 [00:39<00:33,  5.53ba/s]#015Running tokenizer on dataset:  53%|█████▎    | 210/393 [00:39<00:32,  5.70ba/s]#015Running tokenizer on dataset:  54%|█████▎    | 211/393 [00:39<00:31,  5.75ba/s]#015Running tokenizer on dataset:  54%|█████▍    | 212/393 [00:40<00:30,  5.84ba/s]#015Running tokenizer on dataset:  54%|█████▍    | 213/393 [00:40<00:30,  5.89ba/s]#015Running tokenizer on dataset:  54%|█████▍    | 214/393 [00:40<00:30,  5.90ba/s]#015Running tokenizer on dataset:  55%|█████▍    | 215/393 [00:40<00:30,  5.89ba/s]#015Running tokenizer on dataset:  55%|█████▍    | 216/393 [00:40<00:30,  5.88ba/s]#015Running tokenizer on dataset:  55%|█████▌    | 217/393 [00:40<00:29,  5.87ba/s]#015Running tokenizer on dataset:  55%|█████▌    | 218/393 [00:41<00:29,  5.87ba/s]#015Running tokenizer on dataset:  56%|█████▌    | 219/393 [00:41<00:29,  5.83ba/s]#015Running tokenizer on dataset:  56%|█████▌    | 220/393 [00:41<00:32,  5.39ba/s]#015Running tokenizer on dataset:  56%|█████▌    | 221/393 [00:41<00:30,  5.56ba/s]#015Running tokenizer on dataset:  56%|█████▋    | 222/393 [00:41<00:29,  5.71ba/s]#015Running tokenizer on dataset:  57%|█████▋    | 223/393 [00:42<00:29,  5.76ba/s]#015Running tokenizer on dataset:  57%|█████▋    | 224/393 [00:42<00:29,  5.81ba/s]#015Running tokenizer on dataset:  57%|█████▋    | 225/393 [00:42<00:28,  5.86ba/s]#015Running tokenizer on dataset:  58%|█████▊    | 226/393 [00:42<00:28,  5.88ba/s]#015Running tokenizer on dataset:  58%|█████▊    | 227/393 [00:42<00:28,  5.87ba/s]#015Running tokenizer on dataset:  58%|█████▊    | 228/393 [00:42<00:28,  5.86ba/s]#015Running tokenizer on dataset:  58%|█████▊    | 229/393 [00:43<00:28,  5.85ba/s]#015Running tokenizer on dataset:  59%|█████▊    | 230/393 [00:43<00:28,  5.82ba/s]#015Running tokenizer on dataset:  59%|█████▉    | 231/393 [00:43<00:27,  5.81ba/s]#015Running tokenizer on dataset:  59%|█████▉    | 232/393 [00:43<00:30,  5.36ba/s]#015Running tokenizer on dataset:  59%|█████▉    | 233/393 [00:43<00:28,  5.54ba/s]#015Running tokenizer on dataset:  60%|█████▉    | 234/393 [00:43<00:28,  5.68ba/s]#015Running tokenizer on dataset:  60%|█████▉    | 235/393 [00:44<00:27,  5.77ba/s]#015Running tokenizer on dataset:  60%|██████    | 236/393 [00:44<00:27,  5.81ba/s]#015Running tokenizer on dataset:  60%|██████    | 237/393 [00:44<00:26,  5.83ba/s]#015Running tokenizer on dataset:  61%|██████    | 238/393 [00:44<00:26,  5.86ba/s]#015Running tokenizer on dataset:  61%|██████    | 239/393 [00:44<00:26,  5.86ba/s]#015Running tokenizer on dataset:  61%|██████    | 240/393 [00:44<00:26,  5.87ba/s]#015Running tokenizer on dataset:  61%|██████▏   | 241/393 [00:45<00:25,  5.87ba/s]#015Running tokenizer on dataset:  62%|██████▏   | 242/393 [00:45<00:25,  5.87ba/s]#015Running tokenizer on dataset:  62%|██████▏   | 243/393 [00:45<00:25,  5.86ba/s]#015Running tokenizer on dataset:  62%|██████▏   | 244/393 [00:45<00:27,  5.42ba/s]#015Running tokenizer on dataset:  62%|██████▏   | 245/393 [00:45<00:26,  5.58ba/s]#015Running tokenizer on dataset:  63%|██████▎   | 246/393 [00:46<00:25,  5.68ba/s]#015Running tokenizer on dataset:  63%|██████▎   | 247/393 [00:46<00:25,  5.76ba/s]#015Running tokenizer on dataset:  63%|██████▎   | 248/393 [00:46<00:24,  5.81ba/s]#015Running tokenizer on dataset:  63%|██████▎   | 249/393 [00:46<00:24,  5.84ba/s]#015Running tokenizer on dataset:  64%|██████▎   | 250/393 [00:46<00:24,  5.88ba/s]#015Running tokenizer on dataset:  64%|██████▍   | 251/393 [00:46<00:24,  5.86ba/s]#015Running tokenizer on dataset:  64%|██████▍   | 252/393 [00:47<00:24,  5.86ba/s]#015Running tokenizer on dataset:  64%|██████▍   | 253/393 [00:47<00:24,  5.83ba/s]#015Running tokenizer on dataset:  65%|██████▍   | 254/393 [00:47<00:23,  5.85ba/s]#015Running tokenizer on dataset:  65%|██████▍   | 255/393 [00:47<00:23,  5.86ba/s]#015Running tokenizer on dataset:  65%|██████▌   | 256/393 [00:47<00:25,  5.40ba/s]#015Running tokenizer on dataset:  65%|██████▌   | 257/393 [00:47<00:24,  5.59ba/s]#015Running tokenizer on dataset:  66%|██████▌   | 258/393 [00:48<00:23,  5.72ba/s]#015Running tokenizer on dataset:  66%|██████▌   | 259/393 [00:48<00:23,  5.79ba/s]#015Running tokenizer on dataset:  66%|██████▌   | 260/393 [00:48<00:22,  5.81ba/s]#015Running tokenizer on dataset:  66%|██████▋   | 261/393 [00:48<00:22,  5.86ba/s]#015Running tokenizer on dataset:  67%|██████▋   | 262/393 [00:48<00:22,  5.89ba/s]#015Running tokenizer on dataset:  67%|██████▋   | 263/393 [00:48<00:22,  5.90ba/s]#015Running tokenizer on dataset:  67%|██████▋   | 264/393 [00:49<00:21,  5.87ba/s]#015Running tokenizer on dataset:  67%|██████▋   | 265/393 [00:49<00:21,  5.90ba/s]#015Running tokenizer on dataset:  68%|██████▊   | 266/393 [00:49<00:21,  5.90ba/s]#015Running tokenizer on dataset:  68%|██████▊   | 267/393 [00:49<00:21,  5.88ba/s]#015Running tokenizer on dataset:  68%|██████▊   | 268/393 [00:49<00:22,  5.44ba/s]#015Running tokenizer on dataset:  68%|██████▊   | 269/393 [00:50<00:22,  5.61ba/s]#015Running tokenizer on dataset:  69%|██████▊   | 270/393 [00:50<00:21,  5.73ba/s]#015Running tokenizer on dataset:  69%|██████▉   | 271/393 [00:50<00:21,  5.81ba/s]#015Running tokenizer on dataset:  69%|██████▉   | 272/393 [00:50<00:20,  5.87ba/s]#015Running tokenizer on dataset:  69%|██████▉   | 273/393 [00:50<00:20,  5.91ba/s]#015Running tokenizer on dataset:  70%|██████▉   | 274/393 [00:50<00:20,  5.93ba/s]#015Running tokenizer on dataset:  70%|██████▉   | 275/393 [00:51<00:19,  5.93ba/s]#015Running tokenizer on dataset:  70%|███████   | 276/393 [00:51<00:19,  5.88ba/s]#015Running tokenizer on dataset:  70%|███████   | 277/393 [00:51<00:19,  5.90ba/s]#015Running tokenizer on dataset:  71%|███████   | 278/393 [00:51<00:19,  5.90ba/s]#015Running tokenizer on dataset:  71%|███████   | 279/393 [00:51<00:19,  5.86ba/s]#015Running tokenizer on dataset:  71%|███████   | 280/393 [00:51<00:20,  5.39ba/s]#015Running tokenizer on dataset:  72%|███████▏  | 281/393 [00:52<00:20,  5.57ba/s]#015Running tokenizer on dataset:  72%|███████▏  | 282/393 [00:52<00:19,  5.68ba/s]#015Running tokenizer on dataset:  72%|███████▏  | 283/393 [00:52<00:19,  5.76ba/s]#015Running tokenizer on dataset:  72%|███████▏  | 284/393 [00:52<00:18,  5.79ba/s]#015Running tokenizer on dataset:  73%|███████▎  | 285/393 [00:52<00:18,  5.80ba/s]#015Running tokenizer on dataset:  73%|███████▎  | 286/393 [00:52<00:18,  5.82ba/s]#015Running tokenizer on dataset:  73%|███████▎  | 287/393 [00:53<00:18,  5.83ba/s]#015Running tokenizer on dataset:  73%|███████▎  | 288/393 [00:53<00:18,  5.79ba/s]#015Running tokenizer on dataset:  74%|███████▎  | 289/393 [00:53<00:17,  5.82ba/s]#015Running tokenizer on dataset:  74%|███████▍  | 290/393 [00:53<00:17,  5.82ba/s]#015Running tokenizer on dataset:  74%|███████▍  | 291/393 [00:53<00:17,  5.81ba/s]#015Running tokenizer on dataset:  74%|███████▍  | 292/393 [00:54<00:18,  5.32ba/s]#015Running tokenizer on dataset:  75%|███████▍  | 293/393 [00:54<00:18,  5.51ba/s]#015Running tokenizer on dataset:  75%|███████▍  | 294/393 [00:54<00:17,  5.67ba/s]#015Running tokenizer on dataset:  75%|███████▌  | 295/393 [00:54<00:16,  5.79ba/s]#015Running tokenizer on dataset:  75%|███████▌  | 296/393 [00:54<00:16,  5.83ba/s]#015Running tokenizer on dataset:  76%|███████▌  | 297/393 [00:54<00:16,  5.87ba/s]#015Running tokenizer on dataset:  76%|███████▌  | 298/393 [00:55<00:16,  5.90ba/s]#015Running tokenizer on dataset:  76%|███████▌  | 299/393 [00:55<00:15,  5.89ba/s]#015Running tokenizer on dataset:  76%|███████▋  | 300/393 [00:55<00:15,  5.86ba/s]#015Running tokenizer on dataset:  77%|███████▋  | 301/393 [00:55<00:15,  5.83ba/s]#015Running tokenizer on dataset:  77%|███████▋  | 302/393 [00:55<00:15,  5.80ba/s]#015Running tokenizer on dataset:  77%|███████▋  | 303/393 [00:55<00:15,  5.82ba/s]#015Running tokenizer on dataset:  77%|███████▋  | 304/393 [00:56<00:16,  5.29ba/s]#015Running tokenizer on dataset:  78%|███████▊  | 305/393 [00:56<00:16,  5.42ba/s]#015Running tokenizer on dataset:  78%|███████▊  | 306/393 [00:56<00:15,  5.56ba/s]#015Running tokenizer on dataset:  78%|███████▊  | 307/393 [00:56<00:15,  5.66ba/s]#015Running tokenizer on dataset:  78%|███████▊  | 308/393 [00:56<00:14,  5.75ba/s]#015Running tokenizer on dataset:  79%|███████▊  | 309/393 [00:56<00:14,  5.76ba/s]#015Running tokenizer on dataset:  79%|███████▉  | 310/393 [00:57<00:14,  5.76ba/s]#015Running tokenizer on dataset:  79%|███████▉  | 311/393 [00:57<00:14,  5.78ba/s]#015Running tokenizer on dataset:  79%|███████▉  | 312/393 [00:57<00:14,  5.76ba/s]#015Running tokenizer on dataset:  80%|███████▉  | 313/393 [00:57<00:13,  5.75ba/s]#015Running tokenizer on dataset:  80%|███████▉  | 314/393 [00:57<00:13,  5.78ba/s]#015Running tokenizer on dataset:  80%|████████  | 315/393 [00:58<00:13,  5.74ba/s]#015Running tokenizer on dataset:  80%|████████  | 316/393 [00:58<00:14,  5.26ba/s]#015Running tokenizer on dataset:  81%|████████  | 317/393 [00:58<00:13,  5.44ba/s]#015Running tokenizer on dataset:  81%|████████  | 318/393 [00:58<00:13,  5.60ba/s]#015Running tokenizer on dataset:  81%|████████  | 319/393 [00:58<00:13,  5.68ba/s]#015Running tokenizer on dataset:  81%|████████▏ | 320/393 [00:58<00:12,  5.73ba/s]#015Running tokenizer on dataset:  82%|████████▏ | 321/393 [00:59<00:12,  5.76ba/s]#015Running tokenizer on dataset:  82%|████████▏ | 322/393 [00:59<00:12,  5.78ba/s]#015Running tokenizer on dataset:  82%|████████▏ | 323/393 [00:59<00:12,  5.78ba/s]#015Running tokenizer on dataset:  82%|████████▏ | 324/393 [00:59<00:11,  5.80ba/s]#015Running tokenizer on dataset:  83%|████████▎ | 325/393 [00:59<00:11,  5.78ba/s]#015Running tokenizer on dataset:  83%|████████▎ | 326/393 [00:59<00:11,  5.77ba/s]#015Running tokenizer on dataset:  83%|████████▎ | 327/393 [01:00<00:11,  5.72ba/s]#015Running tokenizer on dataset:  83%|████████▎ | 328/393 [01:00<00:12,  5.25ba/s]#015Running tokenizer on dataset:  84%|████████▎ | 329/393 [01:00<00:11,  5.40ba/s]#015Running tokenizer on dataset:  84%|████████▍ | 330/393 [01:00<00:11,  5.54ba/s]#015Running tokenizer on dataset:  84%|████████▍ | 331/393 [01:00<00:10,  5.66ba/s]#015Running tokenizer on dataset:  84%|████████▍ | 332/393 [01:01<00:10,  5.74ba/s]#015Running tokenizer on dataset:  85%|████████▍ | 333/393 [01:01<00:10,  5.79ba/s]#015Running tokenizer on dataset:  85%|████████▍ | 334/393 [01:01<00:10,  5.79ba/s]#015Running tokenizer on dataset:  85%|████████▌ | 335/393 [01:01<00:10,  5.80ba/s]#015Running tokenizer on dataset:  85%|████████▌ | 336/393 [01:01<00:09,  5.81ba/s]#015Running tokenizer on dataset:  86%|████████▌ | 337/393 [01:01<00:09,  5.83ba/s]#015Running tokenizer on dataset:  86%|████████▌ | 338/393 [01:02<00:09,  5.80ba/s]#015Running tokenizer on dataset:  86%|████████▋ | 339/393 [01:02<00:09,  5.78ba/s]#015Running tokenizer on dataset:  87%|████████▋ | 340/393 [01:02<00:09,  5.31ba/s]#015Running tokenizer on dataset:  87%|████████▋ | 341/393 [01:02<00:09,  5.51ba/s]#015Running tokenizer on dataset:  87%|████████▋ | 342/393 [01:02<00:09,  5.64ba/s]#015Running tokenizer on dataset:  87%|████████▋ | 343/393 [01:02<00:08,  5.68ba/s]#015Running tokenizer on dataset:  88%|████████▊ | 344/393 [01:03<00:08,  5.75ba/s]#015Running tokenizer on dataset:  88%|████████▊ | 345/393 [01:03<00:08,  5.80ba/s]#015Running tokenizer on dataset:  88%|████████▊ | 346/393 [01:03<00:08,  5.84ba/s]#015Running tokenizer on dataset:  88%|████████▊ | 347/393 [01:03<00:07,  5.84ba/s]#015Running tokenizer on dataset:  89%|████████▊ | 348/393 [01:03<00:07,  5.84ba/s]#015Running tokenizer on dataset:  89%|████████▉ | 349/393 [01:03<00:07,  5.84ba/s]#015Running tokenizer on dataset:  89%|████████▉ | 350/393 [01:04<00:07,  5.84ba/s]#015Running tokenizer on dataset:  89%|████████▉ | 351/393 [01:04<00:07,  5.81ba/s]#015Running tokenizer on dataset:  90%|████████▉ | 352/393 [01:04<00:07,  5.40ba/s]#015Running tokenizer on dataset:  90%|████████▉ | 353/393 [01:04<00:07,  5.58ba/s]#015Running tokenizer on dataset:  90%|█████████ | 354/393 [01:04<00:06,  5.71ba/s]#015Running tokenizer on dataset:  90%|█████████ | 355/393 [01:05<00:06,  5.78ba/s]#015Running tokenizer on dataset:  91%|█████████ | 356/393 [01:05<00:06,  5.79ba/s]#015Running tokenizer on dataset:  91%|█████████ | 357/393 [01:05<00:08,  4.44ba/s]#015Running tokenizer on dataset:  91%|█████████ | 358/393 [01:05<00:07,  4.56ba/s]#015Running tokenizer on dataset:  91%|█████████▏| 359/393 [01:05<00:07,  4.76ba/s]#015Running tokenizer on dataset:  92%|█████████▏| 360/393 [01:06<00:06,  4.91ba/s]#015Running tokenizer on dataset:  92%|█████████▏| 361/393 [01:06<00:06,  5.01ba/s]#015Running tokenizer on dataset:  92%|█████████▏| 362/393 [01:06<00:06,  5.05ba/s]#015Running tokenizer on dataset:  92%|█████████▏| 363/393 [01:06<00:05,  5.23ba/s]#015Running tokenizer on dataset:  93%|█████████▎| 364/393 [01:06<00:05,  4.99ba/s]#015Running tokenizer on dataset:  \u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sm/0jbn3m7x7gg6sxqyq1h3lmgj6h25fm/T/ipykernel_60883/2655345476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msm_local_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms3_output_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 output_name='predictions')]\n\u001b[0m\u001b[1;32m     84\u001b[0m     )\n",
      "\u001b[0;32m~/venv/shortcuts/lib/python3.7/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, code, source_dir, dependencies, git_config, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m   1604\u001b[0m             \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m             \u001b[0mexperiment_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1607\u001b[0m         )\n\u001b[1;32m   1608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/shortcuts/lib/python3.7/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_include_code_in_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/shortcuts/lib/python3.7/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    960\u001b[0m         \"\"\"\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_processing_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_processing_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/shortcuts/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_processing_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3811\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3813\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "framework_processor = FrameworkProcessor(HuggingFace,\n",
    "                                      framework_version=None,\n",
    "                                      image_uri=docker_repo,\n",
    "                                      code_location = s3_code_path, \n",
    "                                       py_version=\"py36\",\n",
    "                                       command=[\"python\"],\n",
    "                                       env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "                                       role=role,\n",
    "                                       instance_type=instance_type,\n",
    "                                       instance_count=instance_count,\n",
    "                                       max_runtime_in_seconds= 5 * 24 * 60 * 60,\n",
    "                                       volume_size_in_gb = 250,\n",
    "                                       network_config=NetworkConfig(enable_network_isolation=False),\n",
    "                                       base_job_name =\"glue-reverse-mnli\"\n",
    "                                       )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sm_local_input_model = \"/opt/ml/processing/input/data/model\"\n",
    "sm_local_input_data = \"/opt/ml/processing/input/data/jsonlines\"\n",
    "sm_local_input_vocab = \"/opt/ml/processing/input/data/vocab\"\n",
    "\n",
    "\n",
    "sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "\n",
    "\n",
    "framework_processor.run(\n",
    "        code=f'run_glue.py',\n",
    "        source_dir=f'{transformer_examples_dir}/examples/pytorch/text-classification',\n",
    "        arguments=[\n",
    "            \"--task_name\", \"mnli\",\n",
    "            \"--model_name_or_path\", sm_local_input_model,\n",
    "            \"--do_train\", \"1\",\n",
    "            \"--do_eval\",\"1\",\n",
    "            \"--do_predict\",\"1\",\n",
    "            \"--max_seq_length\", str(512),\n",
    "            \"--per_device_train_batch_size\", str(8),\n",
    "            \"--gradient_accumulation_steps\", str(4),\n",
    "            \"--learning_rate\", str(2e-5),\n",
    "            \"--num_train_epochs\", str(3),\n",
    "            \"--output_dir\", sm_local_output,\n",
    "            \"--overwrite_output_dir\", \"1\",\n",
    "            \"--load_best_model_at_end\", \"1\",     # load the best model when finished training (default metric is loss)\n",
    "            \"--eval_steps\",\"200\",\n",
    "            \"--save_steps\",\"200\",\n",
    "            \"--evaluation_strategy\",\"steps\",\n",
    "            \"--disable_tqdm\",\"1\"\n",
    "           \n",
    "        ],\n",
    "\n",
    "        inputs=[\n",
    "#                 ProcessingInput(\n",
    "#                     source=s3_input_data,\n",
    "#                     s3_data_type = s3_data_type,\n",
    "#                     destination=sm_local_input_data,\n",
    "#                     s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "                ProcessingInput(\n",
    "                        source=s3_model_package_path,\n",
    "                        destination=sm_local_input_model,\n",
    "                        s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "#                 ProcessingInput(\n",
    "#                         source=s3_input_vocab,\n",
    "#                         destination=sm_local_input_vocab,\n",
    "#                         s3_data_distribution_type=\"FullyReplicated\")\n",
    "            ],\n",
    "\n",
    "\n",
    "        outputs=[ProcessingOutput(\n",
    "                source=sm_local_output, \n",
    "                destination=s3_output_path,\n",
    "                output_name='predictions')]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from uuid import uuid4\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "account_id =  boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role=\"arn:aws:iam::{}:role/service-role/AmazonSageMaker-ExecutionRole-20190118T115449\".format(account_id)\n",
    "max_runs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = \"temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_examples_dir = os.path.join(temp_dir, \"hugging_face_example\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup image and instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_image_name=f\"huggingface-pytorch-training:1.9.1-transformers4.12.3-gpu-py38-cu111-ubuntu20.04\"\n",
    "image_account_id=\"763104351884\"\n",
    "instance_type = \"ml.p3.2xlarge\"\n",
    "instance_type_gpu_map = {\"ml.p3.8xlarge\":4, \"ml.p3.2xlarge\": 1, \"ml.p3.16xlarge\":8}\n",
    "instance_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_repo = \"{}.dkr.ecr.{}.amazonaws.com/{}\".format(image_account_id, region, custom_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configure train/ test and validation datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"aegovan-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_bert=\"s3://{}/embeddings/bert_base_cased/\".format(bucket)\n",
    "\n",
    "\n",
    "trainfile = \"s3://{}/glue_dataset/train/multinli_1.0_train.jsonl\".format(bucket)\n",
    "# valfile=\"s3://{}/mnli_dataset/val/multinli_1.0_dev_matched.jsonl\".format(bucket)\n",
    "\n",
    "#trainfile = \"s3://{}/mnli_dataset_mini/train/multinli.jsonl\".format(bucket)\n",
    "valfile=\"s3://{}/glue_dataset_mini/train/multinli.jsonl\".format(bucket)\n",
    "\n",
    "s3_model_path = \"s3://aegovan-data/mnli_sagemakerresults/mnli-reverse-lang-bert-accuracy-2022-01-23-21-29-34-327/output/model.tar.gz\"\n",
    "s3_model_package_path = \"s3://aegovan-data/models/mnli-reverse-lang-bert-accuracy-2022-01-23-21-29-34-327/output\"\n",
    "s3_model_config_vocab_path = \"s3://aegovan-data/embeddings/bert_base_cased/\"\n",
    "\n",
    "s3_output_path= \"s3://{}/glue_sagemakerresults/\".format(bucket)\n",
    "s3_code_path= \"s3://{}/glue_code\".format(bucket)\n",
    "s3_checkpoint = \"s3://{}/mnli_bert_checkpoint/{}\".format(bucket, str(uuid4()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run processing job training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(transformer_examples_dir):\n",
    "    shutil.rmtree(transformer_examples_dir)\n",
    "    os.makedirs(transformer_examples_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'temp/hugging_face_example'...\n",
      "remote: Enumerating objects: 99654, done.\u001b[K\n",
      "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 99654 (delta 7), reused 17 (delta 5), pack-reused 99631\u001b[K\n",
      "Receiving objects: 100% (99654/99654), 84.61 MiB | 2.65 MiB/s, done.\n",
      "Resolving deltas: 100% (72298/72298), done.\n",
      "Note: switching to 'tags/v4.12.3'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at 3ea15d278 Style\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/transformers $transformer_examples_dir\n",
    "!git -C $transformer_examples_dir checkout tags/v4.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "framework_processor = FrameworkProcessor(HuggingFace,\n",
    "                                      framework_version=None,\n",
    "                                      image_uri=docker_repo,\n",
    "                                      code_location = s3_code_path, \n",
    "                                       py_version=\"py36\",\n",
    "                                       command=[\"python\"],\n",
    "                                       env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "                                       role=role,\n",
    "                                       instance_type=instance_type,\n",
    "                                       instance_count=instance_count,\n",
    "                                       max_runtime_in_seconds= 5 * 24 * 60 * 60,\n",
    "                                       volume_size_in_gb = 250,\n",
    "                                       network_config=NetworkConfig(enable_network_isolation=False),\n",
    "                                       base_job_name =\"glue-processing\"\n",
    "                                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run base mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 19:57:20,966 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 19:57:20,969 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 19:57:20,969 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 19:57:20,969 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 19:59:06 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.545918345451355, 'eval_accuracy': 0.780539989811513, 'eval_runtime': 105.4771, 'eval_samples_per_second': 93.053, 'eval_steps_per_second': 11.633, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 19:59:06,446 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-2200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 19:59:06,447 >> Configuration saved in /opt/ml/processing/output/checkpoint-2200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 19:59:07,136 >> Model weights saved in /opt/ml/processing/output/checkpoint-2200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 19:59:07,136 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-2200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 19:59:07,137 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-2200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:02:26,059 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:02:26,061 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:02:26,061 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:02:26,061 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 20:04:10 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5382832288742065, 'eval_accuracy': 0.7871625063678044, 'eval_runtime': 104.7315, 'eval_samples_per_second': 93.716, 'eval_steps_per_second': 11.716, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:04:10,792 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-2400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:04:10,793 >> Configuration saved in /opt/ml/processing/output/checkpoint-2400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:04:11,451 >> Model weights saved in /opt/ml/processing/output/checkpoint-2400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:04:11,452 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-2400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:04:11,452 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-2400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.5809, 'learning_rate': 1.8641894828335507e-05, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:07:29,312 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:07:29,314 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:07:29,315 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:07:29,315 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 20:09:14 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5322791934013367, 'eval_accuracy': 0.7886907794192562, 'eval_runtime': 104.7394, 'eval_samples_per_second': 93.709, 'eval_steps_per_second': 11.715, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:09:14,054 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-2600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:09:14,055 >> Configuration saved in /opt/ml/processing/output/checkpoint-2600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:09:14,740 >> Model weights saved in /opt/ml/processing/output/checkpoint-2600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:09:14,740 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-2600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:09:14,741 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-2600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:12:32,728 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:12:32,730 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:12:32,730 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:12:32,730 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 20:14:17 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5488401055335999, 'eval_accuracy': 0.7816607233825776, 'eval_runtime': 104.7429, 'eval_samples_per_second': 93.706, 'eval_steps_per_second': 11.714, 'epoch': 0.23}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:14:17,473 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-2800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:14:17,474 >> Configuration saved in /opt/ml/processing/output/checkpoint-2800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:14:18,151 >> Model weights saved in /opt/ml/processing/output/checkpoint-2800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:14:18,152 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-2800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:14:18,152 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-2800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.5652, 'learning_rate': 1.837027379400261e-05, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:17:36,117 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:17:36,119 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:17:36,119 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:17:36,119 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 20:19:20 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5367445945739746, 'eval_accuracy': 0.7865511971472237, 'eval_runtime': 104.505, 'eval_samples_per_second': 93.919, 'eval_steps_per_second': 11.741, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:19:20,625 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-3000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:19:20,626 >> Configuration saved in /opt/ml/processing/output/checkpoint-3000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:19:21,298 >> Model weights saved in /opt/ml/processing/output/checkpoint-3000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:19:21,299 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-3000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:19:21,299 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-3000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:22:39,605 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:22:39,607 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:22:39,607 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:22:39,608 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 20:24:24 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5301528573036194, 'eval_accuracy': 0.7926642893530311, 'eval_runtime': 104.5427, 'eval_samples_per_second': 93.885, 'eval_steps_per_second': 11.737, 'epoch': 0.26}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:24:24,150 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-3200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:24:24,151 >> Configuration saved in /opt/ml/processing/output/checkpoint-3200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:24:24,829 >> Model weights saved in /opt/ml/processing/output/checkpoint-3200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:24:24,830 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-3200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:24:24,830 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-3200/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:27:42,209 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:27:42,211 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:27:42,211 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:27:42,211 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 20:29:27 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5076935887336731, 'eval_accuracy': 0.7969434538970963, 'eval_runtime': 104.8362, 'eval_samples_per_second': 93.622, 'eval_steps_per_second': 11.704, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:29:27,048 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-3400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:29:27,048 >> Configuration saved in /opt/ml/processing/output/checkpoint-3400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:29:27,707 >> Model weights saved in /opt/ml/processing/output/checkpoint-3400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:29:27,708 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-3400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:29:27,708 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-3400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.5517, 'learning_rate': 1.809865275966971e-05, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:32:45,484 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:32:45,486 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:32:45,486 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:32:45,486 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 20:34:30 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5046467781066895, 'eval_accuracy': 0.7991849210392257, 'eval_runtime': 105.0822, 'eval_samples_per_second': 93.403, 'eval_steps_per_second': 11.677, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:34:30,569 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-3600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:34:30,570 >> Configuration saved in /opt/ml/processing/output/checkpoint-3600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:34:31,252 >> Model weights saved in /opt/ml/processing/output/checkpoint-3600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:34:31,252 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-3600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:34:31,252 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-3600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:37:49,753 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:37:49,755 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:37:49,755 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:37:49,755 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 20:39:34 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.501025915145874, 'eval_accuracy': 0.7959246051961284, 'eval_runtime': 105.0098, 'eval_samples_per_second': 93.468, 'eval_steps_per_second': 11.685, 'epoch': 0.31}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:39:34,765 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-3800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:39:34,766 >> Configuration saved in /opt/ml/processing/output/checkpoint-3800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:39:35,442 >> Model weights saved in /opt/ml/processing/output/checkpoint-3800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:39:35,443 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-3800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:39:35,443 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-3800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.5352, 'learning_rate': 1.7827031725336812e-05, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:42:53,279 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:42:53,281 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:42:53,281 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:42:53,281 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 20:44:38 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.497858464717865, 'eval_accuracy': 0.7994905756495161, 'eval_runtime': 104.8959, 'eval_samples_per_second': 93.569, 'eval_steps_per_second': 11.697, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:44:38,177 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-4000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:44:38,178 >> Configuration saved in /opt/ml/processing/output/checkpoint-4000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:44:38,843 >> Model weights saved in /opt/ml/processing/output/checkpoint-4000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:44:38,844 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-4000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:44:38,844 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-4000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:47:56,846 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:47:56,848 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:47:56,848 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:47:56,848 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 20:49:41 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49156028032302856, 'eval_accuracy': 0.8040753948038716, 'eval_runtime': 104.6074, 'eval_samples_per_second': 93.827, 'eval_steps_per_second': 11.73, 'epoch': 0.34}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:49:41,456 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-4200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:49:41,457 >> Configuration saved in /opt/ml/processing/output/checkpoint-4200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:49:42,133 >> Model weights saved in /opt/ml/processing/output/checkpoint-4200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:49:42,133 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-4200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:49:42,134 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-4200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:52:59,597 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:52:59,599 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:52:59,599 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:52:59,599 >>   Batch size = 8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m02/12/2022 20:54:44 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5182867646217346, 'eval_accuracy': 0.8025471217524197, 'eval_runtime': 104.5524, 'eval_samples_per_second': 93.876, 'eval_steps_per_second': 11.736, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:54:44,152 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-4400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:54:44,153 >> Configuration saved in /opt/ml/processing/output/checkpoint-4400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:54:44,812 >> Model weights saved in /opt/ml/processing/output/checkpoint-4400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:54:44,812 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-4400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:54:44,812 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-4400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.5137, 'learning_rate': 1.7555410691003914e-05, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 20:58:02,688 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 20:58:02,690 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 20:58:02,690 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 20:58:02,690 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 20:59:47 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49173012375831604, 'eval_accuracy': 0.8047885888945492, 'eval_runtime': 104.7466, 'eval_samples_per_second': 93.702, 'eval_steps_per_second': 11.714, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 20:59:47,437 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-4600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 20:59:47,438 >> Configuration saved in /opt/ml/processing/output/checkpoint-4600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 20:59:48,097 >> Model weights saved in /opt/ml/processing/output/checkpoint-4600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 20:59:48,098 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-4600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 20:59:48,098 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-4600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:03:05,982 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:03:05,984 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:03:05,984 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:03:05,984 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 21:04:50 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4866994619369507, 'eval_accuracy': 0.8081507896077432, 'eval_runtime': 104.4857, 'eval_samples_per_second': 93.936, 'eval_steps_per_second': 11.743, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 21:04:50,470 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-4800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 21:04:50,471 >> Configuration saved in /opt/ml/processing/output/checkpoint-4800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 21:04:51,159 >> Model weights saved in /opt/ml/processing/output/checkpoint-4800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 21:04:51,160 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-4800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 21:04:51,160 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-4800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.5217, 'learning_rate': 1.7283789656671015e-05, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:08:09,490 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:08:09,492 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:08:09,492 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:08:09,492 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 21:09:54 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.48479875922203064, 'eval_accuracy': 0.8056036678553234, 'eval_runtime': 104.6332, 'eval_samples_per_second': 93.804, 'eval_steps_per_second': 11.727, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 21:09:54,126 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-5000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 21:09:54,127 >> Configuration saved in /opt/ml/processing/output/checkpoint-5000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 21:09:54,808 >> Model weights saved in /opt/ml/processing/output/checkpoint-5000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 21:09:54,809 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-5000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 21:09:54,809 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-5000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:13:13,374 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:13:13,377 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:13:13,377 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:13:13,377 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 21:14:58 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.47645923495292664, 'eval_accuracy': 0.8104941416199695, 'eval_runtime': 105.1225, 'eval_samples_per_second': 93.367, 'eval_steps_per_second': 11.672, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 21:14:58,500 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-5200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 21:14:58,501 >> Configuration saved in /opt/ml/processing/output/checkpoint-5200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 21:14:59,168 >> Model weights saved in /opt/ml/processing/output/checkpoint-5200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 21:14:59,169 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-5200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 21:14:59,169 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-5200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:18:17,370 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:18:17,372 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:18:17,372 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:18:17,372 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 21:20:01 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4808582663536072, 'eval_accuracy': 0.8103922567498727, 'eval_runtime': 104.4744, 'eval_samples_per_second': 93.946, 'eval_steps_per_second': 11.745, 'epoch': 0.44}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 21:20:01,847 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-5400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 21:20:01,848 >> Configuration saved in /opt/ml/processing/output/checkpoint-5400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 21:20:02,534 >> Model weights saved in /opt/ml/processing/output/checkpoint-5400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 21:20:02,535 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-5400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 21:20:02,535 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-5400/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m{'loss': 0.513, 'learning_rate': 1.7012168622338114e-05, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:23:20,247 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:23:20,249 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:23:20,249 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:23:20,249 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 21:25:04 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4832491874694824, 'eval_accuracy': 0.8120224146714213, 'eval_runtime': 104.6278, 'eval_samples_per_second': 93.809, 'eval_steps_per_second': 11.727, 'epoch': 0.46}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 21:25:04,878 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-5600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 21:25:04,879 >> Configuration saved in /opt/ml/processing/output/checkpoint-5600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 21:25:05,540 >> Model weights saved in /opt/ml/processing/output/checkpoint-5600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 21:25:05,541 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-5600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 21:25:05,541 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-5600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:28:23,156 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:28:23,158 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:28:23,158 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:28:23,158 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 21:30:07 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4766974151134491, 'eval_accuracy': 0.8122261844116149, 'eval_runtime': 104.5641, 'eval_samples_per_second': 93.866, 'eval_steps_per_second': 11.734, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 21:30:07,723 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-5800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 21:30:07,724 >> Configuration saved in /opt/ml/processing/output/checkpoint-5800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 21:30:08,384 >> Model weights saved in /opt/ml/processing/output/checkpoint-5800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 21:30:08,384 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-5800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 21:30:08,384 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-5800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.5065, 'learning_rate': 1.6740547588005215e-05, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:33:26,238 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:33:26,240 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:33:26,241 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:33:26,241 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 21:35:11 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.48760172724723816, 'eval_accuracy': 0.810697911360163, 'eval_runtime': 105.282, 'eval_samples_per_second': 93.226, 'eval_steps_per_second': 11.654, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 21:35:11,523 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-6000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 21:35:11,524 >> Configuration saved in /opt/ml/processing/output/checkpoint-6000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 21:35:12,210 >> Model weights saved in /opt/ml/processing/output/checkpoint-6000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 21:35:12,210 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-6000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 21:35:12,211 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-6000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:38:30,584 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:38:30,586 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:38:30,587 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:38:30,587 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 21:40:15 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4868960976600647, 'eval_accuracy': 0.8097809475292919, 'eval_runtime': 104.6294, 'eval_samples_per_second': 93.807, 'eval_steps_per_second': 11.727, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 21:40:15,218 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-6200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 21:40:15,219 >> Configuration saved in /opt/ml/processing/output/checkpoint-6200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 21:40:15,885 >> Model weights saved in /opt/ml/processing/output/checkpoint-6200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 21:40:15,885 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-6200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 21:40:15,885 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-6200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:43:33,821 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:43:33,823 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:43:33,823 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:43:33,823 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 21:45:18 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.47745653986930847, 'eval_accuracy': 0.8127356087620988, 'eval_runtime': 104.3893, 'eval_samples_per_second': 94.023, 'eval_steps_per_second': 11.754, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 21:45:18,213 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-6400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 21:45:18,214 >> Configuration saved in /opt/ml/processing/output/checkpoint-6400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 21:45:18,882 >> Model weights saved in /opt/ml/processing/output/checkpoint-6400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 21:45:18,883 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-6400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 21:45:18,883 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-6400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.5055, 'learning_rate': 1.6468926553672317e-05, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:48:37,070 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:48:37,072 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:48:37,072 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:48:37,072 >>   Batch size = 8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m02/12/2022 21:50:21 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4841580390930176, 'eval_accuracy': 0.8102903718797758, 'eval_runtime': 104.3836, 'eval_samples_per_second': 94.028, 'eval_steps_per_second': 11.755, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 21:50:21,456 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-6600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 21:50:21,457 >> Configuration saved in /opt/ml/processing/output/checkpoint-6600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 21:50:22,139 >> Model weights saved in /opt/ml/processing/output/checkpoint-6600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 21:50:22,139 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-6600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 21:50:22,139 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-6600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:53:39,596 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:53:39,599 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:53:39,599 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:53:39,599 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 21:55:24 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4747143089771271, 'eval_accuracy': 0.8128374936321956, 'eval_runtime': 104.7605, 'eval_samples_per_second': 93.69, 'eval_steps_per_second': 11.712, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 21:55:24,362 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-6800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 21:55:24,363 >> Configuration saved in /opt/ml/processing/output/checkpoint-6800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 21:55:25,034 >> Model weights saved in /opt/ml/processing/output/checkpoint-6800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 21:55:25,034 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-6800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 21:55:25,035 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-6800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.4978, 'learning_rate': 1.619730551933942e-05, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 21:58:43,275 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 21:58:43,277 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 21:58:43,278 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 21:58:43,278 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:00:28 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.47981688380241394, 'eval_accuracy': 0.8133469179826796, 'eval_runtime': 104.7335, 'eval_samples_per_second': 93.714, 'eval_steps_per_second': 11.715, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:00:28,012 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-7000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:00:28,013 >> Configuration saved in /opt/ml/processing/output/checkpoint-7000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:00:28,688 >> Model weights saved in /opt/ml/processing/output/checkpoint-7000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:00:28,688 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-7000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:00:28,689 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-7000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:03:46,482 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:03:46,484 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:03:46,484 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:03:46,484 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:05:31 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4636145532131195, 'eval_accuracy': 0.8192562404482935, 'eval_runtime': 104.6872, 'eval_samples_per_second': 93.756, 'eval_steps_per_second': 11.721, 'epoch': 0.59}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:05:31,172 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-7200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:05:31,173 >> Configuration saved in /opt/ml/processing/output/checkpoint-7200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:05:31,864 >> Model weights saved in /opt/ml/processing/output/checkpoint-7200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:05:31,865 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-7200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:05:31,865 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-7200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:08:49,730 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:08:49,732 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:08:49,733 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:08:49,733 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:10:34 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.46886709332466125, 'eval_accuracy': 0.817524197656648, 'eval_runtime': 104.8741, 'eval_samples_per_second': 93.588, 'eval_steps_per_second': 11.7, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:10:34,610 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-7400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:10:34,611 >> Configuration saved in /opt/ml/processing/output/checkpoint-7400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:10:35,279 >> Model weights saved in /opt/ml/processing/output/checkpoint-7400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:10:35,280 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-7400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:10:35,280 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-7400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.4874, 'learning_rate': 1.592568448500652e-05, 'epoch': 0.61}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:13:54,041 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:13:54,044 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:13:54,044 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:13:54,044 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:15:38 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4878438115119934, 'eval_accuracy': 0.8144676515537442, 'eval_runtime': 104.7795, 'eval_samples_per_second': 93.673, 'eval_steps_per_second': 11.71, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:15:38,823 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-7600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:15:38,824 >> Configuration saved in /opt/ml/processing/output/checkpoint-7600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:15:39,504 >> Model weights saved in /opt/ml/processing/output/checkpoint-7600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:15:39,505 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-7600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:15:39,505 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-7600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:18:57,321 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:18:57,323 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:18:57,323 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:18:57,323 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:20:42 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4762866497039795, 'eval_accuracy': 0.8096790626591951, 'eval_runtime': 104.874, 'eval_samples_per_second': 93.588, 'eval_steps_per_second': 11.7, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:20:42,197 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-7800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:20:42,198 >> Configuration saved in /opt/ml/processing/output/checkpoint-7800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:20:42,886 >> Model weights saved in /opt/ml/processing/output/checkpoint-7800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:20:42,887 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-7800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:20:42,887 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-7800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.4868, 'learning_rate': 1.5654063450673622e-05, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:24:00,891 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:24:00,893 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:24:00,893 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:24:00,893 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:25:45 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4602074921131134, 'eval_accuracy': 0.8160978094752929, 'eval_runtime': 104.8429, 'eval_samples_per_second': 93.616, 'eval_steps_per_second': 11.703, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:25:45,737 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-8000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:25:45,738 >> Configuration saved in /opt/ml/processing/output/checkpoint-8000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:25:46,398 >> Model weights saved in /opt/ml/processing/output/checkpoint-8000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:25:46,399 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-8000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:25:46,399 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-8000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:29:04,583 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:29:04,585 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:29:04,585 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:29:04,585 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:30:48 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.45268866419792175, 'eval_accuracy': 0.8205807437595517, 'eval_runtime': 104.3486, 'eval_samples_per_second': 94.06, 'eval_steps_per_second': 11.759, 'epoch': 0.67}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:30:48,934 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-8200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:30:48,935 >> Configuration saved in /opt/ml/processing/output/checkpoint-8200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:30:49,614 >> Model weights saved in /opt/ml/processing/output/checkpoint-8200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:30:49,615 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-8200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:30:49,615 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-8200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:34:08,062 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:34:08,064 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:34:08,064 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:34:08,064 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:35:52 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.47195908427238464, 'eval_accuracy': 0.8168110035659705, 'eval_runtime': 104.5007, 'eval_samples_per_second': 93.923, 'eval_steps_per_second': 11.742, 'epoch': 0.68}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:35:52,565 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-8400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:35:52,566 >> Configuration saved in /opt/ml/processing/output/checkpoint-8400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:35:53,242 >> Model weights saved in /opt/ml/processing/output/checkpoint-8400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:35:53,242 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-8400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:35:53,242 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-8400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.4837, 'learning_rate': 1.5382442416340724e-05, 'epoch': 0.69}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:39:11,206 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:39:11,208 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:39:11,208 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:39:11,208 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:40:56 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.46321970224380493, 'eval_accuracy': 0.8221090168110036, 'eval_runtime': 104.9423, 'eval_samples_per_second': 93.528, 'eval_steps_per_second': 11.692, 'epoch': 0.7}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:40:56,151 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-8600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:40:56,152 >> Configuration saved in /opt/ml/processing/output/checkpoint-8600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:40:56,830 >> Model weights saved in /opt/ml/processing/output/checkpoint-8600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:40:56,830 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-8600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:40:56,830 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-8600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:44:15,039 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:44:15,041 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:44:15,041 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:44:15,041 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:45:59 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.45129087567329407, 'eval_accuracy': 0.8215995924605196, 'eval_runtime': 104.9154, 'eval_samples_per_second': 93.552, 'eval_steps_per_second': 11.695, 'epoch': 0.72}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:45:59,957 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-8800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:45:59,958 >> Configuration saved in /opt/ml/processing/output/checkpoint-8800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:46:00,624 >> Model weights saved in /opt/ml/processing/output/checkpoint-8800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:46:00,624 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-8800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:46:00,624 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-8800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.4793, 'learning_rate': 1.5110821382007822e-05, 'epoch': 0.73}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:49:18,151 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:49:18,153 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:49:18,153 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:49:18,153 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:51:02 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.462389200925827, 'eval_accuracy': 0.82190524707081, 'eval_runtime': 104.7913, 'eval_samples_per_second': 93.662, 'eval_steps_per_second': 11.709, 'epoch': 0.73}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:51:02,945 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-9000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:51:02,946 >> Configuration saved in /opt/ml/processing/output/checkpoint-9000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:51:03,625 >> Model weights saved in /opt/ml/processing/output/checkpoint-9000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:51:03,625 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-9000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:51:03,625 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-9000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:54:21,537 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:54:21,539 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:54:21,539 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:54:21,539 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 22:56:05 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.45600762963294983, 'eval_accuracy': 0.8206826286296485, 'eval_runtime': 104.2457, 'eval_samples_per_second': 94.153, 'eval_steps_per_second': 11.77, 'epoch': 0.75}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 22:56:05,787 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-9200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 22:56:05,788 >> Configuration saved in /opt/ml/processing/output/checkpoint-9200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 22:56:06,450 >> Model weights saved in /opt/ml/processing/output/checkpoint-9200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 22:56:06,451 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-9200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 22:56:06,451 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-9200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 22:59:24,500 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 22:59:24,502 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 22:59:24,503 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 22:59:24,503 >>   Batch size = 8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m02/12/2022 23:01:09 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4597398042678833, 'eval_accuracy': 0.8180336220071319, 'eval_runtime': 104.4995, 'eval_samples_per_second': 93.924, 'eval_steps_per_second': 11.742, 'epoch': 0.77}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:01:09,002 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-9400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:01:09,003 >> Configuration saved in /opt/ml/processing/output/checkpoint-9400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:01:09,675 >> Model weights saved in /opt/ml/processing/output/checkpoint-9400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:01:09,675 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-9400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:01:09,675 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-9400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.4787, 'learning_rate': 1.4839200347674924e-05, 'epoch': 0.77}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 23:04:27,459 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 23:04:27,461 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 23:04:27,461 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 23:04:27,461 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 23:06:12 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4537450671195984, 'eval_accuracy': 0.8214977075904228, 'eval_runtime': 104.9759, 'eval_samples_per_second': 93.498, 'eval_steps_per_second': 11.688, 'epoch': 0.78}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:06:12,438 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-9600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:06:12,439 >> Configuration saved in /opt/ml/processing/output/checkpoint-9600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:06:13,128 >> Model weights saved in /opt/ml/processing/output/checkpoint-9600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:06:13,129 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-9600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:06:13,129 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-9600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 23:09:31,229 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 23:09:31,231 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 23:09:31,231 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 23:09:31,231 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 23:11:16 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4753616750240326, 'eval_accuracy': 0.8096790626591951, 'eval_runtime': 105.0714, 'eval_samples_per_second': 93.413, 'eval_steps_per_second': 11.678, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:11:16,306 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-9800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:11:16,307 >> Configuration saved in /opt/ml/processing/output/checkpoint-9800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:11:16,971 >> Model weights saved in /opt/ml/processing/output/checkpoint-9800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:11:16,971 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-9800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:11:16,972 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-9800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.4627, 'learning_rate': 1.4567579313342026e-05, 'epoch': 0.81}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 23:14:35,332 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 23:14:35,334 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 23:14:35,334 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 23:14:35,334 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 23:16:20 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.46158233284950256, 'eval_accuracy': 0.8205807437595517, 'eval_runtime': 104.9224, 'eval_samples_per_second': 93.545, 'eval_steps_per_second': 11.694, 'epoch': 0.81}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:16:20,257 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-10000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:16:20,258 >> Configuration saved in /opt/ml/processing/output/checkpoint-10000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:16:20,936 >> Model weights saved in /opt/ml/processing/output/checkpoint-10000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:16:20,936 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-10000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:16:20,937 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-10000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 23:19:39,157 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 23:19:39,159 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 23:19:39,159 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 23:19:39,159 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 23:21:23 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.45560765266418457, 'eval_accuracy': 0.8193581253183903, 'eval_runtime': 104.4853, 'eval_samples_per_second': 93.937, 'eval_steps_per_second': 11.743, 'epoch': 0.83}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:21:23,646 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-10200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:21:23,646 >> Configuration saved in /opt/ml/processing/output/checkpoint-10200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:21:24,309 >> Model weights saved in /opt/ml/processing/output/checkpoint-10200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:21:24,310 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-10200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:21:24,310 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-10200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 23:24:41,755 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 23:24:41,757 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 23:24:41,757 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 23:24:41,757 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 23:26:26 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.45808660984039307, 'eval_accuracy': 0.82190524707081, 'eval_runtime': 104.8218, 'eval_samples_per_second': 93.635, 'eval_steps_per_second': 11.706, 'epoch': 0.85}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:26:26,581 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-10400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:26:26,581 >> Configuration saved in /opt/ml/processing/output/checkpoint-10400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:26:27,240 >> Model weights saved in /opt/ml/processing/output/checkpoint-10400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:26:27,241 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-10400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:26:27,241 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-10400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.474, 'learning_rate': 1.4295958279009128e-05, 'epoch': 0.86}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 23:29:44,888 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 23:29:44,890 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 23:29:44,890 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 23:29:44,890 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 23:31:29 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4441540539264679, 'eval_accuracy': 0.828222109016811, 'eval_runtime': 104.6277, 'eval_samples_per_second': 93.809, 'eval_steps_per_second': 11.727, 'epoch': 0.86}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:31:29,518 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-10600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:31:29,519 >> Configuration saved in /opt/ml/processing/output/checkpoint-10600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:31:30,182 >> Model weights saved in /opt/ml/processing/output/checkpoint-10600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:31:30,182 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-10600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:31:30,183 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-10600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 23:34:48,034 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 23:34:48,036 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 23:34:48,036 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 23:34:48,036 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 23:36:32 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4570295214653015, 'eval_accuracy': 0.8220071319409068, 'eval_runtime': 104.8952, 'eval_samples_per_second': 93.57, 'eval_steps_per_second': 11.697, 'epoch': 0.88}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:36:32,932 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-10800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:36:32,933 >> Configuration saved in /opt/ml/processing/output/checkpoint-10800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:36:33,609 >> Model weights saved in /opt/ml/processing/output/checkpoint-10800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:36:33,609 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-10800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:36:33,610 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-10800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.4694, 'learning_rate': 1.402433724467623e-05, 'epoch': 0.9}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 23:39:51,845 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 23:39:51,848 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 23:39:51,848 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 23:39:51,848 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 23:41:36 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.44372573494911194, 'eval_accuracy': 0.8251655629139073, 'eval_runtime': 105.1452, 'eval_samples_per_second': 93.347, 'eval_steps_per_second': 11.67, 'epoch': 0.9}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:41:36,993 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-11000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:41:36,994 >> Configuration saved in /opt/ml/processing/output/checkpoint-11000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:41:37,674 >> Model weights saved in /opt/ml/processing/output/checkpoint-11000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:41:37,675 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-11000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:41:37,675 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-11000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 23:44:55,895 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 23:44:55,897 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 23:44:55,897 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 23:44:55,897 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 23:46:40 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.44700220227241516, 'eval_accuracy': 0.8237391747325522, 'eval_runtime': 104.4714, 'eval_samples_per_second': 93.949, 'eval_steps_per_second': 11.745, 'epoch': 0.91}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:46:40,369 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-11200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:46:40,370 >> Configuration saved in /opt/ml/processing/output/checkpoint-11200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:46:41,032 >> Model weights saved in /opt/ml/processing/output/checkpoint-11200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:46:41,033 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-11200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:46:41,033 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-11200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 23:49:59,147 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 23:49:59,149 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 23:49:59,149 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 23:49:59,150 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 23:51:44 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.43912556767463684, 'eval_accuracy': 0.8288334182373918, 'eval_runtime': 105.105, 'eval_samples_per_second': 93.383, 'eval_steps_per_second': 11.674, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:51:44,258 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-11400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:51:44,259 >> Configuration saved in /opt/ml/processing/output/checkpoint-11400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:51:44,921 >> Model weights saved in /opt/ml/processing/output/checkpoint-11400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:51:44,921 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-11400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:51:44,921 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-11400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.4694, 'learning_rate': 1.3752716210343331e-05, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-12 23:55:02,961 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-12 23:55:02,963 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-12 23:55:02,963 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-12 23:55:02,963 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/12/2022 23:56:47 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.435088187456131, 'eval_accuracy': 0.8286296484971981, 'eval_runtime': 104.5617, 'eval_samples_per_second': 93.868, 'eval_steps_per_second': 11.735, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-12 23:56:47,525 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-11600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-12 23:56:47,526 >> Configuration saved in /opt/ml/processing/output/checkpoint-11600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-12 23:56:48,189 >> Model weights saved in /opt/ml/processing/output/checkpoint-11600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-12 23:56:48,189 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-11600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-12 23:56:48,189 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-11600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:00:05,671 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:00:05,673 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:00:05,673 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:00:05,673 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:01:50 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4471873342990875, 'eval_accuracy': 0.8248599083036169, 'eval_runtime': 104.5235, 'eval_samples_per_second': 93.902, 'eval_steps_per_second': 11.739, 'epoch': 0.96}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:01:50,197 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-11800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:01:50,198 >> Configuration saved in /opt/ml/processing/output/checkpoint-11800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:01:50,877 >> Model weights saved in /opt/ml/processing/output/checkpoint-11800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:01:50,878 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-11800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:01:50,878 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-11800/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m{'loss': 0.4663, 'learning_rate': 1.3481095176010431e-05, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:05:08,852 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:05:08,854 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:05:08,854 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:05:08,854 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:06:53 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.43200671672821045, 'eval_accuracy': 0.8288334182373918, 'eval_runtime': 104.559, 'eval_samples_per_second': 93.87, 'eval_steps_per_second': 11.735, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:06:53,414 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-12000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:06:53,415 >> Configuration saved in /opt/ml/processing/output/checkpoint-12000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:06:54,099 >> Model weights saved in /opt/ml/processing/output/checkpoint-12000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:06:54,100 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-12000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:06:54,100 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-12000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:10:12,077 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:10:12,079 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:10:12,080 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:10:12,080 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:11:56 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.43717139959335327, 'eval_accuracy': 0.8307692307692308, 'eval_runtime': 104.6525, 'eval_samples_per_second': 93.787, 'eval_steps_per_second': 11.725, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:11:56,732 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-12200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:11:56,733 >> Configuration saved in /opt/ml/processing/output/checkpoint-12200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:11:57,416 >> Model weights saved in /opt/ml/processing/output/checkpoint-12200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:11:57,417 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-12200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:11:57,417 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-12200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:15:15,334 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:15:15,336 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:15:15,336 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:15:15,336 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:16:59 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4661597013473511, 'eval_accuracy': 0.8267957208354559, 'eval_runtime': 104.4419, 'eval_samples_per_second': 93.976, 'eval_steps_per_second': 11.748, 'epoch': 1.01}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:16:59,779 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-12400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:16:59,779 >> Configuration saved in /opt/ml/processing/output/checkpoint-12400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:17:00,467 >> Model weights saved in /opt/ml/processing/output/checkpoint-12400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:17:00,467 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-12400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:17:00,468 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-12400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.4104, 'learning_rate': 1.3209474141677531e-05, 'epoch': 1.02}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:20:18,546 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:20:18,547 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:20:18,548 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:20:18,548 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:22:03 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.46879705786705017, 'eval_accuracy': 0.8266938359653592, 'eval_runtime': 104.5552, 'eval_samples_per_second': 93.874, 'eval_steps_per_second': 11.735, 'epoch': 1.03}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:22:03,104 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-12600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:22:03,105 >> Configuration saved in /opt/ml/processing/output/checkpoint-12600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:22:03,789 >> Model weights saved in /opt/ml/processing/output/checkpoint-12600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:22:03,789 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-12600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:22:03,790 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-12600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:25:23,040 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:25:23,042 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:25:23,042 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:25:23,042 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:27:07 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4596109688282013, 'eval_accuracy': 0.8314824248599083, 'eval_runtime': 104.7811, 'eval_samples_per_second': 93.671, 'eval_steps_per_second': 11.71, 'epoch': 1.04}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:27:07,824 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-12800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:27:07,825 >> Configuration saved in /opt/ml/processing/output/checkpoint-12800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:27:08,512 >> Model weights saved in /opt/ml/processing/output/checkpoint-12800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:27:08,512 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-12800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:27:08,513 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-12800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3489, 'learning_rate': 1.2937853107344633e-05, 'epoch': 1.06}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:30:27,465 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:30:27,467 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:30:27,467 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:30:27,468 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:32:12 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.45668262243270874, 'eval_accuracy': 0.8293428425878757, 'eval_runtime': 104.8707, 'eval_samples_per_second': 93.591, 'eval_steps_per_second': 11.7, 'epoch': 1.06}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:32:12,338 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-13000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:32:12,339 >> Configuration saved in /opt/ml/processing/output/checkpoint-13000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:32:13,024 >> Model weights saved in /opt/ml/processing/output/checkpoint-13000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:32:13,025 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-13000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:32:13,025 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-13000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:35:32,223 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:35:32,225 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:35:32,225 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:35:32,225 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:37:16 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4893443286418915, 'eval_accuracy': 0.8221090168110036, 'eval_runtime': 104.7073, 'eval_samples_per_second': 93.737, 'eval_steps_per_second': 11.718, 'epoch': 1.08}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:37:16,933 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-13200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:37:16,934 >> Configuration saved in /opt/ml/processing/output/checkpoint-13200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:37:17,623 >> Model weights saved in /opt/ml/processing/output/checkpoint-13200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:37:17,624 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-13200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:37:17,624 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-13200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:40:36,602 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:40:36,604 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:40:36,604 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:40:36,604 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:42:21 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4617394506931305, 'eval_accuracy': 0.8299541518084564, 'eval_runtime': 105.1055, 'eval_samples_per_second': 93.382, 'eval_steps_per_second': 11.674, 'epoch': 1.09}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:42:21,710 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-13400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:42:21,711 >> Configuration saved in /opt/ml/processing/output/checkpoint-13400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:42:22,403 >> Model weights saved in /opt/ml/processing/output/checkpoint-13400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:42:22,403 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-13400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:42:22,403 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-13400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3366, 'learning_rate': 1.2666232073011735e-05, 'epoch': 1.1}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:45:41,498 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:45:41,500 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:45:41,500 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:45:41,500 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:47:26 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4697200357913971, 'eval_accuracy': 0.8280183392766174, 'eval_runtime': 104.7125, 'eval_samples_per_second': 93.733, 'eval_steps_per_second': 11.718, 'epoch': 1.11}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:47:26,213 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-13600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:47:26,214 >> Configuration saved in /opt/ml/processing/output/checkpoint-13600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:47:26,888 >> Model weights saved in /opt/ml/processing/output/checkpoint-13600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:47:26,889 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-13600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:47:26,889 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-13600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:50:45,275 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:50:45,277 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:50:45,277 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:50:45,277 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:52:30 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.46772104501724243, 'eval_accuracy': 0.8272032603158431, 'eval_runtime': 104.9195, 'eval_samples_per_second': 93.548, 'eval_steps_per_second': 11.695, 'epoch': 1.12}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:52:30,198 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-13800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:52:30,199 >> Configuration saved in /opt/ml/processing/output/checkpoint-13800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:52:30,878 >> Model weights saved in /opt/ml/processing/output/checkpoint-13800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:52:30,879 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-13800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:52:30,879 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-13800/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m{'loss': 0.353, 'learning_rate': 1.2394611038678836e-05, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 00:55:49,312 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 00:55:49,314 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 00:55:49,315 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 00:55:49,315 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 00:57:33 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.46772637963294983, 'eval_accuracy': 0.8269994905756495, 'eval_runtime': 104.5142, 'eval_samples_per_second': 93.911, 'eval_steps_per_second': 11.74, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 00:57:33,829 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-14000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 00:57:33,830 >> Configuration saved in /opt/ml/processing/output/checkpoint-14000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 00:57:34,497 >> Model weights saved in /opt/ml/processing/output/checkpoint-14000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 00:57:34,498 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-14000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 00:57:34,498 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-14000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:00:52,693 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:00:52,695 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:00:52,695 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:00:52,695 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 01:02:37 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4714691638946533, 'eval_accuracy': 0.8278145695364238, 'eval_runtime': 104.5348, 'eval_samples_per_second': 93.892, 'eval_steps_per_second': 11.738, 'epoch': 1.16}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:02:37,231 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-14200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:02:37,232 >> Configuration saved in /opt/ml/processing/output/checkpoint-14200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:02:37,915 >> Model weights saved in /opt/ml/processing/output/checkpoint-14200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:02:37,915 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-14200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:02:37,915 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-14200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:05:56,275 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:05:56,277 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:05:56,277 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:05:56,277 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 01:07:41 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.47534793615341187, 'eval_accuracy': 0.8237391747325522, 'eval_runtime': 104.8497, 'eval_samples_per_second': 93.61, 'eval_steps_per_second': 11.702, 'epoch': 1.17}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:07:41,127 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-14400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:07:41,128 >> Configuration saved in /opt/ml/processing/output/checkpoint-14400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:07:41,815 >> Model weights saved in /opt/ml/processing/output/checkpoint-14400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:07:41,815 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-14400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:07:41,816 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-14400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3568, 'learning_rate': 1.2122990004345938e-05, 'epoch': 1.18}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:11:00,387 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:11:00,389 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:11:00,389 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:11:00,389 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 01:12:45 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.46338197588920593, 'eval_accuracy': 0.8265919510952624, 'eval_runtime': 104.6213, 'eval_samples_per_second': 93.815, 'eval_steps_per_second': 11.728, 'epoch': 1.19}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:12:45,011 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-14600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:12:45,012 >> Configuration saved in /opt/ml/processing/output/checkpoint-14600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:12:45,705 >> Model weights saved in /opt/ml/processing/output/checkpoint-14600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:12:45,706 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-14600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:12:45,706 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-14600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:16:03,759 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:16:03,761 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:16:03,761 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:16:03,761 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 01:17:48 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.46259167790412903, 'eval_accuracy': 0.8291390728476821, 'eval_runtime': 104.3221, 'eval_samples_per_second': 94.084, 'eval_steps_per_second': 11.762, 'epoch': 1.21}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:17:48,084 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-14800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:17:48,085 >> Configuration saved in /opt/ml/processing/output/checkpoint-14800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:17:48,766 >> Model weights saved in /opt/ml/processing/output/checkpoint-14800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:17:48,767 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-14800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:17:48,767 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-14800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.355, 'learning_rate': 1.185136897001304e-05, 'epoch': 1.22}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:21:06,783 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:21:06,785 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:21:06,785 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:21:06,785 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 01:22:51 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.486528605222702, 'eval_accuracy': 0.8218033622007132, 'eval_runtime': 104.549, 'eval_samples_per_second': 93.879, 'eval_steps_per_second': 11.736, 'epoch': 1.22}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:22:51,334 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-15000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:22:51,335 >> Configuration saved in /opt/ml/processing/output/checkpoint-15000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:22:52,024 >> Model weights saved in /opt/ml/processing/output/checkpoint-15000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:22:52,024 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-15000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:22:52,024 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-15000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:26:10,800 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:26:10,802 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:26:10,802 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:26:10,802 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 01:27:55 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4517234265804291, 'eval_accuracy': 0.8311767702496179, 'eval_runtime': 104.3851, 'eval_samples_per_second': 94.027, 'eval_steps_per_second': 11.755, 'epoch': 1.24}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:27:55,188 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-15200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:27:55,188 >> Configuration saved in /opt/ml/processing/output/checkpoint-15200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:27:55,869 >> Model weights saved in /opt/ml/processing/output/checkpoint-15200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:27:55,870 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-15200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:27:55,870 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-15200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:31:14,077 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:31:14,079 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:31:14,079 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:31:14,079 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 01:32:58 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.46368739008903503, 'eval_accuracy': 0.8288334182373918, 'eval_runtime': 104.9083, 'eval_samples_per_second': 93.558, 'eval_steps_per_second': 11.696, 'epoch': 1.25}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:32:58,988 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-15400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:32:58,989 >> Configuration saved in /opt/ml/processing/output/checkpoint-15400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:32:59,690 >> Model weights saved in /opt/ml/processing/output/checkpoint-15400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:32:59,691 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-15400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:32:59,691 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-15400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3452, 'learning_rate': 1.157974793568014e-05, 'epoch': 1.26}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:36:17,852 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:36:17,854 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:36:17,854 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:36:17,854 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 01:38:02 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.483315646648407, 'eval_accuracy': 0.8249617931737137, 'eval_runtime': 104.8762, 'eval_samples_per_second': 93.587, 'eval_steps_per_second': 11.7, 'epoch': 1.27}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:38:02,731 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-15600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:38:02,731 >> Configuration saved in /opt/ml/processing/output/checkpoint-15600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:38:03,414 >> Model weights saved in /opt/ml/processing/output/checkpoint-15600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:38:03,415 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-15600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:38:03,415 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-15600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:41:21,803 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:41:21,805 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:41:21,805 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:41:21,805 >>   Batch size = 8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m02/13/2022 01:43:06 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.45735758543014526, 'eval_accuracy': 0.8283239938869078, 'eval_runtime': 105.0996, 'eval_samples_per_second': 93.388, 'eval_steps_per_second': 11.675, 'epoch': 1.29}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:43:06,905 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-15800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:43:06,906 >> Configuration saved in /opt/ml/processing/output/checkpoint-15800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:43:07,579 >> Model weights saved in /opt/ml/processing/output/checkpoint-15800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:43:07,580 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-15800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:43:07,580 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-15800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3507, 'learning_rate': 1.130812690134724e-05, 'epoch': 1.3}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:46:25,518 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:46:25,520 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:46:25,520 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:46:25,520 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 01:48:10 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.45802581310272217, 'eval_accuracy': 0.8330106979113602, 'eval_runtime': 104.922, 'eval_samples_per_second': 93.546, 'eval_steps_per_second': 11.694, 'epoch': 1.3}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:48:10,443 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-16000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:48:10,444 >> Configuration saved in /opt/ml/processing/output/checkpoint-16000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:48:11,129 >> Model weights saved in /opt/ml/processing/output/checkpoint-16000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:48:11,130 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-16000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:48:11,130 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-16000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:51:29,471 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:51:29,473 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:51:29,473 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:51:29,473 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 01:53:13 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4621824026107788, 'eval_accuracy': 0.8300560366785532, 'eval_runtime': 104.4365, 'eval_samples_per_second': 93.981, 'eval_steps_per_second': 11.749, 'epoch': 1.32}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:53:13,910 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-16200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:53:13,910 >> Configuration saved in /opt/ml/processing/output/checkpoint-16200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:53:14,580 >> Model weights saved in /opt/ml/processing/output/checkpoint-16200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:53:14,580 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-16200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:53:14,580 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-16200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 01:56:32,404 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 01:56:32,406 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 01:56:32,406 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 01:56:32,406 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 01:58:16 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4743872880935669, 'eval_accuracy': 0.8271013754457464, 'eval_runtime': 104.3531, 'eval_samples_per_second': 94.056, 'eval_steps_per_second': 11.758, 'epoch': 1.34}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 01:58:16,759 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-16400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 01:58:16,760 >> Configuration saved in /opt/ml/processing/output/checkpoint-16400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 01:58:17,428 >> Model weights saved in /opt/ml/processing/output/checkpoint-16400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 01:58:17,429 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-16400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 01:58:17,429 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-16400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3492, 'learning_rate': 1.1036505867014341e-05, 'epoch': 1.34}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:01:35,407 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:01:35,409 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:01:35,409 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:01:35,409 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 02:03:19 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.44929376244544983, 'eval_accuracy': 0.8325012735608762, 'eval_runtime': 104.435, 'eval_samples_per_second': 93.982, 'eval_steps_per_second': 11.749, 'epoch': 1.35}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:03:19,845 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-16600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:03:19,846 >> Configuration saved in /opt/ml/processing/output/checkpoint-16600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:03:20,528 >> Model weights saved in /opt/ml/processing/output/checkpoint-16600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:03:20,529 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-16600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:03:20,529 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-16600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:06:38,262 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:06:38,264 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:06:38,264 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:06:38,265 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 02:08:22 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.43979787826538086, 'eval_accuracy': 0.8361691288843607, 'eval_runtime': 104.5183, 'eval_samples_per_second': 93.907, 'eval_steps_per_second': 11.74, 'epoch': 1.37}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:08:22,783 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-16800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:08:22,784 >> Configuration saved in /opt/ml/processing/output/checkpoint-16800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:08:23,449 >> Model weights saved in /opt/ml/processing/output/checkpoint-16800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:08:23,450 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-16800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:08:23,450 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-16800/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m{'loss': 0.3596, 'learning_rate': 1.0764884832681443e-05, 'epoch': 1.39}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:11:41,239 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:11:41,241 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:11:41,241 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:11:41,241 >>   Batch size = 8\u001b[0m\n",
      "\n",
      "\u001b[34m02/13/2022 02:13:25 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.445220410823822, 'eval_accuracy': 0.8318899643402955, 'eval_runtime': 104.6784, 'eval_samples_per_second': 93.763, 'eval_steps_per_second': 11.722, 'epoch': 1.39}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:13:25,919 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-17000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:13:25,920 >> Configuration saved in /opt/ml/processing/output/checkpoint-17000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:13:26,597 >> Model weights saved in /opt/ml/processing/output/checkpoint-17000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:13:26,597 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-17000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:13:26,597 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-17000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:16:44,679 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:16:44,681 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:16:44,681 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:16:44,681 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 02:18:29 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4707734286785126, 'eval_accuracy': 0.8285277636271013, 'eval_runtime': 104.4574, 'eval_samples_per_second': 93.962, 'eval_steps_per_second': 11.746, 'epoch': 1.4}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:18:29,139 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-17200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:18:29,140 >> Configuration saved in /opt/ml/processing/output/checkpoint-17200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:18:29,818 >> Model weights saved in /opt/ml/processing/output/checkpoint-17200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:18:29,819 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-17200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:18:29,819 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-17200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:21:47,296 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:21:47,298 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:21:47,298 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:21:47,298 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 02:23:31 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4511159062385559, 'eval_accuracy': 0.8303616912888436, 'eval_runtime': 104.5387, 'eval_samples_per_second': 93.889, 'eval_steps_per_second': 11.737, 'epoch': 1.42}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:23:31,837 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-17400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:23:31,838 >> Configuration saved in /opt/ml/processing/output/checkpoint-17400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:23:32,524 >> Model weights saved in /opt/ml/processing/output/checkpoint-17400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:23:32,525 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-17400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:23:32,525 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-17400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3499, 'learning_rate': 1.0493263798348545e-05, 'epoch': 1.43}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:26:50,631 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:26:50,633 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:26:50,633 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:26:50,633 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 02:28:34 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4495769739151001, 'eval_accuracy': 0.8354559347936832, 'eval_runtime': 104.3142, 'eval_samples_per_second': 94.091, 'eval_steps_per_second': 11.763, 'epoch': 1.43}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:28:34,947 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-17600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:28:34,948 >> Configuration saved in /opt/ml/processing/output/checkpoint-17600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:28:35,611 >> Model weights saved in /opt/ml/processing/output/checkpoint-17600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:28:35,611 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-17600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:28:35,611 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-17600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:31:53,766 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:31:53,768 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:31:53,768 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:31:53,768 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 02:33:38 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4694417417049408, 'eval_accuracy': 0.8267957208354559, 'eval_runtime': 104.8569, 'eval_samples_per_second': 93.604, 'eval_steps_per_second': 11.702, 'epoch': 1.45}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:33:38,626 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-17800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:33:38,627 >> Configuration saved in /opt/ml/processing/output/checkpoint-17800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:33:39,305 >> Model weights saved in /opt/ml/processing/output/checkpoint-17800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:33:39,306 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-17800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:33:39,306 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-17800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3436, 'learning_rate': 1.0221642764015647e-05, 'epoch': 1.47}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:36:57,025 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:36:57,027 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:36:57,027 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:36:57,027 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 02:38:42 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4634448289871216, 'eval_accuracy': 0.8303616912888436, 'eval_runtime': 105.1505, 'eval_samples_per_second': 93.342, 'eval_steps_per_second': 11.669, 'epoch': 1.47}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:38:42,178 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-18000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:38:42,179 >> Configuration saved in /opt/ml/processing/output/checkpoint-18000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:38:42,874 >> Model weights saved in /opt/ml/processing/output/checkpoint-18000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:38:42,874 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-18000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:38:42,874 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-18000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:42:01,649 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:42:01,652 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:42:01,652 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:42:01,652 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 02:43:46 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.46016454696655273, 'eval_accuracy': 0.8316861946001018, 'eval_runtime': 104.7167, 'eval_samples_per_second': 93.729, 'eval_steps_per_second': 11.717, 'epoch': 1.48}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:43:46,369 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-18200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:43:46,370 >> Configuration saved in /opt/ml/processing/output/checkpoint-18200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:43:47,055 >> Model weights saved in /opt/ml/processing/output/checkpoint-18200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:43:47,056 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-18200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:43:47,056 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-18200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:47:05,694 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:47:05,696 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:47:05,696 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:47:05,696 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 02:48:50 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.45177552103996277, 'eval_accuracy': 0.83555781966378, 'eval_runtime': 104.6489, 'eval_samples_per_second': 93.79, 'eval_steps_per_second': 11.725, 'epoch': 1.5}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:48:50,345 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-18400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:48:50,346 >> Configuration saved in /opt/ml/processing/output/checkpoint-18400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:48:51,025 >> Model weights saved in /opt/ml/processing/output/checkpoint-18400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:48:51,026 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-18400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:48:51,026 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-18400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3474, 'learning_rate': 9.950021729682747e-06, 'epoch': 1.51}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:52:09,000 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:52:09,002 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:52:09,003 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:52:09,003 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 02:53:53 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4761042594909668, 'eval_accuracy': 0.829240957717779, 'eval_runtime': 104.7868, 'eval_samples_per_second': 93.666, 'eval_steps_per_second': 11.709, 'epoch': 1.52}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:53:53,790 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-18600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:53:53,790 >> Configuration saved in /opt/ml/processing/output/checkpoint-18600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:53:54,454 >> Model weights saved in /opt/ml/processing/output/checkpoint-18600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:53:54,454 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-18600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:53:54,454 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-18600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 02:57:12,389 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 02:57:12,391 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 02:57:12,392 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 02:57:12,392 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 02:58:57 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4432385265827179, 'eval_accuracy': 0.8360672440142639, 'eval_runtime': 104.8735, 'eval_samples_per_second': 93.589, 'eval_steps_per_second': 11.7, 'epoch': 1.53}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 02:58:57,265 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-18800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 02:58:57,266 >> Configuration saved in /opt/ml/processing/output/checkpoint-18800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 02:58:57,958 >> Model weights saved in /opt/ml/processing/output/checkpoint-18800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 02:58:57,958 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-18800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 02:58:57,958 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-18800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3439, 'learning_rate': 9.678400695349848e-06, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:02:16,691 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:02:16,693 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:02:16,693 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:02:16,693 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:04:01 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.456025093793869, 'eval_accuracy': 0.8359653591441671, 'eval_runtime': 105.1075, 'eval_samples_per_second': 93.381, 'eval_steps_per_second': 11.674, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:04:01,801 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-19000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:04:01,801 >> Configuration saved in /opt/ml/processing/output/checkpoint-19000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:04:02,491 >> Model weights saved in /opt/ml/processing/output/checkpoint-19000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:04:02,492 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-19000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:04:02,492 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-19000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:07:20,895 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:07:20,897 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:07:20,897 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:07:20,897 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:09:05 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4527376592159271, 'eval_accuracy': 0.8316861946001018, 'eval_runtime': 104.9681, 'eval_samples_per_second': 93.505, 'eval_steps_per_second': 11.689, 'epoch': 1.56}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:09:05,866 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-19200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:09:05,867 >> Configuration saved in /opt/ml/processing/output/checkpoint-19200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:09:06,539 >> Model weights saved in /opt/ml/processing/output/checkpoint-19200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:09:06,540 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-19200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:09:06,540 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-19200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:12:25,224 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:12:25,226 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:12:25,226 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:12:25,226 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:14:10 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4360826015472412, 'eval_accuracy': 0.8396332144676516, 'eval_runtime': 104.9483, 'eval_samples_per_second': 93.522, 'eval_steps_per_second': 11.691, 'epoch': 1.58}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:14:10,175 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-19400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:14:10,176 >> Configuration saved in /opt/ml/processing/output/checkpoint-19400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:14:10,842 >> Model weights saved in /opt/ml/processing/output/checkpoint-19400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:14:10,843 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-19400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:14:10,843 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-19400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3488, 'learning_rate': 9.40677966101695e-06, 'epoch': 1.59}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:17:29,100 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:17:29,102 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:17:29,102 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:17:29,102 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:19:14 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4646061658859253, 'eval_accuracy': 0.8340295466123281, 'eval_runtime': 104.9133, 'eval_samples_per_second': 93.553, 'eval_steps_per_second': 11.695, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:19:14,016 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-19600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:19:14,016 >> Configuration saved in /opt/ml/processing/output/checkpoint-19600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:19:14,696 >> Model weights saved in /opt/ml/processing/output/checkpoint-19600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:19:14,697 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-19600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:19:14,697 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-19600/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:22:32,439 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:22:32,441 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:22:32,441 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:22:32,441 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:24:17 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4462297558784485, 'eval_accuracy': 0.8342333163525216, 'eval_runtime': 104.7816, 'eval_samples_per_second': 93.671, 'eval_steps_per_second': 11.71, 'epoch': 1.61}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:24:17,223 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-19800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:24:17,224 >> Configuration saved in /opt/ml/processing/output/checkpoint-19800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:24:17,902 >> Model weights saved in /opt/ml/processing/output/checkpoint-19800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:24:17,903 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-19800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:24:17,903 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-19800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3439, 'learning_rate': 9.13515862668405e-06, 'epoch': 1.63}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:27:35,940 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:27:35,942 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:27:35,943 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:27:35,943 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:29:20 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4476785361766815, 'eval_accuracy': 0.8339276617422313, 'eval_runtime': 104.5566, 'eval_samples_per_second': 93.873, 'eval_steps_per_second': 11.735, 'epoch': 1.63}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:29:20,500 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-20000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:29:20,501 >> Configuration saved in /opt/ml/processing/output/checkpoint-20000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:29:21,182 >> Model weights saved in /opt/ml/processing/output/checkpoint-20000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:29:21,183 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-20000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:29:21,183 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-20000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:32:39,263 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:32:39,265 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:32:39,265 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:32:39,265 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:34:23 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.46026694774627686, 'eval_accuracy': 0.8337238920020377, 'eval_runtime': 104.595, 'eval_samples_per_second': 93.838, 'eval_steps_per_second': 11.731, 'epoch': 1.65}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:34:23,860 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-20200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:34:23,861 >> Configuration saved in /opt/ml/processing/output/checkpoint-20200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:34:24,541 >> Model weights saved in /opt/ml/processing/output/checkpoint-20200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:34:24,542 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-20200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:34:24,542 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-20200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:37:42,603 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:37:42,605 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:37:42,605 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:37:42,605 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:39:27 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4417038857936859, 'eval_accuracy': 0.8346408558329088, 'eval_runtime': 104.8275, 'eval_samples_per_second': 93.63, 'eval_steps_per_second': 11.705, 'epoch': 1.66}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:39:27,433 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-20400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:39:27,434 >> Configuration saved in /opt/ml/processing/output/checkpoint-20400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:39:28,100 >> Model weights saved in /opt/ml/processing/output/checkpoint-20400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:39:28,100 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-20400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:39:28,100 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-20400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3422, 'learning_rate': 8.863537592351152e-06, 'epoch': 1.67}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:42:46,204 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:42:46,206 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:42:46,206 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:42:46,206 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:44:31 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.44285717606544495, 'eval_accuracy': 0.83555781966378, 'eval_runtime': 105.3772, 'eval_samples_per_second': 93.142, 'eval_steps_per_second': 11.644, 'epoch': 1.68}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:44:31,584 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-20600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:44:31,584 >> Configuration saved in /opt/ml/processing/output/checkpoint-20600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:44:32,251 >> Model weights saved in /opt/ml/processing/output/checkpoint-20600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:44:32,252 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-20600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:44:32,252 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-20600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:47:49,876 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:47:49,878 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:47:49,878 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:47:49,878 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:49:34 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4420278072357178, 'eval_accuracy': 0.8344370860927153, 'eval_runtime': 105.0291, 'eval_samples_per_second': 93.45, 'eval_steps_per_second': 11.682, 'epoch': 1.69}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:49:34,907 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-20800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:49:34,908 >> Configuration saved in /opt/ml/processing/output/checkpoint-20800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:49:35,591 >> Model weights saved in /opt/ml/processing/output/checkpoint-20800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:49:35,591 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-20800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:49:35,592 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-20800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3513, 'learning_rate': 8.591916558018254e-06, 'epoch': 1.71}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:52:53,693 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:52:53,695 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:52:53,695 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:52:53,695 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:54:38 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.43944644927978516, 'eval_accuracy': 0.8339276617422313, 'eval_runtime': 104.3422, 'eval_samples_per_second': 94.066, 'eval_steps_per_second': 11.759, 'epoch': 1.71}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:54:38,038 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-21000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:54:38,039 >> Configuration saved in /opt/ml/processing/output/checkpoint-21000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:54:38,723 >> Model weights saved in /opt/ml/processing/output/checkpoint-21000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:54:38,723 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-21000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:54:38,723 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-21000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 03:57:57,071 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 03:57:57,073 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 03:57:57,074 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 03:57:57,074 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 03:59:41 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.43526872992515564, 'eval_accuracy': 0.8372898624554254, 'eval_runtime': 104.4252, 'eval_samples_per_second': 93.991, 'eval_steps_per_second': 11.75, 'epoch': 1.73}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 03:59:41,500 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-21200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 03:59:41,500 >> Configuration saved in /opt/ml/processing/output/checkpoint-21200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 03:59:42,172 >> Model weights saved in /opt/ml/processing/output/checkpoint-21200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 03:59:42,173 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-21200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 03:59:42,173 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-21200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:02:59,762 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:02:59,764 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:02:59,764 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:02:59,764 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 04:04:44 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.45462939143180847, 'eval_accuracy': 0.8367804381049414, 'eval_runtime': 105.006, 'eval_samples_per_second': 93.471, 'eval_steps_per_second': 11.685, 'epoch': 1.74}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 04:04:44,770 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-21400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 04:04:44,771 >> Configuration saved in /opt/ml/processing/output/checkpoint-21400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 04:04:45,461 >> Model weights saved in /opt/ml/processing/output/checkpoint-21400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 04:04:45,462 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-21400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 04:04:45,462 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-21400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3483, 'learning_rate': 8.320295523685355e-06, 'epoch': 1.75}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:08:04,051 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:08:04,053 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:08:04,053 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:08:04,053 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 04:09:48 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.433800607919693, 'eval_accuracy': 0.8407539480387163, 'eval_runtime': 104.6013, 'eval_samples_per_second': 93.832, 'eval_steps_per_second': 11.73, 'epoch': 1.76}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 04:09:48,655 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-21600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 04:09:48,656 >> Configuration saved in /opt/ml/processing/output/checkpoint-21600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 04:09:49,328 >> Model weights saved in /opt/ml/processing/output/checkpoint-21600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 04:09:49,329 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-21600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 04:09:49,329 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-21600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:13:07,141 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:13:07,143 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:13:07,143 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:13:07,143 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 04:14:51 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4344034492969513, 'eval_accuracy': 0.838920020376974, 'eval_runtime': 104.7607, 'eval_samples_per_second': 93.69, 'eval_steps_per_second': 11.712, 'epoch': 1.78}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 04:14:51,904 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-21800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 04:14:51,905 >> Configuration saved in /opt/ml/processing/output/checkpoint-21800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 04:14:52,596 >> Model weights saved in /opt/ml/processing/output/checkpoint-21800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 04:14:52,596 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-21800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 04:14:52,597 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-21800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3455, 'learning_rate': 8.048674489352455e-06, 'epoch': 1.79}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:18:10,259 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:18:10,261 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:18:10,261 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:18:10,261 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 04:19:54 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4384098947048187, 'eval_accuracy': 0.8375955170657158, 'eval_runtime': 104.3998, 'eval_samples_per_second': 94.014, 'eval_steps_per_second': 11.753, 'epoch': 1.79}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 04:19:54,661 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-22000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 04:19:54,662 >> Configuration saved in /opt/ml/processing/output/checkpoint-22000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 04:19:55,333 >> Model weights saved in /opt/ml/processing/output/checkpoint-22000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 04:19:55,334 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-22000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 04:19:55,334 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-22000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:23:12,990 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:23:12,992 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:23:12,992 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:23:12,992 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 04:24:57 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4316962957382202, 'eval_accuracy': 0.8370860927152318, 'eval_runtime': 104.5811, 'eval_samples_per_second': 93.851, 'eval_steps_per_second': 11.733, 'epoch': 1.81}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 04:24:57,574 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-22200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 04:24:57,574 >> Configuration saved in /opt/ml/processing/output/checkpoint-22200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 04:24:58,245 >> Model weights saved in /opt/ml/processing/output/checkpoint-22200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 04:24:58,245 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-22200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 04:24:58,245 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-22200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:28:15,552 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:28:15,554 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:28:15,554 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:28:15,554 >>   Batch size = 8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m02/13/2022 04:29:59 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4555748999118805, 'eval_accuracy': 0.8332144676515537, 'eval_runtime': 104.4354, 'eval_samples_per_second': 93.982, 'eval_steps_per_second': 11.749, 'epoch': 1.83}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 04:29:59,990 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-22400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 04:29:59,991 >> Configuration saved in /opt/ml/processing/output/checkpoint-22400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 04:30:00,681 >> Model weights saved in /opt/ml/processing/output/checkpoint-22400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 04:30:00,682 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-22400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 04:30:00,682 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-22400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3508, 'learning_rate': 7.777053455019557e-06, 'epoch': 1.83}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:33:18,141 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:33:18,143 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:33:18,144 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:33:18,144 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 04:35:02 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4501042664051056, 'eval_accuracy': 0.8347427407030056, 'eval_runtime': 104.4625, 'eval_samples_per_second': 93.957, 'eval_steps_per_second': 11.746, 'epoch': 1.84}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 04:35:02,606 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-22600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 04:35:02,607 >> Configuration saved in /opt/ml/processing/output/checkpoint-22600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 04:35:03,294 >> Model weights saved in /opt/ml/processing/output/checkpoint-22600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 04:35:03,295 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-22600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 04:35:03,295 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-22600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:38:21,279 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:38:21,281 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:38:21,281 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:38:21,282 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 04:40:06 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4428342878818512, 'eval_accuracy': 0.839429444727458, 'eval_runtime': 104.7892, 'eval_samples_per_second': 93.664, 'eval_steps_per_second': 11.709, 'epoch': 1.86}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 04:40:06,071 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-22800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 04:40:06,072 >> Configuration saved in /opt/ml/processing/output/checkpoint-22800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 04:40:06,757 >> Model weights saved in /opt/ml/processing/output/checkpoint-22800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 04:40:06,757 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-22800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 04:40:06,757 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-22800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3297, 'learning_rate': 7.505432420686659e-06, 'epoch': 1.87}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:43:25,178 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:43:25,181 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:43:25,181 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:43:25,181 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 04:45:10 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4387645125389099, 'eval_accuracy': 0.8387162506367805, 'eval_runtime': 104.9168, 'eval_samples_per_second': 93.55, 'eval_steps_per_second': 11.695, 'epoch': 1.87}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 04:45:10,098 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-23000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 04:45:10,099 >> Configuration saved in /opt/ml/processing/output/checkpoint-23000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 04:45:10,780 >> Model weights saved in /opt/ml/processing/output/checkpoint-23000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 04:45:10,781 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-23000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 04:45:10,781 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-23000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:48:28,552 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:48:28,554 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:48:28,554 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:48:28,554 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 04:50:13 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4390619099140167, 'eval_accuracy': 0.8405501782985226, 'eval_runtime': 104.8725, 'eval_samples_per_second': 93.59, 'eval_steps_per_second': 11.7, 'epoch': 1.89}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 04:50:13,427 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-23200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 04:50:13,428 >> Configuration saved in /opt/ml/processing/output/checkpoint-23200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 04:50:14,112 >> Model weights saved in /opt/ml/processing/output/checkpoint-23200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 04:50:14,112 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-23200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 04:50:14,112 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-23200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:53:31,662 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:53:31,664 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:53:31,664 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:53:31,664 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 04:55:16 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.44801652431488037, 'eval_accuracy': 0.8407539480387163, 'eval_runtime': 104.915, 'eval_samples_per_second': 93.552, 'eval_steps_per_second': 11.695, 'epoch': 1.91}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 04:55:16,580 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-23400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 04:55:16,581 >> Configuration saved in /opt/ml/processing/output/checkpoint-23400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 04:55:17,277 >> Model weights saved in /opt/ml/processing/output/checkpoint-23400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 04:55:17,278 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-23400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 04:55:17,278 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-23400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3355, 'learning_rate': 7.23381138635376e-06, 'epoch': 1.91}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 04:58:34,985 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 04:58:34,987 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 04:58:34,987 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 04:58:34,987 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 05:00:19 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4411632716655731, 'eval_accuracy': 0.8409577177789098, 'eval_runtime': 104.7295, 'eval_samples_per_second': 93.718, 'eval_steps_per_second': 11.716, 'epoch': 1.92}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:00:19,716 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-23600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:00:19,717 >> Configuration saved in /opt/ml/processing/output/checkpoint-23600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:00:20,388 >> Model weights saved in /opt/ml/processing/output/checkpoint-23600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:00:20,389 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-23600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:00:20,389 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-23600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:03:38,147 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:03:38,149 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:03:38,149 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:03:38,149 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 05:05:22 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.462836891412735, 'eval_accuracy': 0.8356597045338767, 'eval_runtime': 104.746, 'eval_samples_per_second': 93.703, 'eval_steps_per_second': 11.714, 'epoch': 1.94}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:05:22,895 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-23800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:05:22,896 >> Configuration saved in /opt/ml/processing/output/checkpoint-23800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:05:23,567 >> Model weights saved in /opt/ml/processing/output/checkpoint-23800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:05:23,567 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-23800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:05:23,568 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-23800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.335, 'learning_rate': 6.962190352020861e-06, 'epoch': 1.96}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:08:41,940 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:08:41,942 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:08:41,942 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:08:41,942 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 05:10:27 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4529361426830292, 'eval_accuracy': 0.8371879775853286, 'eval_runtime': 105.0749, 'eval_samples_per_second': 93.41, 'eval_steps_per_second': 11.677, 'epoch': 1.96}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:10:27,018 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-24000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:10:27,019 >> Configuration saved in /opt/ml/processing/output/checkpoint-24000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:10:27,690 >> Model weights saved in /opt/ml/processing/output/checkpoint-24000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:10:27,690 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-24000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:10:27,691 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-24000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:13:45,880 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:13:45,883 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:13:45,883 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:13:45,883 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 05:15:30 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4348946213722229, 'eval_accuracy': 0.840855832908813, 'eval_runtime': 105.0352, 'eval_samples_per_second': 93.445, 'eval_steps_per_second': 11.682, 'epoch': 1.97}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:15:30,918 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-24200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:15:30,919 >> Configuration saved in /opt/ml/processing/output/checkpoint-24200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:15:31,601 >> Model weights saved in /opt/ml/processing/output/checkpoint-24200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:15:31,601 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-24200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:15:31,602 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-24200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:18:49,782 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:18:49,784 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:18:49,784 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:18:49,784 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 05:20:34 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.43109095096588135, 'eval_accuracy': 0.8411614875191035, 'eval_runtime': 104.6054, 'eval_samples_per_second': 93.829, 'eval_steps_per_second': 11.73, 'epoch': 1.99}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:20:34,390 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-24400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:20:34,390 >> Configuration saved in /opt/ml/processing/output/checkpoint-24400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:20:35,074 >> Model weights saved in /opt/ml/processing/output/checkpoint-24400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:20:35,075 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-24400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:20:35,075 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-24400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3348, 'learning_rate': 6.690569317687963e-06, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:23:52,580 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:23:52,582 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:23:52,582 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:23:52,582 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 05:25:37 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.48507291078567505, 'eval_accuracy': 0.8383087111563933, 'eval_runtime': 105.0148, 'eval_samples_per_second': 93.463, 'eval_steps_per_second': 11.684, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:25:37,597 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-24600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:25:37,598 >> Configuration saved in /opt/ml/processing/output/checkpoint-24600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:25:38,276 >> Model weights saved in /opt/ml/processing/output/checkpoint-24600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:25:38,277 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-24600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:25:38,277 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-24600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:28:55,835 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:28:55,837 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:28:55,837 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:28:55,837 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 05:30:40 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49633175134658813, 'eval_accuracy': 0.8412633723892002, 'eval_runtime': 104.4112, 'eval_samples_per_second': 94.003, 'eval_steps_per_second': 11.752, 'epoch': 2.02}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:30:40,249 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-24800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:30:40,250 >> Configuration saved in /opt/ml/processing/output/checkpoint-24800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:30:40,937 >> Model weights saved in /opt/ml/processing/output/checkpoint-24800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:30:40,937 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-24800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:30:40,937 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-24800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2533, 'learning_rate': 6.418948283355063e-06, 'epoch': 2.04}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:33:59,370 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:33:59,372 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:33:59,372 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:33:59,372 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 05:35:43 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.48553696274757385, 'eval_accuracy': 0.8376974019358125, 'eval_runtime': 104.5854, 'eval_samples_per_second': 93.847, 'eval_steps_per_second': 11.732, 'epoch': 2.04}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:35:43,958 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-25000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:35:43,958 >> Configuration saved in /opt/ml/processing/output/checkpoint-25000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:35:44,623 >> Model weights saved in /opt/ml/processing/output/checkpoint-25000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:35:44,624 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-25000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:35:44,624 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-25000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:39:02,312 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:39:02,314 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:39:02,315 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:39:02,315 >>   Batch size = 8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m02/13/2022 05:40:47 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5132477283477783, 'eval_accuracy': 0.8367804381049414, 'eval_runtime': 105.2381, 'eval_samples_per_second': 93.265, 'eval_steps_per_second': 11.659, 'epoch': 2.05}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:40:47,553 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-25200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:40:47,554 >> Configuration saved in /opt/ml/processing/output/checkpoint-25200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:40:48,242 >> Model weights saved in /opt/ml/processing/output/checkpoint-25200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:40:48,242 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-25200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:40:48,243 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-25200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:44:06,542 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:44:06,544 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:44:06,544 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:44:06,544 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 05:45:51 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5036939978599548, 'eval_accuracy': 0.8392256749872644, 'eval_runtime': 104.7601, 'eval_samples_per_second': 93.69, 'eval_steps_per_second': 11.712, 'epoch': 2.07}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:45:51,304 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-25400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:45:51,305 >> Configuration saved in /opt/ml/processing/output/checkpoint-25400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:45:51,965 >> Model weights saved in /opt/ml/processing/output/checkpoint-25400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:45:51,966 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-25400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:45:51,966 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-25400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2338, 'learning_rate': 6.147327249022165e-06, 'epoch': 2.08}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:49:10,357 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:49:10,359 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:49:10,359 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:49:10,359 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 05:50:54 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49378249049186707, 'eval_accuracy': 0.8383087111563933, 'eval_runtime': 104.5637, 'eval_samples_per_second': 93.866, 'eval_steps_per_second': 11.734, 'epoch': 2.09}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:50:54,925 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-25600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:50:54,926 >> Configuration saved in /opt/ml/processing/output/checkpoint-25600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:50:55,606 >> Model weights saved in /opt/ml/processing/output/checkpoint-25600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:50:55,606 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-25600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:50:55,606 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-25600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:54:13,663 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:54:13,665 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:54:13,665 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:54:13,665 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 05:55:58 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.48936691880226135, 'eval_accuracy': 0.8406520631686195, 'eval_runtime': 104.6782, 'eval_samples_per_second': 93.764, 'eval_steps_per_second': 11.722, 'epoch': 2.1}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 05:55:58,344 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-25800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 05:55:58,345 >> Configuration saved in /opt/ml/processing/output/checkpoint-25800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 05:55:59,030 >> Model weights saved in /opt/ml/processing/output/checkpoint-25800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 05:55:59,031 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-25800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 05:55:59,031 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-25800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2404, 'learning_rate': 5.8757062146892665e-06, 'epoch': 2.12}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 05:59:16,918 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 05:59:16,920 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 05:59:16,920 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 05:59:16,920 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 06:01:01 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5109238624572754, 'eval_accuracy': 0.8333163525216505, 'eval_runtime': 104.6131, 'eval_samples_per_second': 93.822, 'eval_steps_per_second': 11.729, 'epoch': 2.12}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:01:01,534 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-26000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:01:01,535 >> Configuration saved in /opt/ml/processing/output/checkpoint-26000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:01:02,227 >> Model weights saved in /opt/ml/processing/output/checkpoint-26000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:01:02,228 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-26000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:01:02,228 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-26000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:04:19,820 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:04:19,822 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:04:19,822 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:04:19,822 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 06:06:04 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5145465731620789, 'eval_accuracy': 0.835048395313296, 'eval_runtime': 104.6533, 'eval_samples_per_second': 93.786, 'eval_steps_per_second': 11.724, 'epoch': 2.13}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:06:04,475 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-26200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:06:04,476 >> Configuration saved in /opt/ml/processing/output/checkpoint-26200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:06:05,169 >> Model weights saved in /opt/ml/processing/output/checkpoint-26200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:06:05,170 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-26200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:06:05,170 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-26200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:09:23,283 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:09:23,285 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:09:23,286 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:09:23,286 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 06:11:07 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49693310260772705, 'eval_accuracy': 0.8402445236882323, 'eval_runtime': 104.6197, 'eval_samples_per_second': 93.816, 'eval_steps_per_second': 11.728, 'epoch': 2.15}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:11:07,906 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-26400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:11:07,906 >> Configuration saved in /opt/ml/processing/output/checkpoint-26400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:11:08,592 >> Model weights saved in /opt/ml/processing/output/checkpoint-26400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:11:08,592 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-26400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:11:08,592 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-26400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2324, 'learning_rate': 5.6040851803563665e-06, 'epoch': 2.16}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:14:26,218 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:14:26,220 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:14:26,220 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:14:26,220 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 06:16:10 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5205555558204651, 'eval_accuracy': 0.8367804381049414, 'eval_runtime': 104.2512, 'eval_samples_per_second': 94.148, 'eval_steps_per_second': 11.77, 'epoch': 2.17}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:16:10,471 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-26600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:16:10,472 >> Configuration saved in /opt/ml/processing/output/checkpoint-26600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:16:11,150 >> Model weights saved in /opt/ml/processing/output/checkpoint-26600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:16:11,150 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-26600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:16:11,150 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-26600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:19:28,647 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:19:28,649 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:19:28,649 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:19:28,649 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 06:21:13 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5090477466583252, 'eval_accuracy': 0.8360672440142639, 'eval_runtime': 104.4196, 'eval_samples_per_second': 93.996, 'eval_steps_per_second': 11.751, 'epoch': 2.18}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:21:13,069 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-26800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:21:13,070 >> Configuration saved in /opt/ml/processing/output/checkpoint-26800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:21:13,730 >> Model weights saved in /opt/ml/processing/output/checkpoint-26800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:21:13,731 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-26800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:21:13,731 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-26800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2323, 'learning_rate': 5.332464146023468e-06, 'epoch': 2.2}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:24:31,727 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:24:31,729 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:24:31,729 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:24:31,729 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 06:26:16 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5064616203308105, 'eval_accuracy': 0.8365766683647479, 'eval_runtime': 104.4948, 'eval_samples_per_second': 93.928, 'eval_steps_per_second': 11.742, 'epoch': 2.2}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:26:16,224 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-27000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:26:16,225 >> Configuration saved in /opt/ml/processing/output/checkpoint-27000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:26:16,905 >> Model weights saved in /opt/ml/processing/output/checkpoint-27000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:26:16,906 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-27000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:26:16,906 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-27000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:29:34,717 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:29:34,720 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:29:34,720 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:29:34,720 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 06:31:19 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5075522661209106, 'eval_accuracy': 0.8368823229750382, 'eval_runtime': 104.3918, 'eval_samples_per_second': 94.021, 'eval_steps_per_second': 11.754, 'epoch': 2.22}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:31:19,112 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-27200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:31:19,113 >> Configuration saved in /opt/ml/processing/output/checkpoint-27200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:31:19,782 >> Model weights saved in /opt/ml/processing/output/checkpoint-27200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:31:19,783 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-27200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:31:19,783 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-27200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:34:37,272 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:34:37,274 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:34:37,274 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:34:37,274 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 06:36:22 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49662885069847107, 'eval_accuracy': 0.8393275598573612, 'eval_runtime': 104.8315, 'eval_samples_per_second': 93.626, 'eval_steps_per_second': 11.705, 'epoch': 2.23}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:36:22,106 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-27400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:36:22,107 >> Configuration saved in /opt/ml/processing/output/checkpoint-27400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:36:22,790 >> Model weights saved in /opt/ml/processing/output/checkpoint-27400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:36:22,791 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-27400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:36:22,791 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-27400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2394, 'learning_rate': 5.06084311169057e-06, 'epoch': 2.24}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:39:41,239 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:39:41,242 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:39:41,242 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:39:41,242 >>   Batch size = 8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m02/13/2022 06:41:25 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49645334482192993, 'eval_accuracy': 0.8392256749872644, 'eval_runtime': 104.6611, 'eval_samples_per_second': 93.779, 'eval_steps_per_second': 11.724, 'epoch': 2.25}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:41:25,903 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-27600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:41:25,904 >> Configuration saved in /opt/ml/processing/output/checkpoint-27600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:41:26,583 >> Model weights saved in /opt/ml/processing/output/checkpoint-27600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:41:26,584 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-27600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:41:26,584 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-27600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:44:45,407 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:44:45,409 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:44:45,409 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:44:45,409 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 06:46:30 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5062791705131531, 'eval_accuracy': 0.8361691288843607, 'eval_runtime': 104.7695, 'eval_samples_per_second': 93.682, 'eval_steps_per_second': 11.711, 'epoch': 2.27}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:46:30,184 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-27800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:46:30,185 >> Configuration saved in /opt/ml/processing/output/checkpoint-27800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:46:30,866 >> Model weights saved in /opt/ml/processing/output/checkpoint-27800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:46:30,866 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-27800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:46:30,867 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-27800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2302, 'learning_rate': 4.789222077357671e-06, 'epoch': 2.28}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:49:49,226 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:49:49,228 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:49:49,228 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:49:49,228 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 06:51:33 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.520899772644043, 'eval_accuracy': 0.8376974019358125, 'eval_runtime': 104.5079, 'eval_samples_per_second': 93.916, 'eval_steps_per_second': 11.741, 'epoch': 2.28}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:51:33,738 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-28000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:51:33,739 >> Configuration saved in /opt/ml/processing/output/checkpoint-28000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:51:34,418 >> Model weights saved in /opt/ml/processing/output/checkpoint-28000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:51:34,419 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-28000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:51:34,419 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-28000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:54:52,174 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:54:52,176 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:54:52,176 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:54:52,176 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 06:56:37 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5055261850357056, 'eval_accuracy': 0.8382068262862965, 'eval_runtime': 104.8653, 'eval_samples_per_second': 93.596, 'eval_steps_per_second': 11.701, 'epoch': 2.3}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 06:56:37,042 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-28200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 06:56:37,043 >> Configuration saved in /opt/ml/processing/output/checkpoint-28200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 06:56:37,724 >> Model weights saved in /opt/ml/processing/output/checkpoint-28200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 06:56:37,725 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-28200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 06:56:37,725 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-28200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 06:59:55,709 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 06:59:55,712 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 06:59:55,712 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 06:59:55,712 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:01:40 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5195873379707336, 'eval_accuracy': 0.8362710137544574, 'eval_runtime': 104.9766, 'eval_samples_per_second': 93.497, 'eval_steps_per_second': 11.688, 'epoch': 2.31}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:01:40,689 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-28400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:01:40,689 >> Configuration saved in /opt/ml/processing/output/checkpoint-28400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:01:41,366 >> Model weights saved in /opt/ml/processing/output/checkpoint-28400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:01:41,367 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-28400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:01:41,367 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-28400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2372, 'learning_rate': 4.5176010430247726e-06, 'epoch': 2.32}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 07:04:59,397 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 07:04:59,399 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 07:04:59,399 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 07:04:59,399 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:06:44 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5006507039070129, 'eval_accuracy': 0.8386143657666837, 'eval_runtime': 104.839, 'eval_samples_per_second': 93.62, 'eval_steps_per_second': 11.704, 'epoch': 2.33}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:06:44,238 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-28600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:06:44,239 >> Configuration saved in /opt/ml/processing/output/checkpoint-28600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:06:44,918 >> Model weights saved in /opt/ml/processing/output/checkpoint-28600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:06:44,919 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-28600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:06:44,919 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-28600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 07:10:03,110 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 07:10:03,112 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 07:10:03,112 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 07:10:03,112 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:11:48 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5124596357345581, 'eval_accuracy': 0.83841059602649, 'eval_runtime': 105.1437, 'eval_samples_per_second': 93.348, 'eval_steps_per_second': 11.67, 'epoch': 2.35}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:11:48,256 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-28800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:11:48,257 >> Configuration saved in /opt/ml/processing/output/checkpoint-28800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:11:48,932 >> Model weights saved in /opt/ml/processing/output/checkpoint-28800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:11:48,933 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-28800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:11:48,933 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-28800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2326, 'learning_rate': 4.2459800086918734e-06, 'epoch': 2.36}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 07:15:07,898 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 07:15:07,900 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 07:15:07,900 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 07:15:07,900 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:16:52 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5193194150924683, 'eval_accuracy': 0.8358634742740703, 'eval_runtime': 104.8702, 'eval_samples_per_second': 93.592, 'eval_steps_per_second': 11.7, 'epoch': 2.36}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:16:52,770 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-29000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:16:52,771 >> Configuration saved in /opt/ml/processing/output/checkpoint-29000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:16:53,454 >> Model weights saved in /opt/ml/processing/output/checkpoint-29000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:16:53,454 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-29000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:16:53,455 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-29000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 07:20:11,445 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 07:20:11,446 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 07:20:11,447 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 07:20:11,447 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:21:56 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.515984058380127, 'eval_accuracy': 0.8377992868059093, 'eval_runtime': 104.6248, 'eval_samples_per_second': 93.811, 'eval_steps_per_second': 11.728, 'epoch': 2.38}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:21:56,072 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-29200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:21:56,073 >> Configuration saved in /opt/ml/processing/output/checkpoint-29200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:21:56,735 >> Model weights saved in /opt/ml/processing/output/checkpoint-29200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:21:56,736 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-29200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:21:56,736 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-29200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 07:25:14,696 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 07:25:14,699 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 07:25:14,699 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 07:25:14,699 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:26:59 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5104573369026184, 'eval_accuracy': 0.8393275598573612, 'eval_runtime': 104.9465, 'eval_samples_per_second': 93.524, 'eval_steps_per_second': 11.692, 'epoch': 2.4}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:26:59,645 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-29400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:26:59,646 >> Configuration saved in /opt/ml/processing/output/checkpoint-29400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:27:00,318 >> Model weights saved in /opt/ml/processing/output/checkpoint-29400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:27:00,318 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-29400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:27:00,318 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-29400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2296, 'learning_rate': 3.974358974358974e-06, 'epoch': 2.4}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 07:30:18,366 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 07:30:18,368 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 07:30:18,368 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 07:30:18,368 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:32:03 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.521169126033783, 'eval_accuracy': 0.8371879775853286, 'eval_runtime': 104.9427, 'eval_samples_per_second': 93.527, 'eval_steps_per_second': 11.692, 'epoch': 2.41}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:32:03,311 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-29600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:32:03,312 >> Configuration saved in /opt/ml/processing/output/checkpoint-29600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:32:04,001 >> Model weights saved in /opt/ml/processing/output/checkpoint-29600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:32:04,002 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-29600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:32:04,002 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-29600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 07:35:22,002 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 07:35:22,004 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 07:35:22,004 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 07:35:22,004 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:37:07 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5140287280082703, 'eval_accuracy': 0.8363728986245542, 'eval_runtime': 105.1896, 'eval_samples_per_second': 93.308, 'eval_steps_per_second': 11.665, 'epoch': 2.43}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:37:07,194 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-29800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:37:07,195 >> Configuration saved in /opt/ml/processing/output/checkpoint-29800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:37:07,891 >> Model weights saved in /opt/ml/processing/output/checkpoint-29800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:37:07,891 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-29800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:37:07,891 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-29800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2223, 'learning_rate': 3.702737940026076e-06, 'epoch': 2.44}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 07:40:26,709 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 07:40:26,711 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 07:40:26,712 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 07:40:26,712 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:42:11 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5252009034156799, 'eval_accuracy': 0.8362710137544574, 'eval_runtime': 105.0768, 'eval_samples_per_second': 93.408, 'eval_steps_per_second': 11.677, 'epoch': 2.44}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:42:11,789 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-30000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:42:11,790 >> Configuration saved in /opt/ml/processing/output/checkpoint-30000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:42:12,475 >> Model weights saved in /opt/ml/processing/output/checkpoint-30000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:42:12,475 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-30000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:42:12,475 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-30000/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 07:45:30,833 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 07:45:30,835 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 07:45:30,835 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 07:45:30,835 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:47:15 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5095880031585693, 'eval_accuracy': 0.8385124808965868, 'eval_runtime': 105.0672, 'eval_samples_per_second': 93.416, 'eval_steps_per_second': 11.678, 'epoch': 2.46}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:47:15,903 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-30200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:47:15,904 >> Configuration saved in /opt/ml/processing/output/checkpoint-30200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:47:16,578 >> Model weights saved in /opt/ml/processing/output/checkpoint-30200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:47:16,579 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-30200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:47:16,579 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-30200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 07:50:35,036 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 07:50:35,038 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 07:50:35,038 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 07:50:35,038 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:52:19 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5008518695831299, 'eval_accuracy': 0.839429444727458, 'eval_runtime': 104.8398, 'eval_samples_per_second': 93.619, 'eval_steps_per_second': 11.704, 'epoch': 2.48}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:52:19,878 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-30400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:52:19,879 >> Configuration saved in /opt/ml/processing/output/checkpoint-30400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:52:20,566 >> Model weights saved in /opt/ml/processing/output/checkpoint-30400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:52:20,567 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-30400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:52:20,567 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-30400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2294, 'learning_rate': 3.431116905693177e-06, 'epoch': 2.49}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 07:55:38,749 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 07:55:38,751 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 07:55:38,751 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 07:55:38,751 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 07:57:23 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5074080228805542, 'eval_accuracy': 0.8401426388181356, 'eval_runtime': 104.9329, 'eval_samples_per_second': 93.536, 'eval_steps_per_second': 11.693, 'epoch': 2.49}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 07:57:23,684 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-30600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 07:57:23,685 >> Configuration saved in /opt/ml/processing/output/checkpoint-30600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 07:57:24,356 >> Model weights saved in /opt/ml/processing/output/checkpoint-30600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 07:57:24,357 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-30600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 07:57:24,357 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-30600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:00:42,618 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:00:42,620 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:00:42,620 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:00:42,620 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:02:27 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5081354379653931, 'eval_accuracy': 0.8376974019358125, 'eval_runtime': 105.0978, 'eval_samples_per_second': 93.389, 'eval_steps_per_second': 11.675, 'epoch': 2.51}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:02:27,718 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-30800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:02:27,719 >> Configuration saved in /opt/ml/processing/output/checkpoint-30800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:02:28,395 >> Model weights saved in /opt/ml/processing/output/checkpoint-30800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:02:28,396 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-30800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:02:28,396 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-30800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2308, 'learning_rate': 3.1594958713602786e-06, 'epoch': 2.53}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:05:46,648 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:05:46,650 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:05:46,650 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:05:46,650 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:07:31 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5047122240066528, 'eval_accuracy': 0.83841059602649, 'eval_runtime': 105.212, 'eval_samples_per_second': 93.288, 'eval_steps_per_second': 11.662, 'epoch': 2.53}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:07:31,862 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-31000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:07:31,863 >> Configuration saved in /opt/ml/processing/output/checkpoint-31000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:07:32,536 >> Model weights saved in /opt/ml/processing/output/checkpoint-31000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:07:32,537 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-31000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:07:32,537 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-31000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:10:51,016 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:10:51,018 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:10:51,018 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:10:51,018 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:12:36 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49705997109413147, 'eval_accuracy': 0.8409577177789098, 'eval_runtime': 105.0015, 'eval_samples_per_second': 93.475, 'eval_steps_per_second': 11.686, 'epoch': 2.54}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:12:36,020 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-31200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:12:36,021 >> Configuration saved in /opt/ml/processing/output/checkpoint-31200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:12:36,686 >> Model weights saved in /opt/ml/processing/output/checkpoint-31200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:12:36,687 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-31200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:12:36,687 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-31200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:15:54,950 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:15:54,952 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:15:54,952 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:15:54,952 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:17:39 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.509962260723114, 'eval_accuracy': 0.8400407539480387, 'eval_runtime': 104.8159, 'eval_samples_per_second': 93.64, 'eval_steps_per_second': 11.706, 'epoch': 2.56}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:17:39,769 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-31400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:17:39,769 >> Configuration saved in /opt/ml/processing/output/checkpoint-31400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:17:40,436 >> Model weights saved in /opt/ml/processing/output/checkpoint-31400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:17:40,436 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-31400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:17:40,436 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-31400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2308, 'learning_rate': 2.8878748370273795e-06, 'epoch': 2.57}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:20:58,795 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:20:58,798 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:20:58,798 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:20:58,798 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:22:43 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5036798715591431, 'eval_accuracy': 0.8392256749872644, 'eval_runtime': 104.9963, 'eval_samples_per_second': 93.48, 'eval_steps_per_second': 11.686, 'epoch': 2.57}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:22:43,794 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-31600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:22:43,795 >> Configuration saved in /opt/ml/processing/output/checkpoint-31600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:22:44,479 >> Model weights saved in /opt/ml/processing/output/checkpoint-31600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:22:44,480 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-31600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:22:44,480 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-31600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:26:02,680 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:26:02,682 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:26:02,682 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:26:02,682 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:27:47 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5092684626579285, 'eval_accuracy': 0.8370860927152318, 'eval_runtime': 104.9308, 'eval_samples_per_second': 93.538, 'eval_steps_per_second': 11.693, 'epoch': 2.59}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:27:47,613 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-31800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:27:47,614 >> Configuration saved in /opt/ml/processing/output/checkpoint-31800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:27:48,293 >> Model weights saved in /opt/ml/processing/output/checkpoint-31800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:27:48,294 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-31800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:27:48,294 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-31800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2441, 'learning_rate': 2.6162538026944812e-06, 'epoch': 2.61}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:31:06,415 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:31:06,417 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:31:06,417 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:31:06,417 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:32:51 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49548104405403137, 'eval_accuracy': 0.841365257259297, 'eval_runtime': 104.61, 'eval_samples_per_second': 93.825, 'eval_steps_per_second': 11.729, 'epoch': 2.61}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:32:51,027 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-32000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:32:51,028 >> Configuration saved in /opt/ml/processing/output/checkpoint-32000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:32:51,705 >> Model weights saved in /opt/ml/processing/output/checkpoint-32000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:32:51,705 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-32000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:32:51,705 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-32000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:36:09,889 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:36:09,891 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:36:09,891 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:36:09,891 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:37:54 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49294933676719666, 'eval_accuracy': 0.8411614875191035, 'eval_runtime': 104.9616, 'eval_samples_per_second': 93.51, 'eval_steps_per_second': 11.69, 'epoch': 2.62}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:37:54,853 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-32200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:37:54,854 >> Configuration saved in /opt/ml/processing/output/checkpoint-32200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:37:55,538 >> Model weights saved in /opt/ml/processing/output/checkpoint-32200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:37:55,539 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-32200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:37:55,539 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-32200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:41:14,040 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:41:14,042 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:41:14,042 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:41:14,042 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:42:59 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.493315190076828, 'eval_accuracy': 0.8416709118695873, 'eval_runtime': 105.3685, 'eval_samples_per_second': 93.149, 'eval_steps_per_second': 11.645, 'epoch': 2.64}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:42:59,411 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-32400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:42:59,412 >> Configuration saved in /opt/ml/processing/output/checkpoint-32400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:43:00,083 >> Model weights saved in /opt/ml/processing/output/checkpoint-32400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:43:00,083 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-32400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:43:00,084 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-32400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2407, 'learning_rate': 2.344632768361582e-06, 'epoch': 2.65}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:46:18,425 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:46:18,427 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:46:18,427 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:46:18,427 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:48:03 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5006418228149414, 'eval_accuracy': 0.8396332144676516, 'eval_runtime': 104.685, 'eval_samples_per_second': 93.757, 'eval_steps_per_second': 11.721, 'epoch': 2.66}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:48:03,113 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-32600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:48:03,113 >> Configuration saved in /opt/ml/processing/output/checkpoint-32600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:48:03,781 >> Model weights saved in /opt/ml/processing/output/checkpoint-32600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:48:03,781 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-32600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:48:03,782 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-32600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:51:21,582 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:51:21,584 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:51:21,584 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:51:21,584 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:53:06 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5004634857177734, 'eval_accuracy': 0.8417727967396842, 'eval_runtime': 104.6632, 'eval_samples_per_second': 93.777, 'eval_steps_per_second': 11.723, 'epoch': 2.67}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:53:06,248 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-32800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:53:06,249 >> Configuration saved in /opt/ml/processing/output/checkpoint-32800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:53:06,913 >> Model weights saved in /opt/ml/processing/output/checkpoint-32800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:53:06,914 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-32800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:53:06,914 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-32800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2362, 'learning_rate': 2.0730117340286834e-06, 'epoch': 2.69}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 08:56:24,920 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 08:56:24,922 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 08:56:24,922 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 08:56:24,922 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 08:58:09 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.507716715335846, 'eval_accuracy': 0.8404482934284259, 'eval_runtime': 104.6653, 'eval_samples_per_second': 93.775, 'eval_steps_per_second': 11.723, 'epoch': 2.69}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 08:58:09,588 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-33000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 08:58:09,589 >> Configuration saved in /opt/ml/processing/output/checkpoint-33000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 08:58:10,257 >> Model weights saved in /opt/ml/processing/output/checkpoint-33000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 08:58:10,257 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-33000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 08:58:10,258 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-33000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:01:27,863 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:01:27,865 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:01:27,865 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:01:27,865 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:03:12 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5000537037849426, 'eval_accuracy': 0.8397350993377484, 'eval_runtime': 104.9187, 'eval_samples_per_second': 93.549, 'eval_steps_per_second': 11.695, 'epoch': 2.71}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:03:12,784 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-33200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:03:12,785 >> Configuration saved in /opt/ml/processing/output/checkpoint-33200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:03:13,470 >> Model weights saved in /opt/ml/processing/output/checkpoint-33200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:03:13,471 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-33200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:03:13,471 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-33200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:06:31,492 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:06:31,494 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:06:31,494 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:06:31,494 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:08:16 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5116192698478699, 'eval_accuracy': 0.8379011716760061, 'eval_runtime': 105.2085, 'eval_samples_per_second': 93.291, 'eval_steps_per_second': 11.663, 'epoch': 2.72}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:08:16,703 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-33400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:08:16,704 >> Configuration saved in /opt/ml/processing/output/checkpoint-33400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:08:17,390 >> Model weights saved in /opt/ml/processing/output/checkpoint-33400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:08:17,391 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-33400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:08:17,391 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-33400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2291, 'learning_rate': 1.8013906996957845e-06, 'epoch': 2.73}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:11:36,046 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:11:36,048 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:11:36,049 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:11:36,049 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:13:21 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5061742067337036, 'eval_accuracy': 0.8366785532348446, 'eval_runtime': 105.1336, 'eval_samples_per_second': 93.357, 'eval_steps_per_second': 11.671, 'epoch': 2.74}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:13:21,182 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-33600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:13:21,183 >> Configuration saved in /opt/ml/processing/output/checkpoint-33600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:13:21,854 >> Model weights saved in /opt/ml/processing/output/checkpoint-33600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:13:21,855 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-33600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:13:21,855 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-33600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:16:39,817 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:16:39,819 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:16:39,819 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:16:39,819 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:18:24 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4966631829738617, 'eval_accuracy': 0.8395313295975547, 'eval_runtime': 104.9413, 'eval_samples_per_second': 93.528, 'eval_steps_per_second': 11.692, 'epoch': 2.75}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:18:24,761 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-33800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:18:24,761 >> Configuration saved in /opt/ml/processing/output/checkpoint-33800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:18:25,432 >> Model weights saved in /opt/ml/processing/output/checkpoint-33800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:18:25,432 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-33800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:18:25,433 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-33800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2381, 'learning_rate': 1.5297696653628858e-06, 'epoch': 2.77}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:21:43,971 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:21:43,973 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:21:43,973 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:21:43,973 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:23:28 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4960918128490448, 'eval_accuracy': 0.8399388690779419, 'eval_runtime': 104.68, 'eval_samples_per_second': 93.762, 'eval_steps_per_second': 11.721, 'epoch': 2.77}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:23:28,653 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-34000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:23:28,654 >> Configuration saved in /opt/ml/processing/output/checkpoint-34000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:23:29,322 >> Model weights saved in /opt/ml/processing/output/checkpoint-34000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:23:29,322 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-34000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:23:29,322 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-34000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:26:47,416 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:26:47,418 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:26:47,418 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:26:47,418 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:28:32 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4991554617881775, 'eval_accuracy': 0.8379011716760061, 'eval_runtime': 104.9693, 'eval_samples_per_second': 93.503, 'eval_steps_per_second': 11.689, 'epoch': 2.79}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:28:32,387 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-34200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:28:32,388 >> Configuration saved in /opt/ml/processing/output/checkpoint-34200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:28:33,066 >> Model weights saved in /opt/ml/processing/output/checkpoint-34200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:28:33,067 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-34200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:28:33,067 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-34200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:31:51,658 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:31:51,660 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:31:51,660 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:31:51,660 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:33:36 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49970388412475586, 'eval_accuracy': 0.8386143657666837, 'eval_runtime': 104.8785, 'eval_samples_per_second': 93.584, 'eval_steps_per_second': 11.699, 'epoch': 2.8}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:33:36,539 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-34400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:33:36,540 >> Configuration saved in /opt/ml/processing/output/checkpoint-34400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:33:37,223 >> Model weights saved in /opt/ml/processing/output/checkpoint-34400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:33:37,224 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-34400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:33:37,224 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-34400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2424, 'learning_rate': 1.258148631029987e-06, 'epoch': 2.81}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:36:55,633 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:36:55,635 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:36:55,636 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:36:55,636 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:38:40 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49748730659484863, 'eval_accuracy': 0.8396332144676516, 'eval_runtime': 104.8927, 'eval_samples_per_second': 93.572, 'eval_steps_per_second': 11.698, 'epoch': 2.82}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:38:40,529 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-34600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:38:40,529 >> Configuration saved in /opt/ml/processing/output/checkpoint-34600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:38:41,201 >> Model weights saved in /opt/ml/processing/output/checkpoint-34600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:38:41,202 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-34600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:38:41,202 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-34600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:41:59,537 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:41:59,539 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:41:59,539 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:41:59,539 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:43:44 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4995777904987335, 'eval_accuracy': 0.8404482934284259, 'eval_runtime': 105.1386, 'eval_samples_per_second': 93.353, 'eval_steps_per_second': 11.67, 'epoch': 2.84}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:43:44,677 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-34800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:43:44,678 >> Configuration saved in /opt/ml/processing/output/checkpoint-34800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:43:45,350 >> Model weights saved in /opt/ml/processing/output/checkpoint-34800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:43:45,351 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-34800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:43:45,351 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-34800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2354, 'learning_rate': 9.865275966970884e-07, 'epoch': 2.85}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:47:03,078 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:47:03,081 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:47:03,081 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:47:03,081 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:48:47 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5004523396492004, 'eval_accuracy': 0.8398369842078451, 'eval_runtime': 104.8825, 'eval_samples_per_second': 93.581, 'eval_steps_per_second': 11.699, 'epoch': 2.85}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:48:47,963 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-35000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:48:47,964 >> Configuration saved in /opt/ml/processing/output/checkpoint-35000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:48:48,646 >> Model weights saved in /opt/ml/processing/output/checkpoint-35000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:48:48,647 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-35000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:48:48,647 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-35000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:52:06,263 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:52:06,265 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:52:06,265 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:52:06,265 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:53:50 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.496532142162323, 'eval_accuracy': 0.8398369842078451, 'eval_runtime': 104.5852, 'eval_samples_per_second': 93.847, 'eval_steps_per_second': 11.732, 'epoch': 2.87}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:53:50,850 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-35200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:53:50,851 >> Configuration saved in /opt/ml/processing/output/checkpoint-35200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:53:51,531 >> Model weights saved in /opt/ml/processing/output/checkpoint-35200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:53:51,532 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-35200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:53:51,532 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-35200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 09:57:09,595 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 09:57:09,597 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 09:57:09,597 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 09:57:09,597 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 09:58:54 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4957488477230072, 'eval_accuracy': 0.840855832908813, 'eval_runtime': 105.149, 'eval_samples_per_second': 93.344, 'eval_steps_per_second': 11.669, 'epoch': 2.88}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 09:58:54,746 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-35400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 09:58:54,747 >> Configuration saved in /opt/ml/processing/output/checkpoint-35400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 09:58:55,432 >> Model weights saved in /opt/ml/processing/output/checkpoint-35400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 09:58:55,433 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-35400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 09:58:55,433 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-35400/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m{'loss': 0.242, 'learning_rate': 7.149065623641896e-07, 'epoch': 2.89}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 10:02:13,109 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 10:02:13,111 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 10:02:13,111 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 10:02:13,111 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 10:03:57 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5020843744277954, 'eval_accuracy': 0.8398369842078451, 'eval_runtime': 104.604, 'eval_samples_per_second': 93.83, 'eval_steps_per_second': 11.73, 'epoch': 2.9}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 10:03:57,716 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-35600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 10:03:57,716 >> Configuration saved in /opt/ml/processing/output/checkpoint-35600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 10:03:58,382 >> Model weights saved in /opt/ml/processing/output/checkpoint-35600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 10:03:58,382 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-35600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 10:03:58,382 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-35600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 10:07:16,223 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 10:07:16,225 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 10:07:16,225 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 10:07:16,225 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 10:09:01 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5056158304214478, 'eval_accuracy': 0.8388181355068772, 'eval_runtime': 104.9731, 'eval_samples_per_second': 93.5, 'eval_steps_per_second': 11.689, 'epoch': 2.92}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 10:09:01,198 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-35800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 10:09:01,199 >> Configuration saved in /opt/ml/processing/output/checkpoint-35800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 10:09:01,878 >> Model weights saved in /opt/ml/processing/output/checkpoint-35800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 10:09:01,879 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-35800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 10:09:01,879 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-35800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2287, 'learning_rate': 4.432855280312908e-07, 'epoch': 2.93}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 10:12:20,240 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 10:12:20,242 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 10:12:20,242 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 10:12:20,242 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 10:14:05 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5008246302604675, 'eval_accuracy': 0.8405501782985226, 'eval_runtime': 105.5035, 'eval_samples_per_second': 93.03, 'eval_steps_per_second': 11.63, 'epoch': 2.93}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 10:14:05,746 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-36000\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 10:14:05,747 >> Configuration saved in /opt/ml/processing/output/checkpoint-36000/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 10:14:06,435 >> Model weights saved in /opt/ml/processing/output/checkpoint-36000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 10:14:06,435 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-36000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 10:14:06,435 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-36000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 10:17:24,906 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 10:17:24,908 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 10:17:24,908 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 10:17:24,908 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 10:19:09 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.49953290820121765, 'eval_accuracy': 0.8403464085583291, 'eval_runtime': 104.6983, 'eval_samples_per_second': 93.746, 'eval_steps_per_second': 11.719, 'epoch': 2.95}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 10:19:09,607 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-36200\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 10:19:09,608 >> Configuration saved in /opt/ml/processing/output/checkpoint-36200/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 10:19:10,291 >> Model weights saved in /opt/ml/processing/output/checkpoint-36200/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 10:19:10,291 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-36200/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 10:19:10,292 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-36200/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 10:22:28,660 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 10:22:28,662 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 10:22:28,663 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 10:22:28,663 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 10:24:13 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5004324316978455, 'eval_accuracy': 0.840855832908813, 'eval_runtime': 104.9766, 'eval_samples_per_second': 93.497, 'eval_steps_per_second': 11.688, 'epoch': 2.97}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 10:24:13,639 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-36400\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 10:24:13,640 >> Configuration saved in /opt/ml/processing/output/checkpoint-36400/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 10:24:14,306 >> Model weights saved in /opt/ml/processing/output/checkpoint-36400/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 10:24:14,307 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-36400/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 10:24:14,307 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-36400/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2344, 'learning_rate': 1.7166449369839202e-07, 'epoch': 2.97}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 10:27:32,471 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 10:27:32,473 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 10:27:32,473 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 10:27:32,473 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 10:29:17 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5001918077468872, 'eval_accuracy': 0.840855832908813, 'eval_runtime': 104.646, 'eval_samples_per_second': 93.792, 'eval_steps_per_second': 11.725, 'epoch': 2.98}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 10:29:17,119 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-36600\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 10:29:17,120 >> Configuration saved in /opt/ml/processing/output/checkpoint-36600/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 10:29:17,803 >> Model weights saved in /opt/ml/processing/output/checkpoint-36600/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 10:29:17,803 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-36600/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 10:29:17,804 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-36600/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 10:32:35,698 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 10:32:35,700 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 10:32:35,700 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 10:32:35,700 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 10:34:20 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4995548129081726, 'eval_accuracy': 0.8409577177789098, 'eval_runtime': 105.0345, 'eval_samples_per_second': 93.445, 'eval_steps_per_second': 11.682, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 10:34:20,735 >> Saving model checkpoint to /opt/ml/processing/output/checkpoint-36800\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 10:34:20,736 >> Configuration saved in /opt/ml/processing/output/checkpoint-36800/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 10:34:21,418 >> Model weights saved in /opt/ml/processing/output/checkpoint-36800/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 10:34:21,419 >> tokenizer config file saved in /opt/ml/processing/output/checkpoint-36800/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 10:34:21,419 >> Special tokens file saved in /opt/ml/processing/output/checkpoint-36800/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1409] 2022-02-13 10:34:38,501 >> \u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1417] 2022-02-13 10:34:38,502 >> Loading best model from /opt/ml/processing/output/checkpoint-24400 (score: 0.43109095096588135).\u001b[0m\n",
      "\u001b[34m{'train_runtime': 55875.6692, 'train_samples_per_second': 21.084, 'train_steps_per_second': 0.659, 'train_loss': 0.37019950811990393, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1995] 2022-02-13 10:34:41,100 >> Saving model checkpoint to /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:417] 2022-02-13 10:34:41,101 >> Configuration saved in /opt/ml/processing/output/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1058] 2022-02-13 10:34:41,780 >> Model weights saved in /opt/ml/processing/output/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2034] 2022-02-13 10:34:41,781 >> tokenizer config file saved in /opt/ml/processing/output/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2040] 2022-02-13 10:34:41,781 >> Special tokens file saved in /opt/ml/processing/output/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m***** train metrics *****\n",
      "  epoch                    =         3.0\n",
      "  train_loss               =      0.3702\n",
      "  train_runtime            = 15:31:15.66\n",
      "  train_samples            =      392702\n",
      "  train_samples_per_second =      21.084\n",
      "  train_steps_per_second   =       0.659\u001b[0m\n",
      "\u001b[34m02/13/2022 10:34:41 - INFO - __main__ - *** Evaluate ***\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 10:34:41,826 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 10:34:41,828 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 10:34:41,828 >>   Num examples = 9815\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 10:34:41,828 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 10:36:27 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.43109095096588135, 'eval_accuracy': 0.8411614875191035, 'eval_runtime': 105.5236, 'eval_samples_per_second': 93.012, 'eval_steps_per_second': 11.628, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_accuracy           =     0.8412\n",
      "  eval_loss               =     0.4311\n",
      "  eval_runtime            = 0:01:45.52\n",
      "  eval_samples            =       9815\n",
      "  eval_samples_per_second =     93.012\n",
      "  eval_steps_per_second   =     11.628\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 10:36:27,352 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 10:36:27,354 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 10:36:27,354 >>   Num examples = 9832\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 10:36:27,354 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 10:38:12 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/glue/mnli/default_experiment-1-0.arrow\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4230722188949585, 'eval_accuracy': 0.8422497965825875, 'eval_runtime': 105.4147, 'eval_samples_per_second': 93.27, 'eval_steps_per_second': 11.659, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_accuracy           =     0.8422\n",
      "  eval_loss               =     0.4231\n",
      "  eval_runtime            = 0:01:45.41\n",
      "  eval_samples            =       9832\n",
      "  eval_samples_per_second =      93.27\n",
      "  eval_steps_per_second   =     11.659\u001b[0m\n",
      "\u001b[34m02/13/2022 10:38:12 - INFO - __main__ - *** Predict ***\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 10:38:12,771 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 10:38:12,773 >> ***** Running Prediction *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 10:38:12,773 >>   Num examples = 9796\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 10:38:12,773 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 10:39:57 - INFO - __main__ - ***** Predict results mnli *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-13 10:39:57,433 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2243] 2022-02-13 10:39:57,435 >> ***** Running Prediction *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2245] 2022-02-13 10:39:57,435 >>   Num examples = 9847\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2248] 2022-02-13 10:39:57,435 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m02/13/2022 10:41:42 - INFO - __main__ - ***** Predict results mnli-mm *****\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sm_local_input_models = \"/opt/ml/processing/input/data/models\"\n",
    "sm_local_input_data = \"/opt/ml/processing/input/data/jsonlines\"\n",
    "sm_local_input_vocab = \"/opt/ml/processing/input/data/vocab\"\n",
    "\n",
    "\n",
    "sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "\n",
    "\n",
    "framework_processor.run(\n",
    "        code=f'run_glue.py',\n",
    "        source_dir=f'{transformer_examples_dir}/examples/pytorch/text-classification',\n",
    "        arguments=[\n",
    "            \"--task_name\", \"mnli\",\n",
    "            \"--model_name_or_path\", \"bert-base-cased\",\n",
    "            \"--do_train\", \"1\",\n",
    "            \"--do_eval\",\"1\",\n",
    "            \"--do_predict\",\"1\",\n",
    "            \"--max_seq_length\", str(512),\n",
    "            \"--per_device_train_batch_size\", str(8),\n",
    "            \"--gradient_accumulation_steps\", str(4),\n",
    "            \"--learning_rate\", str(2e-5),\n",
    "            \"--num_train_epochs\", str(3),\n",
    "            \"--output_dir\", sm_local_output,\n",
    "            \"--overwrite_output_dir\", \"1\",\n",
    "            \"--load_best_model_at_end\", \"1\",     # load the best model when finished training (default metric is loss)\n",
    "            \"--eval_steps\",\"200\",\n",
    "            \"--save_steps\",\"200\",\n",
    "            \"--evaluation_strategy\",\"steps\",\n",
    "            \"--disable_tqdm\",\"1\"\n",
    "           \n",
    "        ],\n",
    "\n",
    "        inputs=[\n",
    "#                 ProcessingInput(\n",
    "#                     source=s3_input_data,\n",
    "#                     s3_data_type = s3_data_type,\n",
    "#                     destination=sm_local_input_data,\n",
    "#                     s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "#                 ProcessingInput(\n",
    "#                         source=s3_model_path,\n",
    "#                         destination=sm_local_input_models,\n",
    "#                         s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "#                 ProcessingInput(\n",
    "#                         source=s3_input_vocab,\n",
    "#                         destination=sm_local_input_vocab,\n",
    "#                         s3_data_distribution_type=\"FullyReplicated\")\n",
    "            ],\n",
    "\n",
    "\n",
    "        outputs=[ProcessingOutput(\n",
    "                source=sm_local_output, \n",
    "                destination=s3_output_path,\n",
    "                output_name='predictions')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with reverse train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  model-packaging-2022-02-14-03-38-34-680\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/mnli_sagemakerresults/mnli-reverse-lang-bert-accuracy-2022-01-23-21-29-34-327/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/input/data/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/embeddings/bert_base_cased/', 'LocalPath': '/opt/ml/processing/input/data/config_vocab', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/glue_code/model-packaging-2022-02-14-03-38-34-680/source/sourcedir.tar.gz', 'LocalPath': '/opt/ml/processing/input/code/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'entrypoint', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/glue_code/model-packaging-2022-02-14-03-38-34-680/source/runproc.sh', 'LocalPath': '/opt/ml/processing/input/entrypoint', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'predictions', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://aegovan-data/models/mnli-reverse-lang-bert-accuracy-2022-01-23-21-29-34-327/output', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..................................\u001b[34m{'modeltarfile': '/opt/ml/processing/input/data/model/model.tar.gz', 'modelconfigfile': '/opt/ml/processing/input/data/config_vocab/config.json', 'vocabfile': '/opt/ml/processing/input/data/config_vocab/vocab.txt', 'outdir': '/opt/ml/processing/output', 'log_level': 'INFO'}\u001b[0m\n",
      "\u001b[34m2022-02-14 03:45:30,682 - __main__ - INFO - Saving just the base bert without classifier\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at /opt/ml/processing/output and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\n",
      "\u001b[34m2022-02-14 03:45:33,953 - __main__ - INFO - Files extracted in output directory: ['config.json', 'pytorch_model.bin', 'vocab.txt', 'training_config_parameters.json']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "framework_processor = FrameworkProcessor(HuggingFace,\n",
    "                                      framework_version=None,\n",
    "                                      image_uri=docker_repo,\n",
    "                                       code_location = s3_code_path, \n",
    "                                       py_version=\"py36\",\n",
    "                                       command=[\"python\"],\n",
    "                                       env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "                                       role=role,\n",
    "                                       instance_type=\"ml.m5.large\",\n",
    "                                       instance_count=1,\n",
    "                                       max_runtime_in_seconds= 5 * 24 * 60 * 60,\n",
    "                                       volume_size_in_gb = 250,\n",
    "                                       network_config=NetworkConfig(enable_network_isolation=False),\n",
    "                                       base_job_name =\"model-packaging\"\n",
    "                                       )\n",
    "\n",
    "sm_local_input_model = \"/opt/ml/processing/input/data/model\"\n",
    "sm_local_input_config_vocab = \"/opt/ml/processing/input/data/config_vocab\"\n",
    "\n",
    "\n",
    "sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "framework_processor.run(\n",
    "        code=f'model_package_bert_utils.py',\n",
    "        source_dir=f'../src/utils',\n",
    "        arguments=[\n",
    "            \"--modeltarfile\", f\"{sm_local_input_model}/model.tar.gz\" ,\n",
    "            \"--modelconfigfile\", f\"{sm_local_input_config_vocab}/config.json\",\n",
    "            \"--vocabfile\",f\"{sm_local_input_config_vocab}/vocab.txt\",\n",
    "            \"--outdir\",sm_local_output\n",
    "          \n",
    "        ],\n",
    "\n",
    "        inputs=[\n",
    "                ProcessingInput(\n",
    "                    source=s3_model_path,\n",
    "                    s3_data_type = \"S3Prefix\",\n",
    "                    destination=sm_local_input_model,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "                ProcessingInput(\n",
    "                        source=s3_model_config_vocab_path,\n",
    "                        destination=sm_local_input_config_vocab,\n",
    "                        s3_data_distribution_type=\"FullyReplicated\")\n",
    "\n",
    "            ],\n",
    "\n",
    "\n",
    "        outputs=[ProcessingOutput(\n",
    "                source=sm_local_output, \n",
    "                destination=s3_model_package_path,\n",
    "                output_name='predictions')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with reverse mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  glue-reverse-mnli-2022-02-14-03-46-02-535\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/models/mnli-reverse-lang-bert-accuracy-2022-01-23-21-29-34-327/output', 'LocalPath': '/opt/ml/processing/input/data/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/glue_code/glue-reverse-mnli-2022-02-14-03-46-02-535/source/sourcedir.tar.gz', 'LocalPath': '/opt/ml/processing/input/code/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'entrypoint', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/glue_code/glue-reverse-mnli-2022-02-14-03-46-02-535/source/runproc.sh', 'LocalPath': '/opt/ml/processing/input/entrypoint', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'predictions', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://aegovan-data/glue_sagemakerresults/', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "......................................\u001b[34mWARNING: Skipping typing as it is not installed.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting accelerate\n",
      "  Downloading accelerate-0.5.1-py3-none-any.whl (58 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets>=1.8.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.1.96)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (3.19.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.9.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (3.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (21.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2.26.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (4.62.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.70.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2021.10.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (1.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (5.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 5)) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.3->-r requirements.txt (line 7)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.8.0->-r requirements.txt (line 2)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets>=1.8.0->-r requirements.txt (line 2)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2021.10.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (21.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (5.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (4.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 2)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: accelerate\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.5.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:31 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:31 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=None,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=True,\u001b[0m\n",
      "\u001b[34mdo_eval=True,\u001b[0m\n",
      "\u001b[34mdo_predict=True,\u001b[0m\n",
      "\u001b[34mdo_train=True,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_steps=200,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34mfp16=False,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=4,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=False,\u001b[0m\n",
      "\u001b[34mgreater_is_better=False,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_strategy=HubStrategy.EVERY_SAVE,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=2e-05,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=True,\u001b[0m\n",
      "\u001b[34mlocal_rank=-1,\u001b[0m\n",
      "\u001b[34mlog_level=-1,\u001b[0m\n",
      "\u001b[34mlog_level_replica=-1,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/opt/ml/processing/output/runs/Feb14_03-52-31_ip-10-0-68-31.us-east-2.compute.internal,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=500,\u001b[0m\n",
      "\u001b[34mlogging_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=SchedulerType.LINEAR,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=1.0,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=loss,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=3.0,\u001b[0m\n",
      "\u001b[34moutput_dir=/opt/ml/processing/output,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=True,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=8,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=8,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=[],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/opt/ml/processing/output,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_steps=200,\u001b[0m\n",
      "\u001b[34msave_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34msave_total_limit=None,\u001b[0m\n",
      "\u001b[34mseed=42,\u001b[0m\n",
      "\u001b[34msharded_ddp=[],\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.0,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.0,\u001b[0m\n",
      "\u001b[34mxpu_backend=None,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:31 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/glue.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp_3iyvc8r\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/7.78k [00:00<?, ?B/s]#015Downloading: 28.8kB [00:00, 20.9MB/s]                   \u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:32 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/glue.py in cache at /root/.cache/huggingface/datasets/downloads/ebcebc40af3c6b9af1a2f380ea06637ee192bce2d17d528809dd0ee2fa281675.759f3e257a3fad0984d9f8ba9a26479d341795eb50fa64e4c1de40f1fc421313.py\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:32 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/ebcebc40af3c6b9af1a2f380ea06637ee192bce2d17d528809dd0ee2fa281675.759f3e257a3fad0984d9f8ba9a26479d341795eb50fa64e4c1de40f1fc421313.py\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:32 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp215umoe9\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/4.47k [00:00<?, ?B/s]#015Downloading: 28.7kB [00:00, 21.8MB/s]                   \u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:32 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.15.1/datasets/glue/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/eea1163a0dd089739f6e5e3951d74b1200c7e66d462d607c43cbc8c4e69bbd47.082d8848abcb8cddda90647ec069014ca338abd4f45e0a83c6df1ece0d45476a\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:32 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/eea1163a0dd089739f6e5e3951d74b1200c7e66d462d607c43cbc8c4e69bbd47.082d8848abcb8cddda90647ec069014ca338abd4f45e0a83c6df1ece0d45476a\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:32 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:32 - INFO - datasets.builder - Generating dataset glue (/root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset glue/mnli (download: 298.29 MiB, generated: 78.65 MiB, post-processed: Unknown size, total: 376.95 MiB) to /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:32 - INFO - datasets.builder - Dataset not on Hf google storage. Downloading and preparing it from source\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:32 - INFO - datasets.utils.file_utils - https://dl.fbaipublicfiles.com/glue/data/MNLI.zip not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpisvym_ok\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Downloading:   0%|          | 0.00/313M [00:00<?, ?B/s]#015Downloading:   0%|          | 2.05k/313M [00:00<4:16:00, 20.4kB/s]#015Downloading:   0%|          | 55.3k/313M [00:00<16:14, 321kB/s]   #015Downloading:   0%|          | 139k/313M [00:00<09:21, 557kB/s] #015Downloading:   0%|          | 296k/313M [00:00<05:27, 954kB/s]#015Downloading:   0%|          | 609k/313M [00:00<03:00, 1.73MB/s]#015Downloading:   0%|          | 1.25M/313M [00:00<01:34, 3.30MB/s]#015Downloading:   1%|          | 2.53M/313M [00:00<00:48, 6.38MB/s]#015Downloading:   2%|▏         | 5.09M/313M [00:00<00:24, 12.4MB/s]#015Downloading:   3%|▎         | 9.31M/313M [00:00<00:14, 21.6MB/s]#015Downloading:   4%|▍         | 13.5M/313M [00:01<00:10, 27.5MB/s]#015Downloading:   6%|▌         | 17.7M/313M [00:01<00:09, 31.7MB/s]#015Downloading:   7%|▋         | 21.7M/313M [00:01<00:08, 34.5MB/s]#015Downloading:   8%|▊         | 25.9M/313M [00:01<00:07, 36.3MB/s]#015Downloading:  10%|▉         | 30.1M/313M [00:01<00:07, 38.0MB/s]#015Downloading:  11%|█         | 34.3M/313M [00:01<00:07, 39.1MB/s]#015Downloading:  12%|█▏        | 38.4M/313M [00:01<00:06, 39.3MB/s]#015Downloading:  14%|█▎        | 42.6M/313M [00:01<00:06, 39.8MB/s]#015Downloading:  15%|█▍        | 46.8M/313M [00:01<00:06, 40.5MB/s]#015Downloading:  16%|█▋        | 50.9M/313M [00:01<00:06, 40.6MB/s]#015Downloading:  18%|█▊        | 55.0M/313M [00:02<00:06, 40.8MB/s]#015Downloading:  19%|█▉        | 59.3M/313M [00:02<00:06, 40.7MB/s]#015Downloading:  20%|██        | 63.5M/313M [00:02<00:06, 41.1MB/s]#015Downloading:  22%|██▏       | 67.6M/313M [00:02<00:05, 41.2MB/s]#015Downloading:  23%|██▎       | 71.8M/313M [00:02<00:05, 41.2MB/s]#015Downloading:  24%|██▍       | 75.9M/313M [00:02<00:05, 40.5MB/s]#015Downloading:  26%|██▌       | 80.4M/313M [00:02<00:05, 41.6MB/s]#015Downloading:  27%|██▋       | 84.5M/313M [00:02<00:05, 41.1MB/s]#015Downloading:  28%|██▊       | 88.7M/313M [00:02<00:05, 41.1MB/s]#015Downloading:  30%|██▉       | 92.8M/313M [00:02<00:05, 40.1MB/s]#015Downloading:  31%|███       | 97.1M/313M [00:03<00:05, 41.1MB/s]#015Downloading:  32%|███▏      | 101M/313M [00:03<00:05, 41.2MB/s] #015Downloading:  34%|███▎      | 105M/313M [00:03<00:05, 41.1MB/s]#015Downloading:  35%|███▌      | 110M/313M [00:03<00:04, 40.9MB/s]#015Downloading:  36%|███▋      | 114M/313M [00:03<00:04, 40.9MB/s]#015Downloading:  38%|███▊      | 118M/313M [00:03<00:04, 41.5MB/s]#015Downloading:  39%|███▉      | 122M/313M [00:03<00:04, 40.8MB/s]#015Downloading:  40%|████      | 126M/313M [00:03<00:04, 40.8MB/s]#015Downloading:  42%|████▏     | 131M/313M [00:03<00:04, 42.8MB/s]#015Downloading:  43%|████▎     | 135M/313M [00:03<00:04, 41.4MB/s]#015Downloading:  45%|████▍     | 139M/313M [00:04<00:04, 40.8MB/s]#015Downloading:  46%|████▌     | 144M/313M [00:04<00:04, 41.7MB/s]#015Downloading:  47%|████▋     | 148M/313M [00:04<00:04, 40.9MB/s]#015Downloading:  49%|████▉     | 153M/313M [00:04<00:03, 42.6MB/s]#015Downloading:  50%|█████     | 157M/313M [00:04<00:03, 42.2MB/s]#015Downloading:  51%|█████▏    | 161M/313M [00:04<00:03, 42.1MB/s]#015Downloading:  53%|█████▎    | 165M/313M [00:04<00:03, 41.9MB/s]#015Downloading:  54%|█████▍    | 169M/313M [00:04<00:03, 41.6MB/s]#015Downloading:  56%|█████▌    | 174M/313M [00:04<00:03, 41.6MB/s]#015Downloading:  57%|█████▋    | 178M/313M [00:04<00:03, 41.4MB/s]#015Downloading:  58%|█████▊    | 182M/313M [00:05<00:03, 41.2MB/s]#015Downloading:  60%|█████▉    | 186M/313M [00:05<00:03, 41.5MB/s]#015Downloading:  61%|██████    | 190M/313M [00:05<00:02, 41.3MB/s]#015Downloading:  62%|██████▏   | 194M/313M [00:05<00:02, 41.4MB/s]#015Downloading:  64%|██████▎   | 199M/313M [00:05<00:02, 41.3MB/s]#015Downloading:  65%|██████▍   | 203M/313M [00:05<00:02, 41.1MB/s]#015Downloading:  66%|██████▌   | 207M/313M [00:05<00:02, 40.8MB/s]#015Downloading:  67%|██████▋   | 211M/313M [00:05<00:02, 41.0MB/s]#015Downloading:  69%|██████▉   | 215M/313M [00:05<00:02, 41.0MB/s]#015Downloading:  70%|███████   | 219M/313M [00:05<00:02, 40.8MB/s]#015Downloading:  71%|███████▏  | 223M/313M [00:06<00:02, 40.0MB/s]#015Downloading:  73%|███████▎  | 228M/313M [00:06<00:02, 41.2MB/s]#015Downloading:  74%|███████▍  | 232M/313M [00:06<00:01, 41.7MB/s]#015Downloading:  76%|███████▌  | 236M/313M [00:06<00:01, 41.1MB/s]#015Downloading:  77%|███████▋  | 240M/313M [00:06<00:01, 41.6MB/s]#015Downloading:  78%|███████▊  | 245M/313M [00:06<00:01, 41.4MB/s]#015Downloading:  80%|███████▉  | 249M/313M [00:06<00:01, 41.5MB/s]#015Downloading:  81%|████████  | 253M/313M [00:06<00:01, 41.2MB/s]#015Downloading:  82%|████████▏ | 257M/313M [00:06<00:01, 41.5MB/s]#015Downloading:  84%|████████▎ | 261M/313M [00:07<00:01, 41.3MB/s]#015Downloading:  85%|████████▍ | 265M/313M [00:07<00:01, 40.4MB/s]#015Downloading:  86%|████████▌ | 269M/313M [00:07<00:01, 40.0MB/s]#015Downloading:  87%|████████▋ | 274M/313M [00:07<00:00, 40.1MB/s]#015Downloading:  89%|████████▊ | 278M/313M [00:07<00:00, 40.0MB/s]#015Downloading:  90%|█████████ | 282M/313M [00:07<00:00, 38.5MB/s]#015Downloading:  92%|█████████▏| 286M/313M [00:07<00:00, 38.4MB/s]#015Downloading:  93%|█████████▎| 291M/313M [00:07<00:00, 39.4MB/s]#015Downloading:  94%|█████████▍| 295M/313M [00:07<00:00, 38.8MB/s]#015Downloading:  95%|█████████▌| 299M/313M [00:07<00:00, 39.4MB/s]#015Downloading:  97%|█████████▋| 303M/313M [00:08<00:00, 40.4MB/s]#015Downloading:  98%|█████████▊| 307M/313M [00:08<00:00, 40.3MB/s]#015Downloading: 100%|█████████▉| 311M/313M [00:08<00:00, 41.0MB/s]#015Downloading: 100%|██████████| 313M/313M [00:08<00:00, 37.7MB/s]\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:41 - INFO - datasets.utils.file_utils - storing https://dl.fbaipublicfiles.com/glue/data/MNLI.zip in cache at /root/.cache/huggingface/datasets/downloads/74d7bc70ada44c1086d1ba81cf6271c128514f629fb8edcd548c113939e3b5f2\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:41 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/74d7bc70ada44c1086d1ba81cf6271c128514f629fb8edcd548c113939e3b5f2\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:41 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:42 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:50 - INFO - datasets.utils.info_utils - All the checksums matched successfully for dataset source files\u001b[0m\n",
      "\u001b[34m02/14/2022 03:52:50 - INFO - datasets.builder - Generating split train\u001b[0m\n",
      "\u001b[34m02/14/2022 03:53:09 - INFO - datasets.builder - Generating split validation_matched\u001b[0m\n",
      "\u001b[34m02/14/2022 03:53:10 - INFO - datasets.builder - Generating split validation_mismatched\u001b[0m\n",
      "\u001b[34m02/14/2022 03:53:10 - INFO - datasets.builder - Generating split test_matched\u001b[0m\n",
      "\u001b[34m02/14/2022 03:53:11 - INFO - datasets.builder - Generating split test_mismatched\u001b[0m\n",
      "\u001b[34m02/14/2022 03:53:13 - INFO - datasets.utils.info_utils - All the splits matched successfully.\u001b[0m\n",
      "\u001b[34mDataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m#0150 examples [00:00, ? examples/s]#0151998 examples [00:00, 19978.30 examples/s]#0154135 examples [00:00, 20792.44 examples/s]#0156271 examples [00:00, 21048.76 examples/s]#0158390 examples [00:00, 21099.95 examples/s]#01510500 examples [00:00, 20135.21 examples/s]#01512670 examples [00:00, 20648.89 examples/s]#01514845 examples [00:00, 20999.32 examples/s]#01516997 examples [00:00, 21161.42 examples/s]#01519142 examples [00:00, 21248.34 examples/s]#01521270 examples [00:01, 20704.96 examples/s]#01523421 examples [00:01, 20943.59 examples/s]#01525588 examples [00:01, 21160.71 examples/s]#01527709 examples [00:01, 21173.15 examples/s]#01529847 examples [00:01, 21232.60 examples/s]#01531972 examples [00:01, 18293.61 examples/s]#01534120 examples [00:01, 19148.79 examples/s]#01536292 examples [00:01, 19862.87 examples/s]#01538427 examples [00:01, 20283.65 examples/s]#01540492 examples [00:01, 20060.46 examples/s]#01542638 examples [00:02, 20462.69 examples/s]#01544781 examples [00:02, 20743.04 examples/s]#01546936 examples [00:02, 20978.80 examples/s]#01549062 examples [00:02, 21059.85 examples/s]#01551176 examples [00:02, 20530.34 examples/s]#01553334 examples [00:02, 20836.39 examples/s]#01555500 examples [00:02, 21078.77 examples/s]#01557654 examples [00:02, 21214.28 examples/s]#01559788 examples [00:02, 21251.20 examples/s]#01561916 examples [00:03, 20679.06 examples/s]#01564061 examples [00:03, 20903.61 examples/s]#01566212 examples [00:03, 21080.14 examples/s]#01568354 examples [00:03, 21179.57 examples/s]#01570475 examples [00:03, 20550.10 examples/s]#01572626 examples [00:03, 20828.48 examples/s]#01574766 examples [00:03, 20994.58 examples/s]#01576900 examples [00:03, 21093.21 examples/s]#01579023 examples [00:03, 21132.55 examples/s]#01581139 examples [00:03, 20509.34 examples/s]#01583195 examples [00:04, 18425.84 examples/s]#01585340 examples [00:04, 19247.70 examples/s]#01587486 examples [00:04, 19865.94 examples/s]#01589597 examples [00:04, 20220.70 examples/s]#01591642 examples [00:04, 19975.46 examples/s]#01593814 examples [00:04, 20480.42 examples/s]#01595980 examples [00:04, 20824.70 examples/s]#01598122 examples [00:04, 20997.49 examples/s]#015100229 examples [00:04, 20397.36 examples/s]#015102400 examples [00:04, 20778.52 examples/s]#015104528 examples [00:05, 20924.56 examples/s]#015106678 examples [00:05, 21092.57 examples/s]#015108805 examples [00:05, 21143.19 examples/s]#015110923 examples [00:05, 20578.10 examples/s]#015113091 examples [00:05, 20898.90 examples/s]#015115214 examples [00:05, 20993.83 examples/s]#015117365 examples [00:05, 21144.73 examples/s]#015119498 examples [00:05, 21198.59 examples/s]#015121620 examples [00:05, 20636.29 examples/s]#015123792 examples [00:05, 20953.47 examples/s]#015125941 examples [00:06, 21110.99 examples/s]#015128098 examples [00:06, 21244.09 examples/s]#015130225 examples [00:06, 20580.82 examples/s]#015132385 examples [00:06, 20876.25 examples/s]#015134552 examples [00:06, 21107.74 examples/s]#015136667 examples [00:06, 18768.03 examples/s]#015138790 examples [00:06, 19438.94 examples/s]#015140775 examples [00:06, 19335.75 examples/s]#015142935 examples [00:06, 19978.08 examples/s]#015145085 examples [00:07, 20415.45 examples/s]#015147251 examples [00:07, 20776.66 examples/s]#015149395 examples [00:07, 20970.33 examples/s]#015151503 examples [00:07, 20447.62 examples/s]#015153649 examples [00:07, 20740.98 examples/s]#015155787 examples [00:07, 20927.29 examples/s]#015157942 examples [00:07, 21108.09 examples/s]#015160057 examples [00:07, 20487.15 examples/s]#015162214 examples [00:07, 20801.52 examples/s]#015164334 examples [00:07, 20917.99 examples/s]#015166489 examples [00:08, 21102.27 examples/s]#015168661 examples [00:08, 21284.12 examples/s]#015170792 examples [00:08, 20629.93 examples/s]#015172964 examples [00:08, 20946.36 examples/s]#015175122 examples [00:08, 21131.00 examples/s]#015177285 examples [00:08, 21276.63 examples/s]#015179436 examples [00:08, 21343.97 examples/s]#015181573 examples [00:08, 20778.39 examples/s]#015183723 examples [00:08, 20987.40 examples/s]#015185903 examples [00:08, 21224.30 examples/s]#015188029 examples [00:09, 18805.64 examples/s]#015190000 examples [00:09, 18778.81 examples/s]#015192154 examples [00:09, 19544.51 examples/s]#015194319 examples [00:09, 20141.17 examples/s]#015196480 examples [00:09, 20564.43 examples/s]#015198640 examples [00:09, 20866.00 examples/s]#015200742 examples [00:09, 20309.01 examples/s]#015202898 examples [00:09, 20670.08 examples/s]#015205056 examples [00:09, 20935.36 examples/s]#015207209 examples [00:10, 21108.78 examples/s]#015209353 examples [00:10, 21204.48 examples/s]#015211478 examples [00:10, 20588.46 examples/s]#015213617 examples [00:10, 20821.74 examples/s]#015215756 examples [00:10, 20986.80 examples/s]#015217923 examples [00:10, 21188.46 examples/s]#015220045 examples [00:10, 20596.07 examples/s]#015222209 examples [00:10, 20900.14 examples/s]#015224360 examples [00:10, 21078.07 examples/s]#015226472 examples [00:11, 18792.52 examples/s]#015228399 examples [00:11, 18283.85 examples/s]#015230283 examples [00:11, 18434.77 examples/s]#015232427 examples [00:11, 19279.46 examples/s]#015234585 examples [00:11, 19937.27 examples/s]#015236690 examples [00:11, 20260.05 examples/s]#015238745 examples [00:11, 20341.60 examples/s]#015240790 examples [00:11, 19955.66 examples/s]#015242950 examples [00:11, 20436.07 examples/s]#015245001 examples [00:11, 18078.97 examples/s]#015247139 examples [00:12, 18972.92 examples/s]#015249280 examples [00:12, 19651.16 examples/s]#015251283 examples [00:12, 19530.25 examples/s]#015253435 examples [00:12, 20100.59 examples/s]#015255614 examples [00:12, 20588.67 examples/s]#015257785 examples [00:12, 20916.02 examples/s]#015259948 examples [00:12, 21124.52 examples/s]#015262070 examples [00:12, 20604.96 examples/s]#015264227 examples [00:12, 20885.96 examples/s]#015266393 examples [00:12, 21113.47 examples/s]#015268556 examples [00:13, 21265.72 examples/s]#015270687 examples [00:13, 20700.90 examples/s]#015272858 examples [00:13, 20994.62 examples/s]#015275035 examples [00:13, 21221.47 examples/s]#015277199 examples [00:13, 21343.80 examples/s]#015279369 examples [00:13, 21447.92 examples/s]#015281516 examples [00:13, 20805.32 examples/s]#015283682 examples [00:13, 21052.72 examples/s]#015285841 examples [00:13, 21209.54 examples/s]#015288008 examples [00:14, 21345.39 examples/s]#015290146 examples [00:14, 20706.71 examples/s]#015292245 examples [00:14, 20786.52 examples/s]#015294417 examples [00:14, 21057.99 examples/s]#015296527 examples [00:14, 18783.31 examples/s]#015298678 examples [00:14, 19527.97 examples/s]#015300671 examples [00:14, 19389.95 examples/s]#015302833 examples [00:14, 20022.60 examples/s]#015304986 examples [00:14, 20454.83 examples/s]#015307149 examples [00:14, 20796.15 examples/s]#015309303 examples [00:15, 21013.88 examples/s]#015311415 examples [00:15, 20519.14 examples/s]#015313588 examples [00:15, 20871.26 examples/s]#015315749 examples [00:15, 21087.48 examples/s]#015317905 examples [00:15, 21226.92 examples/s]#015320032 examples [00:15, 20626.65 examples/s]#015322200 examples [00:15, 20932.24 examples/s]#015324353 examples [00:15, 21106.43 examples/s]#015326514 examples [00:15, 21253.33 examples/s]#015328677 examples [00:15, 21362.85 examples/s]#015330816 examples [00:16, 18997.76 examples/s]#015332766 examples [00:16, 10369.53 examples/s]#015334861 examples [00:16, 12222.88 examples/s]#015337021 examples [00:16, 14099.78 examples/s]#015339188 examples [00:16, 15782.59 examples/s]#015341117 examples [00:16, 16617.37 examples/s]#015343295 examples [00:17, 17937.88 examples/s]#015345479 examples [00:17, 18980.65 examples/s]#015347664 examples [00:17, 19773.11 examples/s]#015349759 examples [00:17, 18020.25 examples/s]#015351705 examples [00:17, 18401.63 examples/s]#015353885 examples [00:17, 19336.57 examples/s]#015356062 examples [00:17, 20020.24 examples/s]#015358257 examples [00:17, 20573.44 examples/s]#015360352 examples [00:17, 20283.61 examples/s]#015362549 examples [00:17, 20769.82 examples/s]#015364736 examples [00:18, 21089.57 examples/s]#015366888 examples [00:18, 21214.25 examples/s]#015369077 examples [00:18, 21412.16 examples/s]#015371227 examples [00:18, 20896.48 examples/s]#015373419 examples [00:18, 21195.08 examples/s]#015375614 examples [00:18, 21416.36 examples/s]#015377808 examples [00:18, 21570.61 examples/s]#015379997 examples [00:18, 21663.83 examples/s]#015382166 examples [00:18, 21027.99 examples/s]#015384356 examples [00:19, 21281.27 examples/s]#015386556 examples [00:19, 21491.07 examples/s]#015388751 examples [00:19, 21625.88 examples/s]#015390917 examples [00:19, 20998.31 examples/s]#015                                            #015#0150 examples [00:00, ? examples/s]#0152084 examples [00:00, 20837.88 examples/s]#0154255 examples [00:00, 21349.27 examples/s]#0156432 examples [00:00, 21537.93 examples/s]#0158586 examples [00:00, 18388.28 examples/s]#015                                          #015#0150 examples [00:00, ? examples/s]#0152059 examples [00:00, 20587.17 examples/s]#0154210 examples [00:00, 21127.98 examples/s]#0156350 examples [00:00, 21247.72 examples/s]#0158487 examples [00:00, 21293.29 examples/s]#015                                          #015#0150 examples [00:00, ? examples/s]#0152291 examples [00:00, 22906.96 examples/s]#0154698 examples [00:00, 23585.65 examples/s]#0157094 examples [00:00, 23752.98 examples/s]#0159494 examples [00:00, 23846.34 examples/s]#015                                          #015#0150 examples [00:00, ? examples/s]#0152264 examples [00:00, 22633.55 examples/s]#0154647 examples [00:00, 23335.08 examples/s]#0157008 examples [00:00, 23457.01 examples/s]#0159366 examples [00:00, 23504.00 examples/s]#015                                          #015#015  0%|          | 0/5 [00:00<?, ?it/s]#015100%|██████████| 5/5 [00:00<00:00, 829.41it/s]\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:586] 2022-02-14 03:53:13,307 >> loading configuration file /opt/ml/processing/input/data/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:625] 2022-02-14 03:53:13,308 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_auto.py:341] 2022-02-14 03:53:13,308 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:586] 2022-02-14 03:53:13,308 >> loading configuration file /opt/ml/processing/input/data/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:625] 2022-02-14 03:53:13,309 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1671] 2022-02-14 03:53:13,309 >> Didn't find file /opt/ml/processing/input/data/model/tokenizer.json. We won't load it.\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1671] 2022-02-14 03:53:13,310 >> Didn't find file /opt/ml/processing/input/data/model/added_tokens.json. We won't load it.\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1671] 2022-02-14 03:53:13,310 >> Didn't find file /opt/ml/processing/input/data/model/special_tokens_map.json. We won't load it.\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1671] 2022-02-14 03:53:13,310 >> Didn't find file /opt/ml/processing/input/data/model/tokenizer_config.json. We won't load it.\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1740] 2022-02-14 03:53:13,310 >> loading file /opt/ml/processing/input/data/model/vocab.txt\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1740] 2022-02-14 03:53:13,310 >> loading file None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1740] 2022-02-14 03:53:13,310 >> loading file None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1740] 2022-02-14 03:53:13,310 >> loading file None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1740] 2022-02-14 03:53:13,310 >> loading file None\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:586] 2022-02-14 03:53:13,310 >> loading configuration file /opt/ml/processing/input/data/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:625] 2022-02-14 03:53:13,311 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:586] 2022-02-14 03:53:13,336 >> loading configuration file /opt/ml/processing/input/data/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:625] 2022-02-14 03:53:13,337 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1338] 2022-02-14 03:53:13,378 >> loading weights file /opt/ml/processing/input/data/model/pytorch_model.bin\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[INFO|modeling_utils.py:1607] 2022-02-14 03:53:15,961 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:1609] 2022-02-14 03:53:15,962 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /opt/ml/processing/input/data/model and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m02/14/2022 03:53:16 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-89e6c98322b0322d.arrow\u001b[0m\n",
      "\u001b[34m#015Running tokenizer on dataset:   0%|          | 0/393 [00:00<?, ?ba/s]#015Running tokenizer on dataset:   0%|          | 1/393 [00:00<02:41,  2.42ba/s]#015Running tokenizer on dataset:   1%|          | 2/393 [00:00<01:45,  3.71ba/s]#015Running tokenizer on dataset:   1%|          | 3/393 [00:00<01:36,  4.02ba/s]#015Running tokenizer on dataset:   1%|          | 4/393 [00:00<01:24,  4.58ba/s]#015Running tokenizer on dataset:   1%|▏         | 5/393 [00:01<01:18,  4.97ba/s]#015Running tokenizer on dataset:   2%|▏         | 6/393 [00:01<01:13,  5.29ba/s]#015Running tokenizer on dataset:   2%|▏         | 7/393 [00:01<01:10,  5.50ba/s]#015Running tokenizer on dataset:   2%|▏         | 8/393 [00:01<01:08,  5.65ba/s]#015Running tokenizer on dataset:   2%|▏         | 9/393 [00:01<01:06,  5.75ba/s]#015Running tokenizer on dataset:   3%|▎         | 10/393 [00:01<01:06,  5.80ba/s]#015Running tokenizer on dataset:   3%|▎         | 11/393 [00:02<01:05,  5.84ba/s]#015Running tokenizer on dataset:   3%|▎         | 12/393 [00:02<01:04,  5.88ba/s]#015Running tokenizer on dataset:   3%|▎         | 13/393 [00:02<01:04,  5.89ba/s]#015Running tokenizer on dataset:   4%|▎         | 14/393 [00:02<01:04,  5.89ba/s]#015Running tokenizer on dataset:   4%|▍         | 15/393 [00:02<01:10,  5.36ba/s]#015Running tokenizer on dataset:   4%|▍         | 16/393 [00:03<01:08,  5.49ba/s]#015Running tokenizer on dataset:   4%|▍         | 17/393 [00:03<01:06,  5.64ba/s]#015Running tokenizer on dataset:   5%|▍         | 18/393 [00:03<01:04,  5.77ba/s]#015Running tokenizer on dataset:   5%|▍         | 19/393 [00:03<01:03,  5.87ba/s]#015Running tokenizer on dataset:   5%|▌         | 20/393 [00:03<01:03,  5.91ba/s]#015Running tokenizer on dataset:   5%|▌         | 21/393 [00:03<01:02,  5.93ba/s]#015Running tokenizer on dataset:   6%|▌         | 22/393 [00:04<01:02,  5.90ba/s]#015Running tokenizer on dataset:   6%|▌         | 23/393 [00:04<01:02,  5.90ba/s]#015Running tokenizer on dataset:   6%|▌         | 24/393 [00:04<01:02,  5.90ba/s]#015Running tokenizer on dataset:   6%|▋         | 25/393 [00:04<01:02,  5.87ba/s]#015Running tokenizer on dataset:   7%|▋         | 26/393 [00:04<01:02,  5.88ba/s]#015Running tokenizer on dataset:   7%|▋         | 27/393 [00:04<01:08,  5.32ba/s]#015Running tokenizer on dataset:   7%|▋         | 28/393 [00:05<01:06,  5.53ba/s]#015Running tokenizer on dataset:   7%|▋         | 29/393 [00:05<01:03,  5.70ba/s]#015Running tokenizer on dataset:   8%|▊         | 30/393 [00:05<01:02,  5.78ba/s]#015Running tokenizer on dataset:   8%|▊         | 31/393 [00:05<01:01,  5.84ba/s]#015Running tokenizer on dataset:   8%|▊         | 32/393 [00:05<01:01,  5.86ba/s]#015Running tokenizer on dataset:   8%|▊         | 33/393 [00:05<01:01,  5.88ba/s]#015Running tokenizer on dataset:   9%|▊         | 34/393 [00:06<01:01,  5.85ba/s]#015Running tokenizer on dataset:   9%|▉         | 35/393 [00:06<01:00,  5.87ba/s]#015Running tokenizer on dataset:   9%|▉         | 36/393 [00:06<01:00,  5.88ba/s]#015Running tokenizer on dataset:   9%|▉         | 37/393 [00:06<01:00,  5.87ba/s]#015Running tokenizer on dataset:  10%|▉         | 38/393 [00:06<01:00,  5.85ba/s]#015Running tokenizer on dataset:  10%|▉         | 39/393 [00:06<01:00,  5.84ba/s]#015Running tokenizer on dataset:  10%|█         | 40/393 [00:07<01:04,  5.45ba/s]#015Running tokenizer on dataset:  10%|█         | 41/393 [00:07<01:02,  5.60ba/s]#015Running tokenizer on dataset:  11%|█         | 42/393 [00:07<01:01,  5.69ba/s]#015Running tokenizer on dataset:  11%|█         | 43/393 [00:07<01:00,  5.79ba/s]#015Running tokenizer on dataset:  11%|█         | 44/393 [00:07<01:00,  5.80ba/s]#015Running tokenizer on dataset:  11%|█▏        | 45/393 [00:08<00:59,  5.83ba/s]#015Running tokenizer on dataset:  12%|█▏        | 46/393 [00:08<00:59,  5.86ba/s]#015Running tokenizer on dataset:  12%|█▏        | 47/393 [00:08<00:59,  5.86ba/s]#015Running tokenizer on dataset:  12%|█▏        | 48/393 [00:08<00:59,  5.84ba/s]#015Running tokenizer on dataset:  12%|█▏        | 49/393 [00:08<00:58,  5.83ba/s]#015Running tokenizer on dataset:  13%|█▎        | 50/393 [00:08<00:59,  5.80ba/s]#015Running tokenizer on dataset:  13%|█▎        | 51/393 [00:09<00:59,  5.78ba/s]#015Running tokenizer on dataset:  13%|█▎        | 52/393 [00:09<01:02,  5.45ba/s]#015Running tokenizer on dataset:  13%|█▎        | 53/393 [00:09<01:00,  5.61ba/s]#015Running tokenizer on dataset:  14%|█▎        | 54/393 [00:09<01:00,  5.65ba/s]#015Running tokenizer on dataset:  14%|█▍        | 55/393 [00:09<00:58,  5.74ba/s]#015Running tokenizer on dataset:  14%|█▍        | 56/393 [00:09<00:57,  5.81ba/s]#015Running tokenizer on dataset:  15%|█▍        | 57/393 [00:10<00:57,  5.88ba/s]#015Running tokenizer on dataset:  15%|█▍        | 58/393 [00:10<00:57,  5.84ba/s]#015Running tokenizer on dataset:  15%|█▌        | 59/393 [00:10<00:56,  5.88ba/s]#015Running tokenizer on dataset:  15%|█▌        | 60/393 [00:10<00:56,  5.88ba/s]#015Running tokenizer on dataset:  16%|█▌        | 61/393 [00:10<00:57,  5.82ba/s]#015Running tokenizer on dataset:  16%|█▌        | 62/393 [00:10<00:57,  5.79ba/s]#015Running tokenizer on dataset:  16%|█▌        | 63/393 [00:11<00:57,  5.79ba/s]#015Running tokenizer on dataset:  16%|█▋        | 64/393 [00:11<01:00,  5.40ba/s]#015Running tokenizer on dataset:  17%|█▋        | 65/393 [00:11<00:58,  5.58ba/s]#015Running tokenizer on dataset:  17%|█▋        | 66/393 [00:11<00:57,  5.70ba/s]#015Running tokenizer on dataset:  17%|█▋        | 67/393 [00:11<00:56,  5.80ba/s]#015Running tokenizer on dataset:  17%|█▋        | 68/393 [00:12<00:55,  5.81ba/s]#015Running tokenizer on dataset:  18%|█▊        | 69/393 [00:12<00:55,  5.84ba/s]#015Running tokenizer on dataset:  18%|█▊        | 70/393 [00:12<00:55,  5.85ba/s]#015Running tokenizer on dataset:  18%|█▊        | 71/393 [00:12<00:55,  5.78ba/s]#015Running tokenizer on dataset:  18%|█▊        | 72/393 [00:12<00:55,  5.80ba/s]#015Running tokenizer on dataset:  19%|█▊        | 73/393 [00:12<00:55,  5.81ba/s]#015Running tokenizer on dataset:  19%|█▉        | 74/393 [00:13<00:54,  5.83ba/s]#015Running tokenizer on dataset:  19%|█▉        | 75/393 [00:13<00:54,  5.81ba/s]#015Running tokenizer on dataset:  19%|█▉        | 76/393 [00:13<00:58,  5.45ba/s]#015Running tokenizer on dataset:  20%|█▉        | 77/393 [00:13<00:56,  5.63ba/s]#015Running tokenizer on dataset:  20%|█▉        | 78/393 [00:13<00:55,  5.73ba/s]#015Running tokenizer on dataset:  20%|██        | 79/393 [00:13<00:54,  5.81ba/s]#015Running tokenizer on dataset:  20%|██        | 80/393 [00:14<00:53,  5.89ba/s]#015Running tokenizer on dataset:  21%|██        | 81/393 [00:14<00:53,  5.88ba/s]#015Running tokenizer on dataset:  21%|██        | 82/393 [00:14<00:52,  5.89ba/s]#015Running tokenizer on dataset:  21%|██        | 83/393 [00:14<00:52,  5.90ba/s]#015Running tokenizer on dataset:  21%|██▏       | 84/393 [00:14<00:52,  5.88ba/s]#015Running tokenizer on dataset:  22%|██▏       | 85/393 [00:14<00:52,  5.89ba/s]#015Running tokenizer on dataset:  22%|██▏       | 86/393 [00:15<00:52,  5.88ba/s]#015Running tokenizer on dataset:  22%|██▏       | 87/393 [00:15<00:52,  5.79ba/s]#015Running tokenizer on dataset:  22%|██▏       | 88/393 [00:15<00:56,  5.40ba/s]#015Running tokenizer on dataset:  23%|██▎       | 89/393 [00:15<00:54,  5.60ba/s]#015Running tokenizer on dataset:  23%|██▎       | 90/393 [00:15<00:52,  5.73ba/s]#015Running tokenizer on dataset:  23%|██▎       | 91/393 [00:16<00:51,  5.81ba/s]#015Running tokenizer on dataset:  23%|██▎       | 92/393 [00:16<00:51,  5.82ba/s]#015Running tokenizer on dataset:  24%|██▎       | 93/393 [00:16<00:51,  5.85ba/s]#015Running tokenizer on dataset:  24%|██▍       | 94/393 [00:16<00:51,  5.85ba/s]#015Running tokenizer on dataset:  24%|██▍       | 95/393 [00:16<00:50,  5.85ba/s]#015Running tokenizer on dataset:  24%|██▍       | 96/393 [00:16<00:50,  5.86ba/s]#015Running tokenizer on dataset:  25%|██▍       | 97/393 [00:17<00:50,  5.84ba/s]#015Running tokenizer on dataset:  25%|██▍       | 98/393 [00:17<00:50,  5.86ba/s]#015Running tokenizer on dataset:  25%|██▌       | 99/393 [00:17<00:50,  5.84ba/s]#015Running tokenizer on dataset:  25%|██▌       | 100/393 [00:17<00:53,  5.48ba/s]#015Running tokenizer on dataset:  26%|██▌       | 101/393 [00:17<00:51,  5.64ba/s]#015Running tokenizer on dataset:  26%|██▌       | 102/393 [00:17<00:50,  5.74ba/s]#015Running tokenizer on dataset:  26%|██▌       | 103/393 [00:18<00:49,  5.83ba/s]#015Running tokenizer on dataset:  26%|██▋       | 104/393 [00:18<00:49,  5.85ba/s]#015Running tokenizer on dataset:  27%|██▋       | 105/393 [00:18<00:48,  5.91ba/s]#015Running tokenizer on dataset:  27%|██▋       | 106/393 [00:18<00:48,  5.90ba/s]#015Running tokenizer on dataset:  27%|██▋       | 107/393 [00:18<00:48,  5.89ba/s]#015Running tokenizer on dataset:  27%|██▋       | 108/393 [00:18<00:48,  5.86ba/s]#015Running tokenizer on dataset:  28%|██▊       | 109/393 [00:19<00:48,  5.84ba/s]#015Running tokenizer on dataset:  28%|██▊       | 110/393 [00:19<00:48,  5.85ba/s]#015Running tokenizer on dataset:  28%|██▊       | 111/393 [00:19<00:48,  5.85ba/s]#015Running tokenizer on dataset:  28%|██▊       | 112/393 [00:19<00:51,  5.47ba/s]#015Running tokenizer on dataset:  29%|██▉       | 113/393 [00:19<00:49,  5.65ba/s]#015Running tokenizer on dataset:  29%|██▉       | 114/393 [00:20<00:48,  5.73ba/s]#015Running tokenizer on dataset:  29%|██▉       | 115/393 [00:20<00:47,  5.82ba/s]#015Running tokenizer on dataset:  30%|██▉       | 116/393 [00:20<00:47,  5.88ba/s]#015Running tokenizer on dataset:  30%|██▉       | 117/393 [00:20<00:46,  5.91ba/s]#015Running tokenizer on dataset:  30%|███       | 118/393 [00:20<00:46,  5.90ba/s]#015Running tokenizer on dataset:  30%|███       | 119/393 [00:20<00:46,  5.85ba/s]#015Running tokenizer on dataset:  31%|███       | 120/393 [00:21<00:46,  5.83ba/s]#015Running tokenizer on dataset:  31%|███       | 121/393 [00:21<00:46,  5.82ba/s]#015Running tokenizer on dataset:  31%|███       | 122/393 [00:21<00:46,  5.82ba/s]#015Running tokenizer on dataset:  31%|███▏      | 123/393 [00:21<00:46,  5.81ba/s]#015Running tokenizer on dataset:  32%|███▏      | 124/393 [00:21<00:49,  5.40ba/s]#015Running tokenizer on dataset:  32%|███▏      | 125/393 [00:21<00:48,  5.55ba/s]#015Running tokenizer on dataset:  32%|███▏      | 126/393 [00:22<00:47,  5.67ba/s]#015Running tokenizer on dataset:  32%|███▏      | 127/393 [00:22<00:46,  5.78ba/s]#015Running tokenizer on dataset:  33%|███▎      | 128/393 [00:22<00:45,  5.86ba/s]#015Running tokenizer on dataset:  33%|███▎      | 129/393 [00:22<00:44,  5.89ba/s]#015Running tokenizer on dataset:  33%|███▎      | 130/393 [00:22<00:44,  5.90ba/s]#015Running tokenizer on dataset:  33%|███▎      | 131/393 [00:22<00:44,  5.89ba/s]#015Running tokenizer on dataset:  34%|███▎      | 132/393 [00:23<00:44,  5.88ba/s]#015Running tokenizer on dataset:  34%|███▍      | 133/393 [00:23<00:44,  5.86ba/s]#015Running tokenizer on dataset:  34%|███▍      | 134/393 [00:23<00:44,  5.87ba/s]#015Running tokenizer on dataset:  34%|███▍      | 135/393 [00:23<00:43,  5.87ba/s]#015Running tokenizer on dataset:  35%|███▍      | 136/393 [00:23<00:46,  5.49ba/s]#015Running tokenizer on dataset:  35%|███▍      | 137/393 [00:23<00:45,  5.64ba/s]#015Running tokenizer on dataset:  35%|███▌      | 138/393 [00:24<00:44,  5.72ba/s]#015Running tokenizer on dataset:  35%|███▌      | 139/393 [00:24<00:43,  5.81ba/s]#015Running tokenizer on dataset:  36%|███▌      | 140/393 [00:24<00:43,  5.84ba/s]#015Running tokenizer on dataset:  36%|███▌      | 141/393 [00:24<00:43,  5.85ba/s]#015Running tokenizer on dataset:  36%|███▌      | 142/393 [00:24<00:42,  5.89ba/s]#015Running tokenizer on dataset:  36%|███▋      | 143/393 [00:24<00:42,  5.89ba/s]#015Running tokenizer on dataset:  37%|███▋      | 144/393 [00:25<00:42,  5.87ba/s]#015Running tokenizer on dataset:  37%|███▋      | 145/393 [00:25<00:42,  5.87ba/s]#015Running tokenizer on dataset:  37%|███▋      | 146/393 [00:25<00:42,  5.86ba/s]#015Running tokenizer on dataset:  37%|███▋      | 147/393 [00:25<00:42,  5.82ba/s]#015Running tokenizer on dataset:  38%|███▊      | 148/393 [00:25<00:44,  5.46ba/s]#015Running tokenizer on dataset:  38%|███▊      | 149/393 [00:26<00:43,  5.64ba/s]#015Running tokenizer on dataset:  38%|███▊      | 150/393 [00:26<00:42,  5.73ba/s]#015Running tokenizer on dataset:  38%|███▊      | 151/393 [00:26<00:41,  5.82ba/s]#015Running tokenizer on dataset:  39%|███▊      | 152/393 [00:26<00:41,  5.83ba/s]#015Running tokenizer on dataset:  39%|███▉      | 153/393 [00:26<00:40,  5.87ba/s]#015Running tokenizer on dataset:  39%|███▉      | 154/393 [00:26<00:40,  5.87ba/s]#015Running tokenizer on dataset:  39%|███▉      | 155/393 [00:27<00:40,  5.86ba/s]#015Running tokenizer on dataset:  40%|███▉      | 156/393 [00:27<00:40,  5.83ba/s]#015Running tokenizer on dataset:  40%|███▉      | 157/393 [00:27<00:40,  5.85ba/s]#015Running tokenizer on dataset:  40%|████      | 158/393 [00:27<00:40,  5.84ba/s]#015Running tokenizer on dataset:  40%|████      | 159/393 [00:27<00:40,  5.82ba/s]#015Running tokenizer on dataset:  41%|████      | 160/393 [00:27<00:42,  5.47ba/s]#015Running tokenizer on dataset:  41%|████      | 161/393 [00:28<00:41,  5.61ba/s]#015Running tokenizer on dataset:  41%|████      | 162/393 [00:28<00:40,  5.72ba/s]#015Running tokenizer on dataset:  41%|████▏     | 163/393 [00:28<00:39,  5.80ba/s]#015Running tokenizer on dataset:  42%|████▏     | 164/393 [00:28<00:39,  5.85ba/s]#015Running tokenizer on dataset:  42%|████▏     | 165/393 [00:28<00:38,  5.90ba/s]#015Running tokenizer on dataset:  42%|████▏     | 166/393 [00:28<00:38,  5.90ba/s]#015Running tokenizer on dataset:  42%|████▏     | 167/393 [00:29<00:38,  5.90ba/s]#015Running tokenizer on dataset:  43%|████▎     | 168/393 [00:29<00:38,  5.90ba/s]#015Running tokenizer on dataset:  43%|████▎     | 169/393 [00:29<00:38,  5.88ba/s]#015Running tokenizer on dataset:  43%|████▎     | 170/393 [00:29<00:37,  5.87ba/s]#015Running tokenizer on dataset:  44%|████▎     | 171/393 [00:29<00:37,  5.87ba/s]#015Running tokenizer on dataset:  44%|████▍     | 172/393 [00:30<00:40,  5.49ba/s]#015Running tokenizer on dataset:  44%|████▍     | 173/393 [00:30<00:39,  5.63ba/s]#015Running tokenizer on dataset:  44%|████▍     | 174/393 [00:30<00:38,  5.74ba/s]#015Running tokenizer on dataset:  45%|████▍     | 175/393 [00:30<00:37,  5.80ba/s]#015Running tokenizer on dataset:  45%|████▍     | 176/393 [00:30<00:37,  5.83ba/s]#015Running tokenizer on dataset:  45%|████▌     | 177/393 [00:30<00:36,  5.87ba/s]#015Running tokenizer on dataset:  45%|████▌     | 178/393 [00:31<00:36,  5.90ba/s]#015Running tokenizer on dataset:  46%|████▌     | 179/393 [00:31<00:36,  5.88ba/s]#015Running tokenizer on dataset:  46%|████▌     | 180/393 [00:31<00:36,  5.88ba/s]#015Running tokenizer on dataset:  46%|████▌     | 181/393 [00:31<00:36,  5.84ba/s]#015Running tokenizer on dataset:  46%|████▋     | 182/393 [00:31<00:36,  5.82ba/s]#015Running tokenizer on dataset:  47%|████▋     | 183/393 [00:31<00:37,  5.66ba/s]#015Running tokenizer on dataset:  47%|████▋     | 184/393 [00:32<00:47,  4.37ba/s]#015Running tokenizer on dataset:  47%|████▋     | 185/393 [00:32<00:43,  4.75ba/s]#015Running tokenizer on dataset:  47%|████▋     | 186/393 [00:32<00:40,  5.07ba/s]#015Running tokenizer on dataset:  48%|████▊     | 187/393 [00:32<00:38,  5.30ba/s]#015Running tokenizer on dataset:  48%|████▊     | 188/393 [00:32<00:37,  5.48ba/s]#015Running tokenizer on dataset:  48%|████▊     | 189/393 [00:33<00:36,  5.59ba/s]#015Running tokenizer on dataset:  48%|████▊     | 190/393 [00:33<00:36,  5.53ba/s]#015Running tokenizer on dataset:  49%|████▊     | 191/393 [00:33<00:36,  5.48ba/s]#015Running tokenizer on dataset:  49%|████▉     | 192/\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m393 [00:33<00:36,  5.48ba/s]#015Running tokenizer on dataset:  49%|████▉     | 193/393 [00:33<00:35,  5.58ba/s]#015Running tokenizer on dataset:  49%|████▉     | 194/393 [00:34<00:35,  5.64ba/s]#015Running tokenizer on dataset:  50%|████▉     | 195/393 [00:34<00:34,  5.68ba/s]#015Running tokenizer on dataset:  50%|████▉     | 196/393 [00:34<00:36,  5.35ba/s]#015Running tokenizer on dataset:  50%|█████     | 197/393 [00:34<00:35,  5.49ba/s]#015Running tokenizer on dataset:  50%|█████     | 198/393 [00:34<00:34,  5.62ba/s]#015Running tokenizer on dataset:  51%|█████     | 199/393 [00:34<00:33,  5.74ba/s]#015Running tokenizer on dataset:  51%|█████     | 200/393 [00:35<00:33,  5.79ba/s]#015Running tokenizer on dataset:  51%|█████     | 201/393 [00:35<00:33,  5.81ba/s]#015Running tokenizer on dataset:  51%|█████▏    | 202/393 [00:35<00:32,  5.83ba/s]#015Running tokenizer on dataset:  52%|█████▏    | 203/393 [00:35<00:32,  5.85ba/s]#015Running tokenizer on dataset:  52%|█████▏    | 204/393 [00:35<00:32,  5.75ba/s]#015Running tokenizer on dataset:  52%|█████▏    | 205/393 [00:35<00:32,  5.76ba/s]#015Running tokenizer on dataset:  52%|█████▏    | 206/393 [00:36<00:32,  5.79ba/s]#015Running tokenizer on dataset:  53%|█████▎    | 207/393 [00:36<00:32,  5.77ba/s]#015Running tokenizer on dataset:  53%|█████▎    | 208/393 [00:36<00:34,  5.36ba/s]#015Running tokenizer on dataset:  53%|█████▎    | 209/393 [00:36<00:33,  5.53ba/s]#015Running tokenizer on dataset:  53%|█████▎    | 210/393 [00:36<00:32,  5.69ba/s]#015Running tokenizer on dataset:  54%|█████▎    | 211/393 [00:37<00:32,  5.68ba/s]#015Running tokenizer on dataset:  54%|█████▍    | 212/393 [00:37<00:31,  5.78ba/s]#015Running tokenizer on dataset:  54%|█████▍    | 213/393 [00:37<00:30,  5.84ba/s]#015Running tokenizer on dataset:  54%|█████▍    | 214/393 [00:37<00:30,  5.83ba/s]#015Running tokenizer on dataset:  55%|█████▍    | 215/393 [00:37<00:30,  5.84ba/s]#015Running tokenizer on dataset:  55%|█████▍    | 216/393 [00:37<00:30,  5.86ba/s]#015Running tokenizer on dataset:  55%|█████▌    | 217/393 [00:38<00:30,  5.85ba/s]#015Running tokenizer on dataset:  55%|█████▌    | 218/393 [00:38<00:29,  5.84ba/s]#015Running tokenizer on dataset:  56%|█████▌    | 219/393 [00:38<00:29,  5.82ba/s]#015Running tokenizer on dataset:  56%|█████▌    | 220/393 [00:38<00:31,  5.46ba/s]#015Running tokenizer on dataset:  56%|█████▌    | 221/393 [00:38<00:30,  5.61ba/s]#015Running tokenizer on dataset:  56%|█████▋    | 222/393 [00:38<00:29,  5.71ba/s]#015Running tokenizer on dataset:  57%|█████▋    | 223/393 [00:39<00:29,  5.79ba/s]#015Running tokenizer on dataset:  57%|█████▋    | 224/393 [00:39<00:28,  5.83ba/s]#015Running tokenizer on dataset:  57%|█████▋    | 225/393 [00:39<00:28,  5.87ba/s]#015Running tokenizer on dataset:  58%|█████▊    | 226/393 [00:39<00:28,  5.88ba/s]#015Running tokenizer on dataset:  58%|█████▊    | 227/393 [00:39<00:28,  5.88ba/s]#015Running tokenizer on dataset:  58%|█████▊    | 228/393 [00:39<00:27,  5.90ba/s]#015Running tokenizer on dataset:  58%|█████▊    | 229/393 [00:40<00:27,  5.91ba/s]#015Running tokenizer on dataset:  59%|█████▊    | 230/393 [00:40<00:27,  5.87ba/s]#015Running tokenizer on dataset:  59%|█████▉    | 231/393 [00:40<00:27,  5.83ba/s]#015Running tokenizer on dataset:  59%|█████▉    | 232/393 [00:40<00:29,  5.45ba/s]#015Running tokenizer on dataset:  59%|█████▉    | 233/393 [00:40<00:28,  5.59ba/s]#015Running tokenizer on dataset:  60%|█████▉    | 234/393 [00:40<00:27,  5.72ba/s]#015Running tokenizer on dataset:  60%|█████▉    | 235/393 [00:41<00:27,  5.82ba/s]#015Running tokenizer on dataset:  60%|██████    | 236/393 [00:41<00:26,  5.90ba/s]#015Running tokenizer on dataset:  60%|██████    | 237/393 [00:41<00:26,  5.88ba/s]#015Running tokenizer on dataset:  61%|██████    | 238/393 [00:41<00:26,  5.88ba/s]#015Running tokenizer on dataset:  61%|██████    | 239/393 [00:41<00:26,  5.92ba/s]#015Running tokenizer on dataset:  61%|██████    | 240/393 [00:41<00:25,  5.92ba/s]#015Running tokenizer on dataset:  61%|██████▏   | 241/393 [00:42<00:25,  5.91ba/s]#015Running tokenizer on dataset:  62%|██████▏   | 242/393 [00:42<00:25,  5.87ba/s]#015Running tokenizer on dataset:  62%|██████▏   | 243/393 [00:42<00:25,  5.88ba/s]#015Running tokenizer on dataset:  62%|██████▏   | 244/393 [00:42<00:27,  5.51ba/s]#015Running tokenizer on dataset:  62%|██████▏   | 245/393 [00:42<00:26,  5.66ba/s]#015Running tokenizer on dataset:  63%|██████▎   | 246/393 [00:43<00:25,  5.77ba/s]#015Running tokenizer on dataset:  63%|██████▎   | 247/393 [00:43<00:25,  5.81ba/s]#015Running tokenizer on dataset:  63%|██████▎   | 248/393 [00:43<00:24,  5.86ba/s]#015Running tokenizer on dataset:  63%|██████▎   | 249/393 [00:43<00:24,  5.89ba/s]#015Running tokenizer on dataset:  64%|██████▎   | 250/393 [00:43<00:24,  5.92ba/s]#015Running tokenizer on dataset:  64%|██████▍   | 251/393 [00:43<00:24,  5.91ba/s]#015Running tokenizer on dataset:  64%|██████▍   | 252/393 [00:44<00:23,  5.91ba/s]#015Running tokenizer on dataset:  64%|██████▍   | 253/393 [00:44<00:23,  5.84ba/s]#015Running tokenizer on dataset:  65%|██████▍   | 254/393 [00:44<00:23,  5.81ba/s]#015Running tokenizer on dataset:  65%|██████▍   | 255/393 [00:44<00:23,  5.80ba/s]#015Running tokenizer on dataset:  65%|██████▌   | 256/393 [00:44<00:25,  5.43ba/s]#015Running tokenizer on dataset:  65%|██████▌   | 257/393 [00:44<00:24,  5.60ba/s]#015Running tokenizer on dataset:  66%|██████▌   | 258/393 [00:45<00:23,  5.74ba/s]#015Running tokenizer on dataset:  66%|██████▌   | 259/393 [00:45<00:23,  5.82ba/s]#015Running tokenizer on dataset:  66%|██████▌   | 260/393 [00:45<00:22,  5.85ba/s]#015Running tokenizer on dataset:  66%|██████▋   | 261/393 [00:45<00:22,  5.88ba/s]#015Running tokenizer on dataset:  67%|██████▋   | 262/393 [00:45<00:22,  5.87ba/s]#015Running tokenizer on dataset:  67%|██████▋   | 263/393 [00:45<00:22,  5.84ba/s]#015Running tokenizer on dataset:  67%|██████▋   | 264/393 [00:46<00:22,  5.83ba/s]#015Running tokenizer on dataset:  67%|██████▋   | 265/393 [00:46<00:22,  5.79ba/s]#015Running tokenizer on dataset:  68%|██████▊   | 266/393 [00:46<00:21,  5.78ba/s]#015Running tokenizer on dataset:  68%|██████▊   | 267/393 [00:46<00:21,  5.77ba/s]#015Running tokenizer on dataset:  68%|██████▊   | 268/393 [00:46<00:23,  5.36ba/s]#015Running tokenizer on dataset:  68%|██████▊   | 269/393 [00:47<00:22,  5.54ba/s]#015Running tokenizer on dataset:  69%|██████▊   | 270/393 [00:47<00:21,  5.66ba/s]#015Running tokenizer on dataset:  69%|██████▉   | 271/393 [00:47<00:21,  5.76ba/s]#015Running tokenizer on dataset:  69%|██████▉   | 272/393 [00:47<00:20,  5.85ba/s]#015Running tokenizer on dataset:  69%|██████▉   | 273/393 [00:47<00:20,  5.88ba/s]#015Running tokenizer on dataset:  70%|██████▉   | 274/393 [00:47<00:20,  5.91ba/s]#015Running tokenizer on dataset:  70%|██████▉   | 275/393 [00:48<00:19,  5.91ba/s]#015Running tokenizer on dataset:  70%|███████   | 276/393 [00:48<00:20,  5.83ba/s]#015Running tokenizer on dataset:  70%|███████   | 277/393 [00:48<00:19,  5.84ba/s]#015Running tokenizer on dataset:  71%|███████   | 278/393 [00:48<00:19,  5.85ba/s]#015Running tokenizer on dataset:  71%|███████   | 279/393 [00:48<00:19,  5.78ba/s]#015Running tokenizer on dataset:  71%|███████   | 280/393 [00:48<00:20,  5.45ba/s]#015Running tokenizer on dataset:  72%|███████▏  | 281/393 [00:49<00:20,  5.56ba/s]#015Running tokenizer on dataset:  72%|███████▏  | 282/393 [00:49<00:19,  5.68ba/s]#015Running tokenizer on dataset:  72%|███████▏  | 283/393 [00:49<00:19,  5.77ba/s]#015Running tokenizer on dataset:  72%|███████▏  | 284/393 [00:49<00:18,  5.84ba/s]#015Running tokenizer on dataset:  73%|███████▎  | 285/393 [00:49<00:18,  5.82ba/s]#015Running tokenizer on dataset:  73%|███████▎  | 286/393 [00:49<00:18,  5.84ba/s]#015Running tokenizer on dataset:  73%|███████▎  | 287/393 [00:50<00:17,  5.89ba/s]#015Running tokenizer on dataset:  73%|███████▎  | 288/393 [00:50<00:17,  5.86ba/s]#015Running tokenizer on dataset:  74%|███████▎  | 289/393 [00:50<00:17,  5.87ba/s]#015Running tokenizer on dataset:  74%|███████▍  | 290/393 [00:50<00:17,  5.87ba/s]#015Running tokenizer on dataset:  74%|███████▍  | 291/393 [00:50<00:17,  5.84ba/s]#015Running tokenizer on dataset:  74%|███████▍  | 292/393 [00:51<00:18,  5.47ba/s]#015Running tokenizer on dataset:  75%|███████▍  | 293/393 [00:51<00:17,  5.60ba/s]#015Running tokenizer on dataset:  75%|███████▍  | 294/393 [00:51<00:17,  5.72ba/s]#015Running tokenizer on dataset:  75%|███████▌  | 295/393 [00:51<00:16,  5.82ba/s]#015Running tokenizer on dataset:  75%|███████▌  | 296/393 [00:51<00:16,  5.87ba/s]#015Running tokenizer on dataset:  76%|███████▌  | 297/393 [00:51<00:16,  5.90ba/s]#015Running tokenizer on dataset:  76%|███████▌  | 298/393 [00:52<00:16,  5.86ba/s]#015Running tokenizer on dataset:  76%|███████▌  | 299/393 [00:52<00:15,  5.89ba/s]#015Running tokenizer on dataset:  76%|███████▋  | 300/393 [00:52<00:15,  5.85ba/s]#015Running tokenizer on dataset:  77%|███████▋  | 301/393 [00:52<00:15,  5.87ba/s]#015Running tokenizer on dataset:  77%|███████▋  | 302/393 [00:52<00:15,  5.88ba/s]#015Running tokenizer on dataset:  77%|███████▋  | 303/393 [00:52<00:15,  5.86ba/s]#015Running tokenizer on dataset:  77%|███████▋  | 304/393 [00:53<00:16,  5.48ba/s]#015Running tokenizer on dataset:  78%|███████▊  | 305/393 [00:53<00:15,  5.65ba/s]#015Running tokenizer on dataset:  78%|███████▊  | 306/393 [00:53<00:15,  5.75ba/s]#015Running tokenizer on dataset:  78%|███████▊  | 307/393 [00:53<00:14,  5.82ba/s]#015Running tokenizer on dataset:  78%|███████▊  | 308/393 [00:53<00:14,  5.87ba/s]#015Running tokenizer on dataset:  79%|███████▊  | 309/393 [00:53<00:14,  5.92ba/s]#015Running tokenizer on dataset:  79%|███████▉  | 310/393 [00:54<00:13,  5.94ba/s]#015Running tokenizer on dataset:  79%|███████▉  | 311/393 [00:54<00:13,  5.94ba/s]#015Running tokenizer on dataset:  79%|███████▉  | 312/393 [00:54<00:13,  5.93ba/s]#015Running tokenizer on dataset:  80%|███████▉  | 313/393 [00:54<00:13,  5.91ba/s]#015Running tokenizer on dataset:  80%|███████▉  | 314/393 [00:54<00:13,  5.89ba/s]#015Running tokenizer on dataset:  80%|████████  | 315/393 [00:54<00:13,  5.87ba/s]#015Running tokenizer on dataset:  80%|████████  | 316/393 [00:55<00:14,  5.48ba/s]#015Running tokenizer on dataset:  81%|████████  | 317/393 [00:55<00:13,  5.66ba/s]#015Running tokenizer on dataset:  81%|████████  | 318/393 [00:55<00:13,  5.74ba/s]#015Running tokenizer on dataset:  81%|████████  | 319/393 [00:55<00:12,  5.82ba/s]#015Running tokenizer on dataset:  81%|████████▏ | 320/393 [00:55<00:12,  5.85ba/s]#015Running tokenizer on dataset:  82%|████████▏ | 321/393 [00:55<00:12,  5.85ba/s]#015Running tokenizer on dataset:  82%|████████▏ | 322/393 [00:56<00:12,  5.88ba/s]#015Running tokenizer on dataset:  82%|████████▏ | 323/393 [00:56<00:11,  5.84ba/s]#015Running tokenizer on dataset:  82%|████████▏ | 324/393 [00:56<00:11,  5.86ba/s]#015Running tokenizer on dataset:  83%|████████▎ | 325/393 [00:56<00:11,  5.86ba/s]#015Running tokenizer on dataset:  83%|████████▎ | 326/393 [00:56<00:11,  5.85ba/s]#015Running tokenizer on dataset:  83%|████████▎ | 327/393 [00:57<00:11,  5.83ba/s]#015Running tokenizer on dataset:  83%|████████▎ | 328/393 [00:57<00:11,  5.49ba/s]#015Running tokenizer on dataset:  84%|████████▎ | 329/393 [00:57<00:11,  5.64ba/s]#015Running tokenizer on dataset:  84%|████████▍ | 330/393 [00:57<00:10,  5.77ba/s]#015Running tokenizer on dataset:  84%|████████▍ | 331/393 [00:57<00:10,  5.84ba/s]#015Running tokenizer on dataset:  84%|████████▍ | 332/393 [00:57<00:10,  5.87ba/s]#015Running tokenizer on dataset:  85%|████████▍ | 333/393 [00:58<00:10,  5.90ba/s]#015Running tokenizer on dataset:  85%|████████▍ | 334/393 [00:58<00:10,  5.89ba/s]#015Running tokenizer on dataset:  85%|████████▌ | 335/393 [00:58<00:09,  5.91ba/s]#015Running tokenizer on dataset:  85%|████████▌ | 336/393 [00:58<00:09,  5.90ba/s]#015Running tokenizer on dataset:  86%|████████▌ | 337/393 [00:58<00:09,  5.88ba/s]#015Running tokenizer on dataset:  86%|████████▌ | 338/393 [00:58<00:09,  5.88ba/s]#015Running tokenizer on dataset:  86%|████████▋ | 339/393 [00:59<00:09,  5.85ba/s]#015Running tokenizer on dataset:  87%|████████▋ | 340/393 [00:59<00:09,  5.49ba/s]#015Running tokenizer on dataset:  87%|████████▋ | 341/393 [00:59<00:09,  5.66ba/s]#015Running tokenizer on dataset:  87%|████████▋ | 342/393 [00:59<00:08,  5.75ba/s]#015Running tokenizer on dataset:  87%|████████▋ | 343/393 [00:59<00:08,  5.82ba/s]#015Running tokenizer on dataset:  88%|████████▊ | 344/393 [00:59<00:08,  5.86ba/s]#015Running tokenizer on dataset:  88%|████████▊ | 345/393 [01:00<00:08,  5.86ba/s]#015Running tokenizer on dataset:  88%|████████▊ | 346/393 [01:00<00:08,  5.85ba/s]#015Running tokenizer on dataset:  88%|████████▊ | 347/393 [01:00<00:07,  5.88ba/s]#015Running tokenizer on dataset:  89%|████████▊ | 348/393 [01:00<00:07,  5.88ba/s]#015Running tokenizer on dataset:  89%|████████▉ | 349/393 [01:00<00:07,  5.87ba/s]#015Running tokenizer on dataset:  89%|████████▉ | 350/393 [01:00<00:07,  5.84ba/s]#015Running tokenizer on dataset:  89%|████████▉ | 351/393 [01:01<00:07,  5.83ba/s]#015Running tokenizer on dataset:  90%|████████▉ | 352/393 [01:01<00:07,  5.46ba/s]#015Running tokenizer on dataset:  90%|████████▉ | 353/393 [01:01<00:07,  5.64ba/s]#015Running tokenizer on dataset:  90%|█████████ | 354/393 [01:01<00:06,  5.75ba/s]#015Running tokenizer on dataset:  90%|█████████ | 355/393 [01:01<00:06,  5.78ba/s]#015Running tokenizer on dataset:  91%|█████████ | 356/393 [01:02<00:06,  5.78ba/s]#015Running tokenizer on dataset:  91%|█████████ | 357/393 [01:02<00:06,  5.86ba/s]#015Running tokenizer on dataset:  91%|█████████ | 358/393 [01:02<00:05,  5.86ba/s]#015Running tokenizer on dataset:  91%|█████████▏| 359/393 [01:02<00:05,  5.89ba/s]#015Running tokenizer on dataset:  92%|█████████▏| 360/393 [01:02<00:06,  5.40ba/s]#015Running tokenizer on dataset:  92%|█████████▏| 361/393 [01:02<00:06,  5.19ba/s]#015Running tokenizer on dataset:  92%|█████████▏| 362/393 [01:03<00:05,  5.35ba/s]#015Running tokenizer on dataset:  92%|█████████▏| 363/393 [01:03<00:05,  5.44ba/s]#015Running tokenizer on dataset:  93%|█████████▎| 364/393 [01:03<00:05,  5.19ba/s]#015Running tokenizer on dataset:  \u001b[0m\n",
      "\u001b[34m93%|█████████▎| 365/393 [01:03<00:05,  5.40ba/s]#015Running tokenizer on dataset:  93%|█████████▎| 366/393 [01:03<00:04,  5.56ba/s]#015Running tokenizer on dataset:  93%|█████████▎| 367/393 [01:04<00:04,  5.67ba/s]#015Running tokenizer on dataset:  94%|█████████▎| 368/393 [01:04<00:04,  5.75ba/s]#015Running tokenizer on dataset:  94%|█████████▍| 369/393 [01:04<00:04,  5.79ba/s]#015Running tokenizer on dataset:  94%|█████████▍| 370/393 [01:04<00:03,  5.83ba/s]#015Running tokenizer on dataset:  94%|█████████▍| 371/393 [01:04<00:03,  5.88ba/s]#015Running tokenizer on dataset:  95%|█████████▍| 372/393 [01:04<00:03,  5.89ba/s]#015Running tokenizer on dataset:  95%|█████████▍| 373/393 [01:05<00:03,  5.86ba/s]#015Running tokenizer on dataset:  95%|█████████▌| 374/393 [01:05<00:03,  5.84ba/s]#015Running tokenizer on dataset:  95%|█████████▌| 375/393 [01:05<00:03,  5.80ba/s]#015Running tokenizer on dataset:  96%|█████████▌| 376/393 [01:05<00:03,  5.45ba/s]#015Running tokenizer on dataset:  96%|█████████▌| 377/393 [01:05<00:02,  5.63ba/s]#015Running tokenizer on dataset:  96%|█████████▌| 378/393 [01:05<00:02,  5.70ba/s]#015Running tokenizer on dataset:  96%|█████████▋| 379/393 [01:06<00:02,  5.80ba/s]#015Running tokenizer on dataset:  97%|█████████▋| 380/393 [01:06<00:02,  5.82ba/s]#015Running tokenizer on dataset:  97%|█████████▋| 381/393 [01:06<00:02,  5.84ba/s]#015Running tokenizer on dataset:  97%|█████████▋| 382/393 [01:06<00:01,  5.88ba/s]#015Running tokenizer on dataset:  97%|█████████▋| 383/393 [01:06<00:01,  5.83ba/s]#015Running tokenizer on dataset:  98%|█████████▊| 384/393 [01:06<00:01,  5.83ba/s]#015Running tokenizer on dataset:  98%|█████████▊| 385/393 [01:07<00:01,  5.85ba/s]#015Running tokenizer on dataset:  98%|█████████▊| 386/393 [01:07<00:01,  5.84ba/s]#015Running tokenizer on dataset:  98%|█████████▊| 387/393 [01:07<00:01,  5.81ba/s]#015Running tokenizer on dataset:  99%|█████████▊| 388/393 [01:07<00:00,  5.42ba/s]#015Running tokenizer on dataset:  99%|█████████▉| 389/393 [01:07<00:00,  5.59ba/s]#015Running tokenizer on dataset:  99%|█████████▉| 390/393 [01:08<00:00,  5.71ba/s]#015Running tokenizer on dataset:  99%|█████████▉| 391/393 [01:08<00:00,  5.80ba/s]#015Running tokenizer on dataset: 100%|█████████▉| 392/393 [01:08<00:00,  5.84ba/s]#015Running tokenizer on dataset: 100%|██████████| 393/393 [01:08<00:00,  6.41ba/s]#015Running tokenizer on dataset: 100%|██████████| 393/393 [01:08<00:00,  5.74ba/s]\u001b[0m\n",
      "\u001b[34m02/14/2022 03:54:24 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecd9ae2b105d4078.arrow\u001b[0m\n",
      "\u001b[34m#015Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]#015Running tokenizer on dataset:  10%|█         | 1/10 [00:00<00:01,  4.87ba/s]#015Running tokenizer on dataset:  20%|██        | 2/10 [00:00<00:01,  5.38ba/s]#015Running tokenizer on dataset:  30%|███       | 3/10 [00:00<00:01,  5.59ba/s]#015Running tokenizer on dataset:  40%|████      | 4/10 [00:00<00:01,  5.75ba/s]#015Running tokenizer on dataset:  50%|█████     | 5/10 [00:00<00:00,  5.85ba/s]#015Running tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:00,  5.92ba/s]#015Running tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  5.95ba/s]#015Running tokenizer on dataset:  80%|████████  | 8/10 [00:01<00:00,  5.43ba/s]#015Running tokenizer on dataset:  90%|█████████ | 9/10 [00:01<00:00,  5.55ba/s]#015Running tokenizer on dataset: 100%|██████████| 10/10 [00:01<00:00,  5.91ba/s]#015Running tokenizer on dataset: 100%|██████████| 10/10 [00:01<00:00,  5.72ba/s]\u001b[0m\n",
      "\u001b[34m02/14/2022 03:54:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-cd34dd5926c1c797.arrow\u001b[0m\n",
      "\u001b[34m#015Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]#015Running tokenizer on dataset:  10%|█         | 1/10 [00:00<00:01,  4.80ba/s]#015Running tokenizer on dataset:  20%|██        | 2/10 [00:00<00:01,  5.33ba/s]#015Running tokenizer on dataset:  30%|███       | 3/10 [00:00<00:01,  5.53ba/s]#015Running tokenizer on dataset:  40%|████      | 4/10 [00:00<00:01,  5.72ba/s]#015Running tokenizer on dataset:  50%|█████     | 5/10 [00:00<00:00,  5.85ba/s]#015Running tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:00,  5.91ba/s]#015Running tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  5.92ba/s]#015Running tokenizer on dataset:  80%|████████  | 8/10 [00:01<00:00,  5.95ba/s]#015Running tokenizer on dataset:  90%|█████████ | 9/10 [00:01<00:00,  5.94ba/s]#015Running tokenizer on dataset: 100%|██████████| 10/10 [00:01<00:00,  5.67ba/s]#015Running tokenizer on dataset: 100%|██████████| 10/10 [00:01<00:00,  5.72ba/s]\u001b[0m\n",
      "\u001b[34m02/14/2022 03:54:28 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1e99cc201d732275.arrow\u001b[0m\n",
      "\u001b[34m#015Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]#015Running tokenizer on dataset:  10%|█         | 1/10 [00:00<00:01,  4.85ba/s]#015Running tokenizer on dataset:  20%|██        | 2/10 [00:00<00:01,  5.38ba/s]#015Running tokenizer on dataset:  30%|███       | 3/10 [00:00<00:01,  5.58ba/s]#015Running tokenizer on dataset:  40%|████      | 4/10 [00:00<00:01,  5.73ba/s]#015Running tokenizer on dataset:  50%|█████     | 5/10 [00:00<00:00,  5.83ba/s]#015Running tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:00,  5.90ba/s]#015Running tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  5.90ba/s]#015Running tokenizer on dataset:  80%|████████  | 8/10 [00:01<00:00,  5.93ba/s]#015Running tokenizer on dataset:  90%|█████████ | 9/10 [00:01<00:00,  5.96ba/s]#015Running tokenizer on dataset: 100%|██████████| 10/10 [00:01<00:00,  6.28ba/s]#015Running tokenizer on dataset: 100%|██████████| 10/10 [00:01<00:00,  5.92ba/s]\u001b[0m\n",
      "\u001b[34m02/14/2022 03:54:29 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-468c951a691eee5d.arrow\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]#015Running tokenizer on dataset:  10%|█         | 1/10 [00:00<00:01,  4.84ba/s]#015Running tokenizer on dataset:  20%|██        | 2/10 [00:00<00:01,  4.48ba/s]#015Running tokenizer on dataset:  30%|███       | 3/10 [00:00<00:01,  5.06ba/s]#015Running tokenizer on dataset:  40%|████      | 4/10 [00:00<00:01,  5.41ba/s]#015Running tokenizer on dataset:  50%|█████     | 5/10 [00:00<00:00,  5.59ba/s]#015Running tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:00,  5.70ba/s]#015Running tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  5.77ba/s]#015Running tokenizer on dataset:  80%|████████  | 8/10 [00:01<00:00,  5.80ba/s]#015Running tokenizer on dataset:  90%|█████████ | 9/10 [00:01<00:00,  5.74ba/s]#015Running tokenizer on dataset: 100%|██████████| 10/10 [00:01<00:00,  5.98ba/s]#015Running tokenizer on dataset: 100%|██████████| 10/10 [00:01<00:00,  5.62ba/s]\u001b[0m\n",
      "\u001b[34m02/14/2022 03:54:31 - INFO - __main__ - Sample 335243 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'hypothesis': \"Parents are busy and it's sometimes hard to get them out.\", 'idx': 335243, 'input_ids': [101, 1128, 1221, 1165, 1147, 2153, 1435, 1105, 1122, 112, 188, 1662, 1106, 1243, 1172, 1149, 1105, 170, 1974, 1104, 2153, 1138, 2844, 1106, 1301, 1105, 1105, 1614, 1176, 1115, 1105, 1122, 112, 188, 1523, 1120, 1480, 1177, 102, 2153, 1132, 5116, 1105, 1122, 112, 188, 2121, 1662, 1106, 1243, 1172, 1149, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0, 'premise': \"you know when their parents come and it's hard to get them out and a lot of parents have places to go and and things like that and it's late at night so\", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\u001b[0m\n",
      "\u001b[34m02/14/2022 03:54:31 - INFO - __main__ - Sample 58369 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'hypothesis': 'Where and what is art? ', 'idx': 58369, 'input_ids': [101, 1187, 1110, 1893, 136, 102, 1187, 1105, 1184, 1110, 1893, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'premise': 'Where is art?', 'token_type_ids': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\u001b[0m\n",
      "\u001b[34m02/14/2022 03:54:31 - INFO - __main__ - Sample 13112 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'hypothesis': 'The list says alcohol and injury are negatives facing staff.', 'idx': 13112, 'input_ids': [101, 6272, 1105, 3773, 117, 1112, 1218, 1112, 4094, 22496, 117, 1132, 1113, 1103, 2190, 119, 102, 1103, 2190, 1867, 6272, 1105, 3773, 1132, 4366, 1116, 4749, 2546, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'premise': 'Alcohol and injury, as well as brief interventions, are on the list.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\u001b[0m\n",
      "\u001b[34m02/14/2022 03:54:31 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.15.1/metrics/glue/glue.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpkzr6p685\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/1.86k [00:00<?, ?B/s]#015Downloading: 5.78kB [00:00, 5.80MB/s]                   \u001b[0m\n",
      "\u001b[34m02/14/2022 03:54:31 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.15.1/metrics/glue/glue.py in cache at /root/.cache/huggingface/datasets/downloads/52be61f55fbfe81f507fe78e7d5f166999072e90327bb77d1b62da84dae59e11.96f088dbf50cf9762fec7012ded805ef991c57b1aed0fd293b2cee069a9bd5d5.py\u001b[0m\n",
      "\u001b[34m02/14/2022 03:54:31 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/52be61f55fbfe81f507fe78e7d5f166999072e90327bb77d1b62da84dae59e11.96f088dbf50cf9762fec7012ded805ef991c57b1aed0fd293b2cee069a9bd5d5.py\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:540] 2022-02-14 03:54:33,989 >> The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: hypothesis, idx, premise.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1196] 2022-02-14 03:54:33,997 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1197] 2022-02-14 03:54:33,997 >>   Num examples = 392702\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1198] 2022-02-14 03:54:33,997 >>   Num Epochs = 3\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1199] 2022-02-14 03:54:33,997 >>   Instantaneous batch size per device = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1200] 2022-02-14 03:54:33,997 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1201] 2022-02-14 03:54:33,998 >>   Gradient Accumulation steps = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1202] 2022-02-14 03:54:33,998 >>   Total optimization steps = 36816\u001b[0m\n",
      "\u001b[34m[2022-02-14 03:54:34.084 ip-10-0-68-31.us-east-2.compute.internal:17 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-02-14 03:54:34.120 ip-10-0-68-31.us-east-2.compute.internal:17 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "framework_processor = FrameworkProcessor(HuggingFace,\n",
    "                                      framework_version=None,\n",
    "                                      image_uri=docker_repo,\n",
    "                                      code_location = s3_code_path, \n",
    "                                       py_version=\"py36\",\n",
    "                                       command=[\"python\"],\n",
    "                                       env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "                                       role=role,\n",
    "                                       instance_type=instance_type,\n",
    "                                       instance_count=instance_count,\n",
    "                                       max_runtime_in_seconds= 5 * 24 * 60 * 60,\n",
    "                                       volume_size_in_gb = 250,\n",
    "                                       network_config=NetworkConfig(enable_network_isolation=False),\n",
    "                                       base_job_name =\"glue-reverse-mnli\"\n",
    "                                       )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sm_local_input_model = \"/opt/ml/processing/input/data/model\"\n",
    "sm_local_input_data = \"/opt/ml/processing/input/data/jsonlines\"\n",
    "sm_local_input_vocab = \"/opt/ml/processing/input/data/vocab\"\n",
    "\n",
    "\n",
    "sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "\n",
    "\n",
    "framework_processor.run(\n",
    "        code=f'run_glue.py',\n",
    "        source_dir=f'{transformer_examples_dir}/examples/pytorch/text-classification',\n",
    "        arguments=[\n",
    "            \"--task_name\", \"mnli\",\n",
    "            \"--model_name_or_path\", sm_local_input_model,\n",
    "            \"--do_train\", \"1\",\n",
    "            \"--do_eval\",\"1\",\n",
    "            \"--do_predict\",\"1\",\n",
    "            \"--max_seq_length\", str(512),\n",
    "            \"--per_device_train_batch_size\", str(8),\n",
    "            \"--gradient_accumulation_steps\", str(4),\n",
    "            \"--learning_rate\", str(2e-5),\n",
    "            \"--num_train_epochs\", str(3),\n",
    "            \"--output_dir\", sm_local_output,\n",
    "            \"--overwrite_output_dir\", \"1\",\n",
    "            \"--load_best_model_at_end\", \"1\",     # load the best model when finished training (default metric is loss)\n",
    "            \"--eval_steps\",\"200\",\n",
    "            \"--save_steps\",\"200\",\n",
    "            \"--evaluation_strategy\",\"steps\",\n",
    "            \"--disable_tqdm\",\"1\"\n",
    "           \n",
    "        ],\n",
    "\n",
    "        inputs=[\n",
    "#                 ProcessingInput(\n",
    "#                     source=s3_input_data,\n",
    "#                     s3_data_type = s3_data_type,\n",
    "#                     destination=sm_local_input_data,\n",
    "#                     s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "                ProcessingInput(\n",
    "                        source=s3_model_package_path,\n",
    "                        destination=sm_local_input_model,\n",
    "                        s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "#                 ProcessingInput(\n",
    "#                         source=s3_input_vocab,\n",
    "#                         destination=sm_local_input_vocab,\n",
    "#                         s3_data_distribution_type=\"FullyReplicated\")\n",
    "            ],\n",
    "\n",
    "\n",
    "        outputs=[ProcessingOutput(\n",
    "                source=sm_local_output, \n",
    "                destination=s3_output_path,\n",
    "                output_name='predictions')]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
